[
    {
        "uri": "/pages/about",
        "title": "About IMTorg",
        "content": "\nThis blog site is a knowledge base of various innovations produced by Information Management Technologies.  If you would like to learn more, please contact us.  We've helped many firms of all sizes, both commercial and public, including the following:\n\nSTG\nNational Institutes of Health\nGlobal Association of Risk Professionals\nUS Department of State\nWisconsin Department of Transportation\nmultiple start-ups \n\n",
        "tags": []
    },
    {
        "uri": "/pages/search",
        "title": "Search the KnowledgeBase",
        "content": "\nThis will look through both internal and external sources to find pertinent information.\n\nSearch\n\ndiv class=\"input-group\"\n      input type=\"text\" class=\"form-control\" id=\"search-field\" placeholder=\"math\" /\n      span class=\"input-group-btn\"\n        button class=\"btn btn-default\" type=\"button\" id=\"search-button\"Search/button\n      /span\n    /div\nimg src=\"img-datascience_plain.svg\" alt=\"datascience\" width=\"400\"/\n    !-- /input-group --\n    p style=\"text-align:right; font-size:10px;\" id=\"found\"/p\n    div id=\"results\"/div\n/div\n\niend of results/i",
        "tags": []
    },
    {
        "uri": "/posts/blog_cmdln-linux_fish",
        "title": "The Linux Command Line with Fish Shell",
        "content": "\n\nThe Linux terminal (typically implemented with the Bourne Again Shell Script, BASH) can be intimidating for beginners and annoying for experienced programmers.  But, it is a necessity for most users of Linux; and, in many situations, it can also be a huge productivity enhancer over graphical interfaces.  \n\nFish is a commandline tool that is a great complement to BASH.  It is highly configureable and provides nice features such as syntax coloring and TAB command completion, out-of-the-box.  For this tutorial, we will use a quick docker set-up with the smallest, but still capable, Linux image (bitnami/minideb).  Then, we will install fish and try some of the most common Linux commands.  Fish isn't necessary for most of these bash commands; however, it can make your life a little easier while flying through various directories working on your next project.\n\nTwo great references that are much more in-depth than this tutorial are the following:\n\nThe Art of the Command Line\nLinux Journey\n\nPreparation\n\nSome terminology to know before working includes: \n\nterminal - text input/output environment\nconsole - physical terminal (older hardware-oriented term)\ncommand line - where user enters commands\nshell - command line interpreter\n\n The user (you) will be opening terminal interface and entering the command line through the fish application shell.\n\nInstall docker for your operating system, then run Bitnami's minideb (mini-debian) so that you have a disposable Linux container.  You can break whatever you want in this container and not worry that you've hurt your actual operating system.  To reset it, just create a new container.\n\nlist current images\ndocker images\nobtain and run minideb container\ndocker run --rm -it bitnami/minideb:latest\nenter container's bash interface application\ndocker exec -it cntr_minideb bash\ninstall and use fish\napt-get update && apt-get upgrade\napt-get install fish\nfish\n\nBefore you get started on the basics, you might want to install two additioanl applications.  The nano text editor can be much more intuitive than the more-common vim.  Also, the Cheat application can help in your learning.  Digital Ocean has a tutorial for getting started.\n\napt-get nano\napt-get install python-pip\npip install cheat\ncheat -v\n\nLater, to exit the applications and shut-down docker\n\nfrom fish\nexit\nfrom bash\nexit\ncontinue with docker container, later\ndocker stop cntr_minideb\nkill container\ndocker rm cntr_minideb\n\n Basic File System\n\nThese basic commands are common to many different shell systems.  They include commands for working with files and directories, as well as some basic programming concepts, such as variables, that show-up throughout working in the terminal.\n\nQuickstart\n\ndirectory structure\necho $HOME\nmkdir dir\ncd dir\npwd \ntree\ndisplay file statistics\nstat file\nfile file\ndisplay help\nman command\nhelp command\ntype command\nwhatis command\n\nVariables\n\nOne way that the shell keeps track of all of these settings and details is through an area it maintains called the environment. \n\nEnvironmental variables are variables that are defined for the current shell and are inherited, and override variables, by any child shells or processes. Environmental variables are used to pass information into processes that are spawned from the shell.\n\nShell variables are variables that are contained exclusively within the shell in which they were set or defined. They are often used to keep track of ephemeral data, like the current working directory.\n\nBy convention, these types of variables are usually defined using all capital letters. \n\nEnvironment variables\n\nenvironment variables\nprintenv\nprint specific variable\nprintenv var\nset specific variable\nenv VAR1=\"blahblah\" commandtorun command_options\n\nShell variables\n\nshell variables\nset | less\nwithout functions\nenv VAR1=\"blahblah\" commandtorun command_options\n\nTypical environment variables:\n\ndescribes the shell\nSHELL\nspecifies the type of terminal to emulate when running the shell\nTERM\ncurrent logged in user\nUSER\ncurrent working directory.\nPWD\nprevious working directory\nOLDPWD\ndefines color codes used to add colored output to the ls command\nLS_COLORS\npath to the current user's mailbox\nMAIL\nlist of (ordered) directories that the system will check when looking for commands\nPATH\ncurrent language and localization settings\nLANG\ncurrent user's home directory\nHOME\npreviously executed command\n_\n\nCommon shell variables:\n\nlist of options that were used when bash was executed\nBASHOPTS\nverion\nBASH_VERSION\nBASH_VERSINFO\nnumber of columns wide that are being used to draw output\nCOLUMNS\nstack of directories that are available with the pushd and popd commands\nDIRSTACK\nnumber of lines of command history stored to a file\nHISTFILESIZE\nnumber of lines of command history allowed in memory\nHISTSIZE\nThe hostname of the computer at this time\nHOSTNAME\ninternal field separator to separate input on the command line; space by default\nIFS\nprimary command prompt definition\nPS1\nsecondary prompts for when a command spans multiple lines\nPS2\nshell options that can be set with the set option.\nSHELLOPTS\nthe UID of the current user\nUID\n\nTest shell variables:\n\ndefine shell var\nTEST_VAR='Hello World!'\nconfirm\nset | grep TEST_VAR\nprintenv | grep TEST_VAR\nreference\necho $TEST_VAR\nshell vars are not passed to child processes\nbash\necho $TEST_VAR\n\nTest environment variables:\n\nexport shell var to the environment\nexport TEST_VAR\navailable in child process\nbash\necho $TEST_VAR\nexit\nconvert back to shell var\nexport -n TEST_VAR\nremove completely\nunset TEST_VAR\n\nTypical usage:\n\nnano ~/.bash_profile\nadd `export TEST_VAR='Hello World!'\nexit\nsource ~/.bash_profile    instead of restarting the terminal\n\nCreation, redirection, and wildcards\n\nThese commands are a little more advanced, but you see them often in instructions.  Once you get comfortable using them, they become very helpful.\n\nnew file\ntouch filename\noverwrites\nstream  filename\nappends\nstream  filename\npipe output of left to input on right\nstream | stream\n\nA common usage of the pipe:\n\nprintenv | less\n\nAdditional operators:\n\ntakes input from the file on the right instead of the keyboard\n<\nredirect standard error to the location on the right\n^\nmatch any character string that does not include \"/\"\nmatche any single character, not including \"/\"\n? \nmatch any string including \"/\", recusively\n**\n\nExamples of the above commands:\n\nlist files in that directory and child directories\nls /etc/**.conf\nstand output to file, stand error to where stand output goes (same file)\nls /etc ls_results.txt ^&1\n\nCommand history and TAB completion\n\nThe history of your previous commands is key for moving quickly and remembering completed tasks.  You can move up chronologically in your history by using the UP key. You can move in the reverse direction by using the DOWN key. This is fairly standard.  If we wish to return to our prompt, we just hit the escape key.  We can also type in part of a previous command and then press the UP key to search for the latest instances of that specific command.  Furthermore, we can use the ALT-UP and ALT-DOWN commands to recall the command line arguments only.\n\nprevious commands\nhistory\nlast argument\ncmd !$  \ncmd !_1\nlast command\n!!\n\nFile manipulation\n\nDownload files or get them via http request, then familiarize yourself with them.\n\ndownload\nwget\nhttp requests\ncurl\nconcatenate\ncat\nword count\nwc\nprint file\nhead\ntail\n\nSystem Administration\n\nAdministration of a Linux server is a huge field.  External references are provided, in various sections, to give more detailed explanation.\n\n Machine configuration\n\nThese are basic commands to understand your machine and prepare it for use.\n\nos version\ncat /etc/os-release\nkernel version\nuname -r\nnumber of core\npython -c 'import multiprocessing as mp; print(mp.cpu_count())'\t\nmake current\nsudo apt-get update && sudo apt-get upgrade\n\nDisplaying disk usage\n\nTo understand the foundations around these commands, take a look at the following:\n\ndisk usage\ndisk space\n\ndu --max-depth=1 --human-readable /home/vagrant/ | sort --human-numeric-sort\ndu -d1 -h /home/ubuntu | sort -h\ndu -sh\ndf -h\ndf -i\t\tinodes\n\nDescribing CPU and memory usage\n\nThis is another field where you really need to know the internals to understand what you're looking at.  Get a better understanding of cpu utilization, here.\n\nsudo apt-get install linux-tools-common linux-tools-generic linux-tools-3.13.0.110\nperf stat -a -- sleep 10\n\nNotes\n\nIPC is < 1.0: you are likely memory stalled, and software tuning strategies include reducing memory I/O, and improving CPU caching and memory locality\nIPC is  1.0: you are likely instruction bound. Look for ways to reduce code execution: eliminate unnecessary work, cache operations, etc. CPU flame graphs are a great tool for this investigation\n\n Installing applications\n\nThis is a very old field and you will likely encounter many types of applications of varying history and quality.  Getting to know how to install applications and build packages can give you a greater appreciation before you inevitably do it yourself.\n\npre-approved sources to get packages from\nnano /etc/apt/sources.list\ninstall package\ndpkg -i somedebpackage.deb\nremove package\ndpkg -r somedebpackage.deb\nlist packages\ndpkg -l\npackage manager: advanced package tool\napt install package\napt list\napt moo\n\n Building packages\n\nThis may include many other commands based upon the language of the application.\n\nbuild tools\napt install build-essential\ntar -xzvf package.tar.gz\ncheck dependencies\n./configure\ninstall:copy the correct files to the correct locations on your computer.\nmake install\nuninstall\nmake uninstall\ninstead make .deb and install it\ncheckinstall\n\n Processes\n\nThe kernel is the software between applications and hardware.  It is managing the processes and resources provided to them.  The Linux kernel is named for Linus Torvalds who first created a replacement for Bell's proprietary Unix kernel.  He also created git version control system, and, so, his discussions and comments on web boaurds come with a healthy dose of ego.\n\nexample process\nsleep 1\nrun in background\nsleep 1 &\njobs\nall details and non-tty ps\nps aux\nrefresh 10sec and NIceness priority\ntop; htop;\nrenice 10 -p pid   \npstree -p\npgrep process\npkill process\nprocess filesystem\nls /proc\nprocess state\ncat /proc/pid/status\nfind from what directory process is run\npwdx pid\nps -ef \nwhat processes are listening\nnetstat -lntp\nhow long system is running\nuptime\n\n Routing\n\nRouting is a HUGE subject, but these commands can give you a good support for the first 20%.\n\napt install net-tools\nroute -n\nifconfig\napt install iproute2\nall interfaces\nip link show\nstats of an interface\nip -s link show eth0\nshow ip addresses allocated to interfaces\nip address show\nnetwork manager\napt install nm-tool???\n\nBackground shells\n\nMultiple screens will become much more useful has you become more capable from the commandline.  There are three main systems, take a look at these references for getting a comparison of them.\n\ntmux vs screen\nnohup vs screen\n\nnohup\nscreen\ntmux \n\n Profiles\n\nOnce you have commands down, you will want to start using the terminal on your host machine and customizing it to get your work down more quickly.  There are two main files for customizing your system.\n\n~/.bashrc - Save aliases, shell settings, and functions you commonly use in ~/.bashrc, and arrange for login shells to source it. This will make your setup available in all your shell sessions.\n~/.bashprofile - Put the settings of environment variables as well as commands that should be executed when you login in ~/.bashprofile. Separate configuration will be needed for shells you launch from graphical environment logins and cron jobs.\n\nA login shell is a shell session that begins by authenticating the user. If you are signing into a terminal session or through SSH and authenticate, your shell session will be set as a \"login\" shell.  A session started as a login session will read configuration details from the /etc/profile file first. It will then look for the first login shell configuration file in the user's home directory to get user-specific configuration details.  It reads the first file that it can find out of ~/.bashprofile, ~/.bashlogin, and ~/.profile and does not read any further files.\n\nA non-login shell is created if you start a new shell session from within your authenticated session, like we did by calling the bash command from the terminal. You were not asked for your authentication details when you started your child shell.  A non-login shell will read /etc/bash.bashrc and then the user-specific ~/.bashrc file to build its environment.\n\nAn interactive shell session, such as one that begins with ssh, is a shell session that is attached to a terminal. A non-interactive shell session is one is not attached to a terminal session, such as a script run from the command line.  Non-interactive shells read the environmental variable called BASH_ENV and read the file specified to define the new environment.\n\nWe will usually be setting user-specific environmental variables, and we usually will want our settings to be available in both login and non-login shells. This means that the place to define these variables is in the ~/.bashrc file.\n\nIf you need to set system-wide variables, you may want to think about adding them to /etc/profile, /etc/bash.bashrc, or /etc/environment.\n\nAlias and functions\n\nThis is another way to customize your system.  For more detailed explanation, try this tutorial.\n\nalias ls=\"ls --group-directories-first --color\"\ncdls() { cd \"$@\" && ls; }\ncddu() { cd \"$@\" && du -d1 -h . | sort -h; }\ndu1() { du -d1 -h \"$@\" | sort -h; }\ndu2() { du -d2 -h \"$@\" | sort -h; }\n\n Path\n\nYour Path is where the shell looks for commands.  It is an ordered list, so the first application that fits the command is used.\n\nexport PATH=$PATH:/path/to/dir\n\nUser Management\n\n Access and groups\n\nAccess can take a while to become comfortable with understanding.  Stay with it as security and protection is a necessity for every usage.\n\nlist of groups \ncat /etc/group\nlist all users in a Linux group\ngetent group groupname;\nlist all groups you belong to\ngroups\ncreate new user\nsudo adduser name\nremove user\ndeluser name\nadd user to group\nsudo usermod -G name-of-group -a name-of-user\nremove user from group\ngpasswd -d user group\n\n SSH to remote server\n\nlogin to remote\n\nssh-keygen -t rsa\nssh-copy-id githubstats@144.76.39.53\nssh githubstats@144.76.39.53\n\nVPS system admin \n\nref(user-config): https://www.digitalocean.com/community/tutorials/how-to-use-git-to-manage-your-user-configuration-files-on-a-linux-vps\n\n Advanced File System\n\nCopying, moving, and merging files\n\ncopy without subfolders\nfind worker-1/data/db/* -type f -exec cp {} dataallRandom-Net/ \\;\n\npython integratedatabases.py --src ~/dataALL/* --dest ~/COMBINED.db\n\nData files: moving\n\nmerge\nrsync -aP worker-1/data/db/* data_all/\nrsync -aP worker-2/data/db/* data_all/\n\nCopy files to remote server\n\nscp file.txt remoteusername@ipaddress:/remote/directory\nscp file.txt jason@10.10.0.2:/remote/directory\nscp remoteusername@hostname:/from/directory /to/directory/\nscp jason@hetzner.com:/mnt/jason/file.xml /Users/jason/Desktop/\n\n Find files, directories, commands, and applications\n\nThis another topic that can take a while to learn all of the functionality, but can make your life amazinginly easier in the long run.  Refer back to over time, and reference a few of these tutorials at Digital Ocean and Binary Tides.\n\nfiles, dir\nfind .\nfind location comparison-criteria \"search-term\"\nfind path -type f,d -maxdepth 2 -iname \"nameignorecase\" ! -iname \"or_name\"\nfind / -ipath \"pathignorecase\"\nfind / -lname \"symbolic_link\"\nfind / -regex \"namebyregex\"\nfind files and remove them\nfind . -maxdepth 1 -type d -name \"feature-*\" -exec rm -rf {} \\;\ncheck everywhere\nlocate filename\ncommands\nhistory | grep ssh\napplication binaries\nwhereis -b application\n\n Find files that contain matching text\n\nSearching among millions of files for specific text is a very powerful feature.  Be sure to include this in your daily habits and it will be a live-saver for some future endeavor.  \n\ngrep -rnw '/path/to/somewhere/' -e 'pattern'\n\n-r or -R is recursive\n -n line number\n-w match the whole word\n -i ignore case\n-l (lower-case L) can be added to just give the file name of matching files\n\nAlong with these, --exclude, --include, --exclude-dir flags could be used for efficient searching:\n\nThis will only search through those files which have .c or .h extensions:\n\n    grep --include=\\*.{c,h} -rnw '/path/to/somewhere/' -e \"pattern\"\n\nThis will exclude searching all the files ending with .o extension:\n\n    grep --exclude=*.o -rnw '/path/to/somewhere/' -e \"pattern\"\n\nFor directories it's possible to exclude a particular directory(ies) through --exclude-dir parameter. For example, this will exclude the dirs dir1/, dir2/ and all of them matching *.dst/:\n\n    grep --exclude-dir={dir1,dir2,*.dst} -rnw '/path/to/somewhere/' -e \"pattern\"\n\n Perform command on multiple files\n\nThere are two ways you can apply the same command across multiple files.  The first is a one-liner using find with -exec.  The second is using a for loop.  The examples use the following Clojure compilation on a javascript file: java -jar compiler.jar --js filename.js --jsoutputfile newfilename.js\n\nfind and execute\nfind . -name \"*.js\" -exec java -jar compiler.jar --js {} --jsoutputfile new{} \\;\n\ntypical for loop\nfor filename in ./*.js\ndo\n    java -jar compiler.jar --js \"${filename}\" --jsoutputfile \"new${filename}\"\ndone\n\nCompress and archive\n\ncreate zip (automatic compression)\nzip -r desiredfile.zip dirpath\nexclude file from zip\nzip desiredfile.zip -r dirpath -x *.file_extension\nadd to existing zip\nzip -r existing_file.zip path/to/dir\ntar compress, maintains folder structure\ntar -czvf desiredtarfile dir_path\nlist files\ntar -tf tarfilename\nuncompress, extract\ntar -xzvf tarball_file\n\n Delete and trash (safe-delete)\n\nrm file\nsudo apt-get install trash-cli\ntrash file\ntrash-list\ntrash-restore file\ntrash-empty\n\nProcessing Files\n\nThis subject is quite popular after the big data and data science movement.  Being able to work with files as they exist on the file system, without bringing them into a memory-hungry processing environment, such as R or Python, can be a life-saver.\n\nThese are a few popular resources for learning more:\nData science tools for the command line\nbook: Data science at the command line\n\n Count files in dir\n\necho 'Files: '; ls -1q ./* | wc -l\necho 'Files in subs'; find . -type f | wc -l\n\nData files: summarizing\n\ncheck number of lines\n! wc -l Data/taxi/greentripdata2015-09.csv\ncheck first few lines\n! head -n3 Data/taxi/greentripdata2015-09.csv\n\n Regex\n\nenv | grep -i User\n\nTools\n\nFor YAML, use shyaml.\nFor Amazon S3, s3cmd is convenient and s4cmd is faster. Amazon's aws and the improved saws are essential for other AWS-related tasks.\n\njq - sed for JSON; For interactive use, also see jid and jiq\njson2csv - convert JSON to CSV\ncsvkit - suite of utilities for working with CSV; provides in2csv, csvcut, csvjoin, csvgrep, etc.\nscrape - HTML extraction using XPath or CSS selectors\nxml2json - convert XML to JSON\n\n Version Control and Github\n\nThe awesome github page provides a good understanding of the functionality that made Github the universal repo site for public source code projects.  Its private couterpart is an emulation named Gitlab.\n\nGit\ngit checkout HEAD -- my-file.txt\ngit push origin --delete branch_name\ngit branch -d branch_name\ngit remote set-url origin https://someurl/somerepo\n\ngit reset --hard\ngit clean -f -d\n\n Conclusion\n\nThis post is more of a cheatsheet and summary than it is for learning.  Each individual subject could be expounded upon in a book.  The reader can use this to gain a superficial understanding and have some commands to try.  After learning more about the details, it can be referenced for a quick review.\n",
        "tags": [
            "commandline",
            "tag2",
            "tag3"
        ]
    },
    {
        "uri": "/posts/blog_datastore-elasticsearch",
        "title": "Simple, Scalable, and Responsive Data Retrieval with ElasticSearch",
        "content": "\n\nDistributed systems are very popular tools in the 'big data' market space and ElasticSearch evolved to become one of the major players.  It serves the niche role of scaling to store large amounts of data, then allows querying it quickly.  It evolved greatly over the last ten years to provide a variety of functionality.  While it serves its primary purpose well, teams should resist the urge to use it in other roles, such as advanced analytics.\n\nTool Characteristics\n\n Strengths\n\nElasticSearch is a Java, Lucene-based, tool that queries large, unstructured data very quickly.  It can be deployed using docker and offers just a simple http endpoint for interaction.\n\nIn the realm of 'big data' it provides much the expected functionality.  Because is distributed it has great ability to scale horizontally.  The data is also replicated, automatically, in case of server node failure.\n\nElasticSearch can execute complex queries very quickly.  This is because it indexes all data.  Part of its speed is that it caches many of the queries used as a filter, so it only executes them once.  This is performed with support for all commonly-used data types, such as Text (structured and unstructured, Numbers (long, integer, short, byte, double, float), Dates, as well as complex types such as: arrays, objects, nested types, geo-spatial, iPV4 and others.\n\nAdditional functionality is provided through a variety of plugins. This supports scenarios for great security and analysis.\n\nWeaknesses\n\nDespite these strengths, Elasticsearch has drawbacks that are quite similar to other 'big data' tools.  Particularly, it is great with data search and recovery, but not for creating and modifying data.  MongoDb is still popular for unstructured transactional data.  \n\nElasticSearch is a type of data warehousing paradigm, not a database replacement.  Specifically, the Elastic company, with its many related products, really grew in size when it was applied to logging and log search problems.  The last decade saw a growing demand for analysts to be able to search the large amounts of metadata created by machines.\n\nElastic attempted to make in-roads as an analytics and data science platform.  This is a dangerous road for teams to go down.  While it can retrieve data, specifically in time-series scenarios, ElasticSearch is an unstructured-only tool.  \n\nData science demands structure in the final stages of modeling.  The balance of working with structured and unstructured data is handled very well by Apache Spark's RDD's and DataFrames.  ElasticSearch has no such complimentary models.  The most sophisticated role it can handel is the analyst answering basic business questions. \n\nAnother difficulty is the major breakages that occur between versions.  For a fast-moving team, keeping up-to-date with the latest ElasticSearch can be a big obstacle.\n\n Installation\n\nElasticSearch can be quickly deployed on a single node using docker.  One requirement is the vm.maxmapcount kernel setting needs to be set to at least 262144 for production use. \n\nget the container running\ndocker run -d -p 9200:9200 -p 9300:9300 -e \"discovery.type=single-node\" --name cntr_elastic docker.elastic.co/elasticsearch/elasticsearch:7.0.1\n\nenter container to check-out configs            \ndocker exec -it --user root cntr_elastic bash\n\nThe configuration is loaded from files under /usr/share/elasticsearch/config/.\n\nSome configurations that may need changing in elasticsearch.yml:\n\ncluster.name: \"docker-cluster\"\npath.logs: /path/to/logs\ndiscovery.zen.ping.unicast.hosts: [\"localhost\"]\n\nTo install directly on MacOS it is simple enough.  Afterward, make appropriate updates to ~/.bash_profile.\n\nbrew install elasticsearch\n\nCheck that node es01 listens on localhost:9200 while es02 talks to es01 over a Docker network.\n\nNOTE: because we are running these curl command from within docker, and they must reach the host's ip address, then when must use host.docker.internal for the ip address (since the host is a MacOS).  Read more about your host's ip address by referencing this stackoverflow post.\n\n! curl http://host.docker.internal:9200/_cat/health\n\n{{ output }}\n1559051160 13:46:00 docker-cluster green 1 1 0 0 0 0 0 0 - 100.0%\n{{ /output }}\n\nOperation\n\n Typical command syntax\n\nAll commands follow similar pattern:\n\nHTTP Verb /Index/Endpoint/ID\n\nExplore cluster\n\nGet health of the cluster:\n\nGreen - everything is good (cluster is fully functional)\nYellow - all data is available but some replicas are not yet allocated (cluster is fully functional)\nRed - some data is not available for whatever reason (cluster is partially functional) \n\n! curl -X GET \"host.docker.internal:9200/_cat/health?v\"\n\n{{ output }}\nepoch      timestamp cluster        status node.total node.data shards pri relo init unassign pendingtasks maxtaskwaittime activeshardspercent\n1559051178 13:46:18  docker-cluster green           1         1      0   0    0    0        0             0                  -                100.0%\n{{ /output }}\n\nList the available nodes\n\n! curl -X GET \"host.docker.internal:9200/_cat/nodes?v\"\n\n{{ output }}\nip         heap.percent ram.percent cpu load1m load5m load_15m node.role master name\n172.17.0.3           31          31  16    0.33    0.25     0.14 mdi       *      fa57091880ec\n{{ /output }}\n\nList indices being used\n\n! curl -X GET \"host.docker.internal:9200/_cat/indices?v\"\n\n{{ output }}\nhealth status index uuid pri rep docs.count docs.deleted store.size pri.store.size\n{{ /output }}\n\nCreate a new index: customer, and use pretty-print in json.\n\nThere is now one index named customer and it has one primary shard and one replica (the defaults) and it contains zero documents in it\n\n! curl -X PUT \"host.docker.internal:9200/customer?pretty\"\n\n{{ output }}\n{\n  \"acknowledged\" : true,\n  \"shards_acknowledged\" : true,\n  \"index\" : \"customer\"\n}\n{{ /output }}\n\nAdd(Index) one document, with id of 1\n\nspecific id provided\n\n! curl -X PUT \"host.docker.internal:9200/customer/_doc/1?pretty\" -H 'Content-Type: application/json' -d'{\"name\": \"John Doe\"}'\n\n{{ output }}\n{\n  \"_index\" : \"customer\",\n  \"type\" : \"doc\",\n  \"_id\" : \"1\",\n  \"_version\" : 1,\n  \"result\" : \"created\",\n  \"_shards\" : {\n    \"total\" : 2,\n    \"successful\" : 1,\n    \"failed\" : 0\n  },\n  \"seqno\" : 0,\n  \"primaryterm\" : 1\n}\n{{ /output }}\n\nno id specified\n\n! curl -X POST \"host.docker.internal:9200/customer/_doc?pretty\" -H 'Content-Type: application/json' -d'{\"name\": \"Jane Doe\"}'\n\n{{ output }}\n{\n  \"_index\" : \"customer\",\n  \"type\" : \"doc\",\n  \"id\" : \"K4SymoBhQilF9iEcwe-\",\n  \"_version\" : 1,\n  \"result\" : \"created\",\n  \"_shards\" : {\n    \"total\" : 2,\n    \"successful\" : 1,\n    \"failed\" : 0\n  },\n  \"seqno\" : 1,\n  \"primaryterm\" : 1\n}\n{{ /output }}\n\nQuery the index\n\n! curl -X GET \"host.docker.internal:9200/customer/_doc/1?pretty\"\n\n{{ output }}\n{\n  \"_index\" : \"customer\",\n  \"type\" : \"doc\",\n  \"_id\" : \"1\",\n  \"_version\" : 1,\n  \"seqno\" : 0,\n  \"primaryterm\" : 1,\n  \"found\" : true,\n  \"_source\" : {\n    \"name\" : \"John Doe\"\n  }\n}\n{{ /output }}\n\nDelete the index\n\n! curl -X DELETE \"host.docker.internal:9200/customer?pretty\"\n\n{{ output }}\n{\n  \"acknowledged\" : true\n}\n{{ /output }}\n\n Modify data\n\nAdd(Index) one document, with id of 1\n\nspecific id provided\n\n! curl -X PUT \"host.docker.internal:9200/customer/_doc/1?pretty\" -H 'Content-Type: application/json' -d'{\"name\": \"John Doe\"}'\n\n{{ output }}\n{\n  \"_index\" : \"customer\",\n  \"type\" : \"doc\",\n  \"_id\" : \"1\",\n  \"_version\" : 1,\n  \"result\" : \"created\",\n  \"_shards\" : {\n    \"total\" : 2,\n    \"successful\" : 1,\n    \"failed\" : 0\n  },\n  \"seqno\" : 0,\n  \"primaryterm\" : 1\n}\n{{ /output }}\n\nUpdate document\n\nChange the name and provide a new field\n\n! curl -X POST \"host.docker.internal:9200/customer/_update/1?pretty\" -H 'Content-Type: application/json' -d '{\"doc\": { \"name\": \"Jane Doe\", \"age\": 20  }}'\n\n{{ output }}\n{\n  \"_index\" : \"customer\",\n  \"type\" : \"doc\",\n  \"_id\" : \"1\",\n  \"_version\" : 2,\n  \"result\" : \"updated\",\n  \"_shards\" : {\n    \"total\" : 2,\n    \"successful\" : 1,\n    \"failed\" : 0\n  },\n  \"seqno\" : 1,\n  \"primaryterm\" : 1\n}\n{{ /output }}\n\nIncrement with script\n\n! curl -X POST \"host.docker.internal:9200/customer/update/1?pretty\" -H 'Content-Type: application/json' -d'{\"script\" : \"ctx.source.age += 5\"}'\n\n{{ output }}\n{\n  \"_index\" : \"customer\",\n  \"type\" : \"doc\",\n  \"_id\" : \"1\",\n  \"_version\" : 3,\n  \"result\" : \"updated\",\n  \"_shards\" : {\n    \"total\" : 2,\n    \"successful\" : 1,\n    \"failed\" : 0\n  },\n  \"seqno\" : 2,\n  \"primaryterm\" : 1\n}\n{{ /output }}\n\nDelete the document\n\n! curl -X DELETE \"host.docker.internal:9200/customer/_doc/2?pretty\"\n\n{{ output }}\n{\n  \"_index\" : \"customer\",\n  \"type\" : \"doc\",\n  \"_id\" : \"2\",\n  \"_version\" : 1,\n  \"result\" : \"not_found\",\n  \"_shards\" : {\n    \"total\" : 2,\n    \"successful\" : 1,\n    \"failed\" : 0\n  },\n  \"seqno\" : 3,\n  \"primaryterm\" : 1\n}\n{{ /output }}\n\nRun a Batch process\n\nupdate the first doc, delete the second\nif a single action fails, it will continue to process others\nmay get an error [\\\\n], different for each operating system\n\n! curl -X POST \"host.docker.internal:9200/customer/_bulk?pretty\" -H 'Content-Type: application/json' -d'\\\n{\"index\":{\"_id\":\"1\"}}\\\n{\"name\": \"John Doe\" }\\\n{\"index\":{\"_id\":\"2\"}}'\n\nExplore data\n\nBulk load json, load data file: accounts.json\n\n! curl -H \"Content-Type: application/json\" -XPOST \"host.docker.internal:9200/bank/_bulk?pretty&refresh\" --data-binary \"@./Data/ElasticSearch/accounts.json\";\n\nQuery: uri\n\n! curl -X GET \"host.docker.internal:9200/bank/search?q=*&sort=accountnumber:asc&pretty\"\n\nQuery: body\n\n  \tmore typical and expressive search\n  \t_source is used to select fields\n  \tfrom is 0-based, defaults to 0 \n  \tsize defaults to 10\n\n! curl -X GET \"host.docker.internal:9200/bank/_search\" -H 'Content-Type: application/json' -d'\\\n{\"query\": { \"match_all\": {} },\\\n  \"source\": [\"accountnumber\", \"balance\"],\\\n  \"sort\": [{ \"account_number\": \"asc\" }],\\\n  \"from\": 10,\\\n  \"size\": 1\\\n}'\n\n{{ output }}\n{\"took\":11,\"timedout\":false,\"shards\":{\"total\":1,\"successful\":1,\"skipped\":0,\"failed\":0},\"hits\":{\"total\":{\"value\":1000,\"relation\":\"eq\"},\"maxscore\":null,\"hits\":[{\"index\":\"bank\",\"type\":\"doc\",\"id\":\"10\",\"score\":null,\"source\":{\"accountnumber\":10,\"balance\":46170},\"sort\":[10]}]}}\n{{ /output }}\n\nQuery: where clause\n\nbool must clause specifies AND, all the queries that must be true\nbool should clause for OR\nbool \"must_not\" clause for NONE\n\n! curl -X GET \"host.docker.internal:9200/bank/_search\" -H 'Content-Type: application/json' -d'\\\n{\"query\": {\"bool\": {\"must\": \\\n\t[{ \"match\": { \"address\": \"mill\" } },\\\n\t { \"match\": { \"address\": \"lane\" } }\\\n    ]\\\n}}}'\n\n{{ output }}\n{\"took\":25,\"timedout\":false,\"shards\":{\"total\":1,\"successful\":1,\"skipped\":0,\"failed\":0},\"hits\":{\"total\":{\"value\":1,\"relation\":\"eq\"},\"maxscore\":9.507477,\"hits\":[{\"index\":\"bank\",\"type\":\"doc\",\"id\":\"136\",\"score\":9.507477,\"source\":{\"accountnumber\":136,\"balance\":45801,\"firstname\":\"Winnie\",\"lastname\":\"Holland\",\"age\":38,\"gender\":\"M\",\"address\":\"198 Mill Lane\",\"employer\":\"Neteria\",\"email\":\"winnieholland@neteria.com\",\"city\":\"Urie\",\"state\":\"IL\"}}]}}\n{{ /output }}\n\nQuery: filter clause\n\nget a range of values\nbool query contains a match_all query (the query part) and a range query (the filter part)\n\n! curl -X GET \"host.docker.internal:9200/bank/_search\" -H 'Content-Type: application/json' -d'\\\n{\"query\": {\"bool\": {\"must\": { \"match_all\": {} },\\\n      \"filter\": {\"range\": {\\\n          \"balance\": {\"gte\": 20000, \"lte\": 30000}\\\n          }}\\\n}}}'\n\nFor more specific queries using Aggregations check the docs.\n\n Conclusion\n\nElasticSearch is a powerful tool for a very specific use case of fast data querying.  However, do not attempt over-extend its functional uses. \n\nReferences\n\ndocker configurations\ngettings started guide\n",
        "tags": [
            "elasticsearch",
            "tag2"
        ]
    },
    {
        "uri": "/posts/blog_econ-return_rate",
        "title": "The Cost of Internal Investment",
        "content": "\n\nThere is one question on every economist's mind: Where has inflation gone?  It is imperative to understanding how actors make decisions and allocate limited resources.  The fact that the inflation rate is so low for so long is incredibly disconcerting for many reasons (with the fear of deflation being just one reason).\n\nBecause of low growth and a lack of inflation the US government and Federal Reserve, as well as nearly every nations' central Bank, are pouring fuel onto the economy and getting a paltry return.  Their actions include the usual suspects:\n\ncorporate federal taxes are lowered to competitive rates\nmassive quantitative easing by the Fed\ninterest rates continued lowest of any business cycle (and crying for lower)\n\nDespite all of this, GDP growth is still just below 3%.  However, the singular understandable financial peculiarity to note is incredible stock buybacks by nearly every corporation using the lowered tax rates that was supposed to be used for investment in capital and (dare say it) wage growth.\n\nFrom a personal perspective, individual sales can be quite difficult to make - even for strong products.  For an individual consultant, such as myself, it usually takes 5 to 7 interactions to make a sale.  At each interaction, I have to tell the client something remarkable about technology that can add value to their business, overnight.  After the 7th, I have to stop interaction with the client and let it known they will not get more until a contract is signed.\n\nBut, even firms with strong products, such as financial oversight technology firm Digital Reasoning, can still face headwinds for making sales.  Proof-of-concepts are needed and different corporations have various scorecards for determining a win.  This is for a market-leader that has a near monopoly within financial services.\n\nFrom the customers' perspective, the customer being large retail establishments, why would businesses invest in new capital, or increase worker salaries, or do anything?  Put aside on the complications and mis-alignments associated with executive compensation.  The return on the market can be as high as 20%.  That means, as a business owner, you have to grow your business greater than 20% in order to out-perform stocks.  When is the last time you're business has done that?  What new investment or genius partner can turn an established business into a growth firm?  \n\nThat is what every business is asking.  The stock market (growth firms) is too hot, and has been that way for too long.  Dividends are at an all-time low.  It ruined nearly all pension funds because fixed-income (a required fraction of their portfolio) provided little to no return.  Investing in people (considering a service-based economy) is both risky and expensive - employment taxes are double those of the amount paid on stock.\n\nSo, why is anyone starting a business, investing in their business, or even hiring full-time to maintain their current business? They could be investing in one of the small groups of super-star FANG monopolies which will inevitably acquire any small business that might be of interest.\n",
        "tags": [
            "sales",
            "fed"
        ]
    },
    {
        "uri": "/posts/blog_math-competitive_edge",
        "title": "A Letter to Students: Math is the Basis for Competitive Edge in Every Field",
        "content": "\n\nMath is the greatest tool humans have for solving problems.  However, it is incredibly expensive to get the experience of using it in the real-world.  This is magnified by most teachers, and many university professors, not having any experience applying math anyplace other than academic contexts.  This post shows the author's trying experiences with learning maths in school, as well as the excitement of applying them to solve actual industry problems.\n\nIntroduction\n\nThroughout my youth and young adult life, I had an antagonistic relationship with math.  I was interested in it, especially the geometric, graphical, and other visualizeable aspects.  But, I never truely felt that it was practical.  The problems in exercises often seemed contrived soley to teach some material.  Teachers rarely had experience with real-world problems - their focus was employing teaching practices, not mathematical practices.\n\nIn fact, I saw that most real-world problem solving, typically in business, are initially estimated then refined based on the results.  How many supplies should you order?  Make some assumptions and try a conservative amount.  This is done without much thought of the scientific / engeineering process or abstracting problems to their fundamentals.  The 80% answer is fine, get on with more the 'real' work.  \n\nI also had real antipathy for much of the reptitive exercises that seemed to form math 'teaching'.  If you performed it once, and the mechanics are easily referenced, then where is the value in performing a hundred times?  Surely more conceptually difficult and interesting problems can be investigated, instead.\n\n 'Forming the Problem' is the Problem\n\nMuch of the work I performed in my formative years was managerial, and the extent of simple mathematical concepts used was either credits and debits of accounting, or the cyclical financial metrics.  I felt it was rare to come across a novel problem.  Any problem that wasn't novel could be easily referenced.  So, the more mundane and rote aspects of math I never felt compelled to invest time.\n\nThis all changed when I saw a novel solution to a problem that I didn't know existed.  As a reconnaissance platoon leader, I had to lay-out the emplacement positions for a battery missile intercept system.  This included the radar, command vehicle, generator, and launchers.  Laying out the posts where the vehicles would emplace was the major bottleneck of the deployment.  The bottleneck of laying out posts was determining the distances distances among equipement because the most accurate approach was for a soldier to run toward a direction using one of several measured tapes.  Thousands of soldiers had performed this tasks for decades.  You simply had to drill yourself and comrades to perform faster than other teams.  Or was that the answer?\n\nThe problem was that I wanted to do it faster than everyone else; thereby, winning award, promotion, etc.  And, therein lies the rub: you don't need math if you're simply doing the same thing as was always done before.  But, if you want to do things better, if you want to innovate, or tackle problems not seen before, then you have to be independent.  You must rely on your mathematical foundations because they are the only skills available for abstracting a problem.\n\nIn this situation, the bottleneck was quite obvious.  But, in many circumstances careful investigation must be performed to find 'root-cause'.  In addition, there can be many alternative perspectives to view the problem.  Despite the endemic use of case studies by educational institutions, it is difficult to get experience in forming problems and applying various problem-solving approaches.  The end state demands that you strip-away the extraneous details, and enumerate the fundamental variables useful for modeling the problem.\n\nThe Practical Value of Math\n\nContinuing with the previous scenario, I remembered the simple rule of angle-side-angle for congruent triangles.  Using an M2 Aiming Circle for survey equipment, and accounting for the two angles by using the surveyor, I only needed the height of the soldier to determine congruency when the soldier had achieved the appropriate distance.  Rather than spending time unspooling tangled measure tapes, the soldier simply ran until I told him to stop.  \n\nThe improvement cut time for the entire process by about 60%, my team took first place for the exercise out of six teams.  Most importantly, I found the magic that comes with seeing things from a different perspective and boldly trying something new in otherwise mundane problems.\n\nIn this situation, it was simple to discover the problem, and the geometric solution was available even to elementary students.  But, it is rare to see this process occur in the real-world.  This may be from a lack of intellectul curiosity within individuals.  Many times, organizations have a culture that is hostile to critical-thinking.  Rather, they prefer leaders who are 'men of action' and use 'gut instincts', not the thoughtful analysis of an introvert.\n\nSuch institutions are dying, quickly.  Since the 1960s, several popular movements occured within industry, such as 'six-sigma' and the 'data-driven' firm.  With the advent of the 'Information Revolution', barely an industry exists where mathematical concepts do not fundamentally determine how business performs its basic functions.  This can be seen from the survival curves of insurance, default risk in banking, optimization in logistics, and  risk-return in finance.\n\n The Data Multiplier \n\nBasic mathematical rules are incredibly useful, and they are necessary for ensuring higher-level reasoning is performed, correctly.  But, a primary component in most discovery or empirical learning situations is data.  While collecting data was historically important in the progression of math, it is the fields of probability and statistics that make data the central focus rather than just part of the solution.  \n\nProbabilty is used when the model is known, but the data is not available; while in statistics, the practicioner has data, but desires a useful model.  These two were quickly combined and became necessary for the advancement of all other sciences, in general, and were hotly debated from philosophical perspectives, such as the idea of hypothesis testing.\n\nComputers made difficult computation possible, first.  The linear algebra necessary for regression could take Karl Pearson's large warehouses of female employees, called computers, weeks to complete.  Thirty years ago, these tasks became trivial with the introduction of the personal computer.  Now, with distributed computing, large swaths of data can be both collected and computed to allow investigators to search for patterns that previously had rarely been mentioned by researchers.\n\nThe Importance of Analysis\n\nAlot of people are interested in math, but are discouraged by ideas that seem theoretical or that may be derived through analysis.  These seem impractical and unuseful for the more general problems that they see, everyday.\n\nTo the contrary, careful analysis provides some of the most valuable insights to practical problems because of their simplicity and wide-ranging importance.  Take, for instance, the huge impact Big Data has had on the world.  The reasoning behind the Hadoop distributed ecosystem was simple: if we cannot bring the data to the computations, then take the computations to the data.  But, this simple idea could not be accomplished without proper understanding of math at an analytical level.  Distributed systems make use of the three basic axioms: i) additive, ii) multiplicative, iii) distributive properties of real numbers in order to move map-reduce computations to disparate servers, then bring them back to the user for the final solution.  \n\nIn fact, computer scientists took such ideas to their extreme.  By using propositional logic, the basis of mathematics, researchers created new systems of programming, such as proof logic and lambda calculus.  These fields directly impact programmers in how they perform their craft, and indirectly effect all users of computational systems.\n\n Resources Do Not Determine Progress\n\nWith such tremendous advancements in data and machine learning many people may again feel discouraged that maths are impractical.  Artificial intelligence will solve problems faster than they can be introduced.  Google, Amazon and their ilk have such vast resources that rarely will problems persist long enough for them to become apparent to the individual, much less to contribute to a solution.\n\nThis is absolutely not the case.  As an example, I have a friend who worked on Apple car and has continued research in machine vision for different industries.  He had the opportunity to ride in a Tesla prototype car where the display console showed exactly what the car 'saw' while driving.  This consisted of a video with outlines defining object silouttes and classification predictions for those objects.\n\nBut, what happened when the car drove up the hill to see a giant sky on the road's hoizon?  The same thing that an amateur's machine learning model would see when it encountered data for the first time: total nonsense.  Despite billions being invested in the field's 'best and brightest', the result was little better than that of a novice.\n\nThere are many problems that remain both untackled and unsolved.\n\nConclusion\n\nJust a few decades ago, it was unncessary to think critically about many problems.  But, with the explosion in data availability, most organizations are forced to constantly become more 'data-driven' in order to squeeze every penny from margins.  This can be difficult to see when educational institutions are far-removed from industry.\n\nYoung students do not have experience with real-world problems.  Much worse, most teachers do not have such experience, either.  This chasim probably existed throughout history.  But, in order for youth to have more buy-in to education, the disparity between 'those who do' and 'those of teach' must be bridged.\n",
        "tags": [
            "tag1",
            "tag2",
            "tag3"
        ]
    },
    {
        "uri": "/posts/blog_models-machine_learning",
        "title": "Generalizing the Machine Learning Process",
        "content": "\n\nThis work describes a general approach to follow when performing machine learning (ML) manually, and when automating in a deployment setting.  Unlike a classical statistical analysis, standard machine learning projects typically follow a general and repeatable process.  While the practictioner should be aware of details for each of the steps and the reasons for choosing them, there is much less design-thinking and checking of assumptions that are necessary components of more mathematical modeling fields.  This makes the machine learning process amenable to deployment as a service because automating the re-training and prediction of a model with consistent data is straight-forward programming.\n\nModel Theory\n\nMost of the design-thinking in the ML process is in choosing a variety of models for comparing performance against.  The following three characteristics succinctly describe a ML model.  See here for more explanation.\n\nRepresentation: structural model characteristics\n    name\n    family\n    interpretability\n    type \n        generative / discriminative \n        bias / var\n        fixed- / variable- learner\nEvaluation: functions applied to the structure\n    objective\n    cost\n    loss\nOptimization: algorithms necessary to solve for parameters\n\nIt is also important to understand how the chosen model effects the modeling process\n\nassumptions inherent in representation\nalignment of loss function with project goals\nsources of bias / variance\ndetermination of resource constraints\nenumeration of how over-tuning can occur (regularization)\nunderstanding when manual methods are ineffective 'fiddling' of model implementation parameters\nstatement of strong false assumptions can be better than weak true ones, because they need more data\n\nNote: This should be considered carefully with feature engineering and feature selection to ensure the input transformations align with the model.\n\n The Machine Learning Process\n\nThe following are the general steps taken in the ML Process.  They are similar to many other problem-solving processes, but tailored to ML specifics.  There are a few steps where care should be taken to ensure the process is reasonable.  These are more design-oriented and some research may be necessary depending on the scenario.  \n\nThe practicioner must ensure he is maintaining honesty with the investigation.  One important check is laying-out proper evaluation methods, before implementing them.  This is similar to classical statistics in choosing an accepatable p-value before running the model.  They include selecting evaluation scores and how they should be evaluated.  Another check is on model resource and time requirements.  More sophisticated models need more memory to implement and take a longer time to run.  These are highly dependent on the environment they are deployed to.  These should be determined with the customer, at the beginning.  To learn more read, here for more. \n\nThe categories to be predicted on, and the percent of records used for each in training, is a very important subject.  If your target data is of a much lower percentage amount than the rest (needle-in-haystack / imbalanced data problem), then it should be addressed before separating training and testing data.  The most orthodox and direct way to deal with this problem is to simply resample from the target records, with replacement, for enough times to reach 50% of your data.  However, this is an important area of research and some time should be taken before moving forward in the process.  For more information on imbalanced data, check here.\n\nWhile classical statistics places a strong emphasis on model exploration and ensuring assumptions are met, this is less important in ML.  Instead, much more time should be focused on the features used in the model.  This is mainly in the form of Feature Engineering, which can include several different methodologies, such as Feature Extraction, Feature Selection / Dimensionality Reduction, and Feature Engineering.  Read more about this, here.  \n\nDiscover\n\ndetermine problem and constraints\ndetermine characteristics the problem / scenario dictates on the solution\n    model family\n    acceptable methods of dimensionality reduction and regularization\n    deployment environment\ndecide evaluation\n    primary / secondary evaluation score (ie. accuracy)\n    methods of evaluation (ie. confusion matrix, roc)\n\nCollect and Transform\n\nobtain raw data \n    internal data warehouses\n    external APIs and services\nintegration and cleaning\t\nfilter, aggregate, and query\n\nSummary and Process\n\nexploration\npreparation\n     address balance (classification, anova, etc.)\n     create Train, Validate, Test with split (above)\nconfigure Feature Extraction with feature_union\nconfigure Preprocess and choose model-families with pipeline\n\nBuild\n\ntrain the models\n    apply k-folds CV and grid search with Training set\n    perform on multiple model-families and hyper-parameters\nevaluate models\n    review afore-mentioned confusion matrix, scoring, classifier-threshold, and tests\n    select the best model-family / hyper-parameters\n    apply to Validation set or all of Training set to model-family to parameterize it and set as the final model\nrefine performance\n    debug performance with learning curve, lift chart\n    use Testing set to evaluate final model characteristics\n    export to binary file\n\nDeliver\n\nselect solution\n    design interface most appropriate for using the model\n    automate data integration and pipelines\n    implement model in deployable environment\ndeploy solution within system environments\n\nNote: Train, Validate, and Test should be from different (independent) data sets, if possible.\n\nStakeholder Interaction and Timeline\n\nIt is useful to display these in relation to interactions that must take place with stakeholders.  These may be business users who need a problem solved, or technology departments that will have to support applications that implement the solution.  The y-axis show stage proximity to these stakeholders.\n\nWhile every project is different, most stages use a similar proportion of time.  The horizontal axis lays-out the timeline.\n\n Demonstation\n\nThe following code demonstrates the programming portions of these stages and steps using a toy example on a simulated diverse dataset of both numeric and categorical data.  It separates the columns and uses transform pipelines to perform different dimensionality reduction techniques. This does display the important steps that must be taken with stakeholders. \n\nConfiguration\n\nNotebook configurations for the kernel and display output.\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\npd.setoption('display.maxrows', 10)\n\n%matplotlib inline\n\nProvide for utility functions.\n\nimport random\nimport string\n\ndef randomString(stringLength=10):\n    \"\"\"Generate a random string of fixed length \"\"\"\n    letters = string.ascii_lowercase\n    return ''.join(random.choice(letters) for i in range(stringLength))\n\nWhile importing modules, try to organize them in the order they are used, and by their parent library.\n\nmodules\nimport pandas as pd\nimport numpy as np\n\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.preprocessing import OneHotEncoder\n\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.preprocessing import StandardScaler\n\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.pipeline import FeatureUnion\n\nfrom sklearn.feature_selection import SelectKBest\nfrom sklearn.decomposition import PCA\n\nfrom sklearn.linear_model import LogisticRegression\n\nfrom sklearn.modelselection import traintest_split\nfrom sklearn.model_selection import KFold\nfrom sklearn.modelselection import crossval_score\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.modelselection import learningcurve\n\nCollect and transform\n\nBring internal and external data, together, for a combined and succinct dataset.  Here, we are simulating both categorical and numeric data for the same dataset.\n\nmake data (both numeric and categorical)\niCOLUMNS = 50\niROWS = 1000\ngenerate classification dataset\nfrom sklearn.datasets.samplesgenerator import makeblobs\nXcat, Ycat = makeblobs(nsamples=iROWS, centers=2, nfeatures=iCOLUMNS, randomstate=1)\ncategories = [randomString(5) for x in range(5)]\ncols = [random.choices(categories, k=iCOLUMNS) for _ in range(iROWS)]\nX_cat = np.array(cols)\n\ngenerate regression dataset\nfrom sklearn.datasets.samplesgenerator import makeregression\nXnum, notused = makeregression(nsamples=iROWS, nfeatures=iCOLUMNS, noise=0.1, randomstate=1)\n\nYour processing is simplified when most of your work is within a dataframe.\n\nset in dataframe\ndfXcat = pd.DataFrame(Xcat, columns=['IndepCat-'+str(x) for x in range(iCOLUMNS)] )\ndfXnum = pd.DataFrame(Xnum, columns=['IndepNum-'+str(x) for x in range(iCOLUMNS)])\ndfYcat = pd.DataFrame(Ycat, columns=[\"Dep\"])\ndfData = pd.concat([dfYcat, dfXcat, dfX_num], axis=1)\n\n Summary and process\n\nEncode your data with transformations in an appropriate order.  Remember that some transformations, such as scaling, should be performed after separation of testing and training datasets because you will be dividing all records by the maximum value, within the dataset.  In model implementation, you would not see the maximum value of your original testing dataset; rather, you would use the current dataset.\n\nseparate\nX = dfData.drop('Dep', axis=1)\ny = dfData['Dep']\n\nencode y and create datasets\nenc = LabelEncoder()\nyset = enc.fittransform(y)\nXtrain, Xtest, ytrain, ytest = traintestsplit(X, yset, testsize=0.2)\n\nprint( \"Training records: %s\"%(X_train.shape[0]) )\nprint( \"Testing records: %s\"%(X_test.shape[0]) )\n\n{{ output }}\nTraining records: 800\nTesting records: 200\n{{ /output }}\n\nHere, you perform scaling, imputation, Principal Component Analysis (PCA), and other transformations whose arguments are dependent upon the same dataset.\n\nAlso, the transformation pipelines should be divided into numeric and categoric because some transformations, such as PCA, are inappropriate for categoric data.  Instead use methods, such as Select K Best, for dimensionality reduction.\n\nWorking with pipelines can be unwieldly at some times.  For a reference of pipelines, see sklearn docs.\n\ncreate feature union of numeric data\nfeatures = []\nfeatures.append(('pca', PCA()))                    <<<GRID\nfeatures.append(('select_best', SelectKBest()))    #<<<GRID\nnumfeatureeng = FeatureUnion(features)\n\ncreate the preprocessing pipelines for both numeric and categorical data\nnumericfeatures = [x for x in Xtrain.columns if x.split('-')[0]=='IndepNum' ]\nnumeric_transformer = Pipeline(steps=[\n    ('imputer', SimpleImputer(strategy='median')),\n    ('scaler', StandardScaler()),\n    ('numfeatureeng', numfeatureeng)\n])\n\ncategoricalfeatures =  [x for x in Xtrain.columns if x.split('-')[0]=='IndepCat' ]\ncategorical_transformer = Pipeline(steps=[\n    ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n    ('onehot', OneHotEncoder(handle_unknown='ignore')),\n    ('select_best', SelectKBest(k=6))\n])\n\npreprocessor = ColumnTransformer(\n    transformers=[\n        ('num', numerictransformer, numericfeatures),\n        ('cat', categoricaltransformer, categoricalfeatures)])\n\nappend classifier to preprocessing pipeline\nfull prediction pipeline\nclf = Pipeline(steps=[('preprocessor', preprocessor),\n                      ('classifier', LogisticRegression(solver='lbfgs'))])\n\nOptimize your hyper-parameters in a grid search.  You may have to get output for all the pipeline keys to find their names because the notation can become quite lenthy based on the amount of nesting, such as this pipeline displays.\n\nparam_grid = {\n    'preprocessornumimputer__strategy': ['mean', 'median'],\n    'classifier__C': [0.1, 1.0, 10, 100],\n    'preprocessornumnumfeatureengpcan_components': [.75, .80, .85, .90, .95],\n    'preprocessornumnumfeatureengselect_bestk': [5, 7, 9, 11]\n}\ngridClf = GridSearchCV(clf, param_grid, cv=5)\n\n Build\n\nBuild your model through optimizing values over the grid.  This is usually based on stochastic gradient descent, or some other iterative routine.  Convergence may be time-consuming depending on the model you've chosen and the number of parameters and hyper-parameters that must be selected.  NaiveBayes methods can be some of the most costly.  Run more balanced models, first, to get an idea of the parameter space, before trying more costly approaches.  \n\ngridClf.fit(Xtrain, ytrain)\n\n{{ output }}\nGridSearchCV(cv=5, error_score='raise-deprecating',\n       estimator=Pipeline(memory=None,\n     steps=[('preprocessor', ColumnTransformer(njobs=None, remainder='drop', sparsethreshold=0.3,\n         transformer_weights=None,\n         transformers=[('num', Pipeline(memory=None,\n     steps=[('imputer', SimpleImputer(copy=True, fillvalue=None, missingvalues=nan,\n       strategy='median', verbo...enalty='l2', random_state=None, solver='lbfgs',\n          tol=0.0001, verbose=0, warm_start=False))]),\n       fitparams=None, iid='warn', njobs=None,\n       paramgrid={'preprocessornumimputerstrategy': ['mean', 'median'], 'classifierC': [0.1, 1.0, 10, 100], 'preprocessornumnumfeatureengpcan_components': [0.75, 0.8, 0.85, 0.9, 0.95], 'preprocessornumnumfeatureengselectbest__k': [5, 7, 9, 11]},\n       predispatch='2*njobs', refit=True, returntrainscore='warn',\n       scoring=None, verbose=0)\n{{ /output }}\n\nTake the best model with parameters / hyper-parameters from highest grid-search, cross-validation, and apply it to the test data.  This data is simulated and you should be able to perform better than a coin-flip (50%).\n\nprint((\"best logistic regression from grid search: %.3f\"\n       % gridClf.score(Xtest, ytest)))\n\n{{ output }}\nbest logistic regression from grid search: 0.515\n{{ /output }}\n\nGet an idea of the results and parameter space.  Extreme values may indicate over-fitting or some other anomaly is occuring.\n\nCross Validation\nGridSearchCV: Mean cross-validated score of the best_estimator\nSGDClassifier: Returns the mean accuracy on the given test data and labels\nprint(\"Best Score: (CV score=%0.3f)\" % gridClf.bestscore)\nprint(\"\\n\")\nprint(\"Best Parameters\\n %s\" % gridClf.bestparams )\nprint(\"\\n\")\nprint(\"Best Estimator\\n %s\" %  gridClf.bestestimator )\n\n{{ output }}\nBest Score: (CV score=0.484)\n\nBest Parameters\n {'classifierC': 10, 'preprocessornumimputerstrategy': 'mean', 'preprocessornumnumfeatureengpcancomponents': 0.9, 'preprocessornumnumfeatureengselectbest__k': 5}\n\nBest Estimator\n Pipeline(memory=None,\n     steps=[('preprocessor', ColumnTransformer(njobs=None, remainder='drop', sparsethreshold=0.3,\n         transformer_weights=None,\n         transformers=[('num', Pipeline(memory=None,\n     steps=[('imputer', SimpleImputer(copy=True, fillvalue=None, missingvalues=nan, strategy='mean',\n       verbose...enalty='l2', random_state=None, solver='lbfgs',\n          tol=0.0001, verbose=0, warm_start=False))])\n{{ /output }}\n\nA confusion matrix is your basic display of results.  This is for your training data.\n\n Confusion Matrix\nfrom sklearn.metrics import confusion_matrix\nytrainpred = gridClf.predict(X_train)\nprint( \"Confusion matrix: Training\")\nconfusionmatrix(ytrain, ytrainpred)\n\n{{ output }}\nConfusion matrix: Training\n{{ /output }}\n\n{{ output }}\narray([[255, 149],\n       [146, 250]])\n{{ /output }}\n\nThis confusion matrix is for your test data.\n\nypred = gridClf.predict(Xtest)\nprint( \"Confusion matrix: Testing\")\nconfusionmatrix(ytest, y_pred)\n\n{{ output }}\nConfusion matrix: Testing\n{{ /output }}\n\n{{ output }}\narray([[51, 45],\n       [52, 52]])\n{{ /output }}\n\nAfter getting a general feel for the situation, look at the specific performance metrics you set, at the beginning of your problem statement.  Ensure you hold yourself to this standard and do not change the solutions' needs based on current results.  For a complete listing of performance metrics, view the sklearn docs.\n\nTesting\n\npredictions for outcome labels\nPredict class probabilities for X.  The predicted class probabilities of an input sample are computed as the mean predicted\nclass probabilities of the trees in the forest. The class probability of a single tree is the fraction of samples of the same\nclass in a leaf.\nyclassprob = gridClf.predictproba(Xtest)                 called   predict_proba(), for some classifiers\nyprob = np.asarray( [x[1] for x in yclass_prob], dtype=np.float32)\nthreshold = 0                                               # set threshold\nysomedigitpred = (yprob  threshold)\nprint( \"Average training probability: %0.3f\" % np.mean(y_prob) )\n\nroc auc\nfrom sklearn.metrics import rocaucscore\nprint( \"Area Under ROC Curve: %0.3f\" % rocaucscore(ytest, yprob) )\n\n{{ output }}\nAverage training probability: 0.484\nArea Under ROC Curve: 0.492\n{{ /output }}\n\nA variety of different plots can be used to explore model and result performance.  The ROC Curve is one of the most fundamental, but several others are of importance.  Performance graphs are explained in the sklearn docs. \n\nlogy_prob = gridClf.decisionfunction(X_test) \n\nfrom sklearn import metrics\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nplt.figure(0).clf()\n\nLogisticRegression  \nyprob = logy_prob\nfpr, tpr, thresh = metrics.roccurve(ytest, y_prob)\nauc = metrics.rocaucscore(ytest, yprob)\nplt.plot(fpr,tpr,label=\"logistic reg, auc=\"+str(auc))\n\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('Receiver operating characteristic')\nplt.legend(loc=0)\nplt.show()\n\n Deliver\n\nSave the model for future use, especially if you just spent a large amount of time getting the algorithm to converge.\n\nfrom sklearn.externals import joblib\nimport os\n\ncwd = os.getcwd()\nfile_path = cwd+'/Data/project/Models/'\n\nsave the model to disk\nfilename = filepath+'finalizedmodel.sav'\njoblib.dump(gridClf, filename)\n\nImplement the model within the necessary solution system.\n\nin deployment application...\nload the model from disk\nloaded_model = joblib.load(filename)\nresult = loadedmodel.score(Xtest, Y_test)\nprint(result)\n\n Conclusion\n\nIn this work, we provide an orthodox approach to the ML Process.  We list the stages involved and the steps for each, and align these with more traditional modeling and analysis processes.  Demo code runs through the basic ideas.  This code can be modified in order to automate processing in a separate environment, such as a deployed service.  The complete process can be generalized to many situations.\n\n: Column Transformer with Mixed Types\n",
        "tags": [
            "machine-learning",
            "best-practice"
        ]
    },
    {
        "uri": "/posts/blog_nlp-explain_metrics",
        "title": "Explaining Difficult (Abstract) Subjects to Customers",
        "content": "\n\nStakeholders want to understand what you are selling and how your approach is different.  However, the level of detail they want varies greatly among your different customers.  A simple whitepaper can be useful enough, in most situations.  But, occaisionally, a layman will want to know exactly what you are doing and will not be content until you very succinctly explain it to them.  This post will explain two methods for approaching such obstacles.\n\nIntroduction\n\nThere are many types of customers and stakeholders that may be encoutered while selling analytics solutions.  Most non-technical stakeholders do not have the time or inclination for the details of analytics.  They may have a colleague or subject matter expert discuss your approach during initial interactions.  However, some parties have a real desire to understand what you are doing.  They may also see it as a test of your abilities that you can explain difficult concepts in a way that they can understand.  \n\nIn any case, their time is limited.  You will have to make your case clearly and succinctly; otherwise, they quickly lose patience and you lose your opportunity.  Two typical failures occur with the too-technical and not-technical-enough approaches.  Both of these outcomes are due to a lack of preparation.\n\nIn the too-technical case, the presenter loses perspective of the forest while getting lost in the trees.  This is common when multi-tasking.  Moments after implementing a difficult programming solution, a data scientist is asked to join a call with a customer.  The scientist has little background on who it is they are engaging, and their mind is working at the same level of detail they were just programming - a recipe for disaster.  The scientist gets muddeled in tangents, and the customer never gets a straight answer.  It finally ends, long-overdue, with the customer frustrated and having little interest in future conversations.\n\nThe opposite happens when a seller is caught off-guard with some difficult questions.  Despite the firm's large investment educating the seller with strong fundamentals, the seller cannot be an expert.  The customer asks some technical questions, incorrectly, or using strange jargon.  Instead of deferring to an expert, the seller presses on, but cannot pary the customers' inquiries.  After some stammering, the customer feels they ferreted out an imposter.  Getting their attention, again, will take time.\n\nThese are painful experiences to undergo.  With preparation using the methods, below, the situation will occur much less frequently.\n\n Methodologies\n\nThe methodologies are best presented using examples.  There are many complicated subjects in the analytics field, but one of the most common is evaluating a solution.  Is your solution a good one?  Is it better than a competitor's solution?  Why is your method of evaluation correct?  This is just a taste of the rapid-fire inquisition that will take place. \n\nIn this NLP scenario, you will need to explain what you are doing, and why it makes sense.  The conclusion of the scenario is that an appropriate balance between precision and recall is necessary for a well-performing model.  \n\nIt is important to remember that the customer is not your advesary.  That may be difficult to believe.  A good basic assumption is that the customer spends the majority of their day looking at powerpoint and has a strong belief that '100%' within a green circle is the only correct answer to any question.\n\nThese methods can take considerable time to iterate on the presentation in order to reach the correct balance.\n\nGolden phrase method\n\nThe purpose of finding the Golden Phrase is that it instantly makes abstract concepts transparent.  There are two difficulties: discovering a good phrase, and ensuring it is universally accepted.  Discovering a good phrase requires careful thought to create ideas and alot of repitiion trying them with customers.  It is important not to anchor on your first phrases; instead, keep brainstorming and allow customers to tell you what is correct by reacting to your words.  It can be very difficult to view the world from their perspective, and to believe you know better than them is the greatest folly.\n\nAfter discovering some phrases where customers do have 'Eureka' moments, it is important to validate the phrases.  Not only should the phrase be applicable to different customers within a shared market, it should be repeatable with the same customer.  This is surprisingly difficult!  In the provided scenario explaining Precision and Recall, a data scientist gave the phrase, '100% Precision ensures there are no False-Positives, 100% Recall ensures there are no Misses.'  The customer shouted with joy that he understood, completely.  Alas, a week went by and the phrase was used, again, on the same customer.  This time, the customer was dumbfounded and had lost confidence the team's work.  Sometimes, that is how it goes.\n\n Example method\n\nThis straight-forward approach explains exactly what you are doing, and is made clear by performing each of the steps, sequentially, just as it is performed.  The difficutly is that it is just one case, so it may not be the correct balance for some audiences.  This is better used with executives that are content with a cursory understanding of a topic, and don't ask too many questions.\n\nNotice the layout is top to bottom, left to right, in essentially two rows.  This is important for the sequential steps\n\nThe green text matches with the first case of naive threshold\nThe blue text matches with the second case of balanced threshold\nblack text is actual text\ngray text is supporting notes\n\nBaby-steps method\n\nBaby-steps are for audiences who really want to understand what you are doing, but have little to no technical background.  While it is thorough, you skip the gory details.  Baby-steps provide the essence of what is happening in as simple an explanation as possible - but not simpler.\n\nWe perform the process using the following steps:\n\nWe use models to retrieve information within electronic communications\nA model may produce one of four outcomes\nThere are many methods for evaluating a models effectiveness\nPrecision-Recall is the most effective evaluation, for this NLP scenario\nPrecision-Recall have important relationships\nChallenges in improving Precision-Recall\n\n Drill-down method\n\nThis method can be really useful for providing the appropriate detail for many different audiences.  It can be conceived of as an onion.  Additional layers can be peeled-back for greater detail and understanding.  The drawback is that it is very time-consuming to create, and also lengthy in presentation.\n\nAspects for Iterative Improvement\n\nSome presentations are collected and used in case they are of value.  But, others may be the key for clenching a deal.  These important jewels need to be continuously polished, presented, and updated to ensure they are ready for the next deal.\n\nIs the color schema meaningful and distinctive?\nDoes the diagramming tool provide reasonable way to perceive the idea?\nWhat audience is best-/least-suited for the presentation\nWhat supporting notes should we maintain to help explain\n\nWhile using these presentations in practice and with customers, be sure to maintain key phrases that either you or the audience says.  These are triggers that immediately create an ah-ha moment.\n\n Conclusion\n\n",
        "tags": [
            "nlp",
            "precision-recall",
            "tag3"
        ]
    },
    {
        "uri": "/posts/blog_nlp-history_nlp_deep_learn",
        "title": "Historical Background of NLP with Deep Learning",
        "content": "\n\nThe automated linguistic annotation of natural languages kept linguists and computer scientists hard at work for many decades.  This work focused on the syntax of language as well as basic understanding and includes part-of-speech, named entity categorization, and syntatic dependency.  Language meta-data tagging became much more accurate with the introduction of neural network and deep learning models.  Because pairing meta-data with more powerful models is sure to allow for an explosion of new applications, it is important to understand the developments that allowed for the creation of this technology.\n\nThis post explores the development of Deep Learning and Natural Language Processing.  It also highlights strengths and weaknesses for future application. \n\nHistory of Deep Learning\n\nThis section is a summary of an excellent three-part series by Andrey Kurenkov.\n\n Perceptron and ArtificialNNs\n\nNeuron built by Warren McCulloch and Walter Pitts Mcculoch-Pitts, who showed that a neuron model that sums binary inputs and outputs a 1 if the sum exceeds a certain threshold value, and otherwise outputs a 0, can model the basic OR/AND/NOT functions ref. \n\nA psychologist, Rosenblatt conceived of the Perceptron as a simplified mathematical model of how the neurons in our brains operate: it takes a set of binary inputs (nearby neurons), multiplies each input by a continuous valued weight (the synapse strength to each nearby neuron), and thresholds the sum of these weighted inputs to output a 1 if the sum is big enough and otherwise a 0 (in the same way neurons either fire or do not) ref.\n\nHebb put forth the unexpected and hugely influential idea that knowledge and learning occurs in the brain primarily through the formation and change of synapses between neurons - concisely stated as Hebbs Rule:\n\n    When an axon of cell A is near enough to excite a cell B and repeatedly or persistently takes part in firing it, some growth process or metabolic change takes place in one or both cells such that As efficiency, as one of the cells firing B, is increased.\n\nMultiple outputs can be learned by having multiple Perceptrons in a layer, such that all these Perceptrons receive the same input and each one is responsible for one output of the function. Indeed, neural nets (or, formally, Artificial Neural Networks - ANNs) are nothing more than layers of Perceptrons.  Only one of the 10 neurons output 1, the highest weighted sum is taken to be the correct output, and the rest output 0.  Finding the right weights using the derivatives of the training error with respect to each weight is exactly how neural nets are typically trained to this day.\n\nMinsky and Paperts 1969 analysis of Perceptrons did not merely show the impossibility of computing XOR with a single Perceptron, but specifically argued that it had to be done with multiple layers of Perceptrons. \n\nAI Winter 1, 1969, multiple layers are necessary for practical usefulness, but no obvious approach for doing this.\n\nHidden layer networks\n\nThe reason hidden layers are good, in basic terms, is that the hidden layers can find features within the data and allow following layers to operate on those features rather than the noisy and large raw data.  Similar to Feature Extraction in machine learning.  \n\nHow to get weights for these hidden layers?  Calculus' Chain Rule - The key realization was that if the neural net neurons were not quite Perceptrons, but were made to compute the output with an activation function that was still non-linear but also differentiable, as with Adaline, not only could the derivative be used to adjust the weight to minimize error, but the chain rule could also be used to compute the derivative for all the neurons in a prior layer and thus the way to adjust their weights would also be known.\n\nAssign some error to the Output Layer, then some to Hidden Layer before it, and Hidden Layer before it - backpropagate the error.  Werbos stated it in his 1974 PHD thesis, but did not publish on the application of backprop to neural nets until 1982.  Learning internal representations by error propagation , specifically addressed the problems discussed by Minsky in Perceptrons. \n\nMultilayer feedforward networks are universal approximators mathematically proved that multiple layers allow neural nets to theoretically implement any function, and certainly XOR.\n\n Convolutional networks\n\nYann LeCun et al. at the AT&T Bell Labs demonstrated a very significant real-world application of backpropagation in classifying handwritten numbers for USPS in \"Backpropagation Applied to Handwritten Zip Code Recognition\".\n\nThe first hidden layer of the neural net was convolutional - instead of each neuron having a different weight for each pixel of the input image (40x60=2400 weights), the neurons only have a small set of weights (5x5=25) that were applied a whole bunch of small subsets of the image of the same size.  a single neuron could learn to detect 45 degree lines on subsets of the image and do that everywhere within it.\n\nMoreover, since the pixel-exact locations of such features do not matter the neuron could basically skip neighboring subsets of the image - subsampling, now known as a type of pooling - when applying the weights, further reducing the training time. \n\nThe addition of Convolutional and Pooling layers distinguishes CNNs from NNs.\n\nMore developments\nauto-encoders - heres another neat thing you can do with neural nets: approximate probability distributions.\nBoltzmann Machine formulation - leads to a domain-independent learning algorithm that modifies the connection strengths between units in such a way that the whole network develops an internal model which captures the underlying structure of its environment. \nHelmholtz Machine - have separate sets of weights for inferring hidden variables from visible variables (recognition weights) and vice versa (generative weights) allows training to be done faster.\n\nSkepticism of neural nets since they seemed so intuition-based and since computers were still barely able to meet their computational needs. \n \nAI Winter 2, 1990, not enough processing or data resources to produce useful results.\n\nRecurrent CNN with LSTM\n\nref: understanding lstm\n\nTo tackle the problem of understanding speech, researchers sought to modify neural nets to process input as a stream of input as in speech rather than one batch as with an image.\n\nAll the networks that have been discussed so far have been feedforward networks, meaning that the output of neurons in a given layer acts as input to only neurons in a next layer. But, it does not have to be so - there is nothing prohibiting us brave computer scientists from connecting output of the last layer act as an input to the first layer, or just connecting the output of a neuron to itself.\n\nThe answer is backpropagation through time. Basically, the idea is to unroll the recurrent neural network by treating each loop through the neural network as an input to another neural network, and looping only a limited number of times.  But there was a problem.  Although recurrent networks can outperform static networks, they appear more difficult to train optimally. Their parameters settle in a suboptimal solution which takes into account short term dependencies but not long term dependencies.\n\nThe core reason that recurrent nets are more exciting than CNN is that they allow us to operate over sequences of vectors: Sequences in the input, the output, or in the most general case both. \n\nWith many layers the CNN calculus-based splitting of blame ends up with either huge or tiny numbers and the resulting neural net just does not work very well - the vanishing or exploding gradient problem.\n\nIn 1997, LSTM was developed.  Some of the units are called Constant Error Carousels (CECs). Each CEC uses as an activation function f, the identity function, and has a connection to itself with xed weight of 1.0. Due to fs constant derivative of 1.0, errors backpropagated through a CEC cannot vanish or explode (Sec. 5.9) but stay as they are (unless they ow out of the CEC to other, typically adaptive parts of the NN).\n\nAI Winter 3, 1993, SVMs and Random Forests were all the rage.  RNN was slow and difficult.\n\n Deep Learning: big data, parallelism (gpu), and algorithms\n\nIn 2004, Canadian Institute for Advanced Research (CIFAR) decided to rebrand the frowned-upon field of neural nets with the moniker Deep Learning.  In 2006, the paper  was released which provided a way to train weights well, if the weights are initialized in a clever way rather than randomly.  The basic idea is to train each layer, as a Restricted Boltzmann Machine (RBM), one by one with unsupervised training, which starts off the weights much better than just giving them random values, and then finishing with a round of supervised learning just as is normal for neural nets. \n\nYoshua Bengio et al. followed up on this work in 2007 with Greedy Layer-Wise Training of Deep Networks , in which they present a strong argument that deep machine learning methods (that is, methods with many processing steps, or equivalently with hierarchical feature representations of the data) are more efficient for difficult problems than shallow methods (which two-layer ANNs or support vector machines are examples of).  Also, using RBMs is not that important - unsupervised pre-training of normal neural net layers using backpropagation with plain Autoencoders layers proved to also work well. \n\nHinton used these methods on standard speech recognition dataset because ML had already performed so well on MNIST.  They did this using GPUs over CPUs and the paper Large-scale Deep Unsupervised Learning using Graphics Processors \nshows and improvement in training of 70 times faster. \n\nAndrew Ng's work with Google Brain led an effort to build truly giant neural nets and explore what they could do. The work resulted in unsupervised neural net learning of 16,000 CPU cores powering the learning of 1 billion weights.\n\nWhy didn't supervised learning with backpropagation not work well in the past? Geoffrey Hinton summarized the findings up to today in these four points:\n\nOur labeled datasets were thousands of times too small.\nOur computers were millions of times too slow.\nWe initialized the weights in a stupid way.\nWe used the wrong type of non-linearity.\n\nAdditional Improvements\n\nOld methods: \n\npooling layers\nconvolution layers\nvariations on the input data\n\nused with new methods:\n\ngpu usage - for improved computation\nactivation function - less intuitive approach, such as ReLU, can be most useful\ndropout - to prevent overfitting, randomly pretend some neurons are not there while training\n\n History of NLP\n\nref: comparison of NLP frameworks\nref: comparison of NLP with image analysis\n\nSince introduction of word vectors, the standard way of conducting NLP projects has largely remained unchanged: word embeddings pretrained on large amounts of unlabeled data via algorithms such as word2vec and GloVe are used to initialize the first layer of a neural network, the rest of which is then trained on data of a particular task.  The downside is that previous knowledge is only used in the first layer.  It does not acquire meaning from a sequence of words. \n\nAt the core of the recent advances of ULMFiT, ELMo, and the OpenAI transformer is one key paradigm shift: going from just initializing the first layer of our models to pretraining the entire model with hierarchical representations.\n\n\"ImageNet for language\"---that is, a task that enables models to learn higher-level nuances of language, similarly to how ImageNet has enabled training of CV models that learn general-purpose features of images.  In 2012, the deep neural network submitted by Alex Krizhevsky, Ilya Sutskever, and Geoffrey Hinton performed 41% better than the next model in the ImageNet Large Scale Visual Recognition Challenge (ILSVRC). It also enabled transfer learning through re-use of weights, achieving good performance with as little as one positive example per category (Donahue et al., 2014).  A key property of an ImageNet-like dataset is thus to encourage a model to learn features that will likely generalize to new tasks in the problem domain.  \n\nEmpirical proof: Embeddings from Language Models (ELMo), Universal Language Model Fine-tuning (ULMFiT), and the OpenAI Transformer, that demonstrate how language modeling can be used for pretraining.  These models perform:\n\n10-20% better than the state-of-the-art on widely studied benchmarks\nextremely sample-efficient with only hundreds of examples\n\nIt is very likely that in a years time NLP practitioners will download pretrained language models rather than pretrained word embeddings for use in their own models, similarly to how pre-trained ImageNet models are the starting point for most CV projects nowadays.\n\nOpen question: how to transfer the information from a pre-trained language model to a downstream task?\n\nELMo - use the pre-trained language model as a fixed feature extractor and incorporate its representation as features into a randomly initialized model \nULMFiT - fine-tune the entire language model, typically done in CV where either the top-most or several of the top layers are fine-tuned\n\nThe next months will show the impact of each of the core components of transfer learning for NLP: an expressive language model encoder such as a deep BiLSTM or the Transformer, the amount and nature of the data used for pretraining, and the method used to fine-tune the pretrained model.\n\nWord Embeddings\n\nref: Word embeddings\nref: Word2Vec Tutorial\nref: CBOW and SkipGram Architectures\n\nCBOW: The input to the model could be 2,1,+1,+2, the preceding and following words of the current word we are at. The output of the neural network will be .  Hence you can think of the task as \"predicting the word given its context\".  Note that the number of words we use depends on your setting for the window size.\n\nSkip-gram: The input to the model is , and the output could be 1,2,+1,+2. So the task here is \"predicting the context given a word\". In addition, more distant words are given less weight by randomly sampling them. When you define the window size parameter, you only configure the maximum window size. The actual window size is randomly chosen between 1 and max size for each training sample, resulting in words with the maximum distance being observed with a probability of 1/c while words directly next to the given word are always(!) observed.\n\n Application\n\nTensors and matrices\n\n[ref: difference between tensors and matrices] (https://math.stackexchange.com/questions/412423/what-are-the-differences-between-a-matrix-and-a-tensor412454)\nthe components of a rank-2 tensor can be written in a matrix.\nthe tensor is not that matrix, because different types of tensors can correspond to the same matrix.\nthe differences between those tensor types are uncovered by the basis transformations (hence the physicist's definition: \"A tensor is what transforms like a tensor\").\n\nFastText\n\nref: FastText\n\nBoth the continuous bag of words and the Skip-gram model update the weights for a context of size between a random uniform distribution between 1 and the value determined by -ws, i.e the window size is stochastic.\n\nThe target vector for the loss function is computed via a normalized sum of all the input vectors. The input vectors are the vector representation for the original word, and all the n-grams of that word. The loss is computed which sets the weights for the forward pass, which propagate their way all the way back to the vectors for the input layer in the back propagation pass. This tuning of the input vector weights that happens during the back propagation pass is what allows us to learn representations that maximize co occurrence similarity. The learning rate -lr affects how much each particular instance affects the weights.\n\n[ref: many diff applications of RNN] (https://karpathy.github.io/2015/05/21/rnn-effectiveness/)\n\n Evaluation\n\nevaluation of language modeling\n",
        "tags": [
            "nlp",
            "deeplearning",
            "tag3"
        ]
    },
    {
        "uri": "/posts/blog_nlp-intro_spacy",
        "title": "Processing Natural Language with Python and Friends",
        "content": "\n\nPython is a typical language chosen for Data Science work, and its strengths with strings make it especially useful for working with natural language.  While the nltk library opened-up this work for python users, the newer spacy improves upon processing power by implementing Cython code.  Tests display its power in production when compared with more traditional approaches, such as with Stanford's CoreNLP.  This post is an outline of examples from the spacy coursework and examples.  It also uses nltk for providing datasets.  Additional examples come from:\n\ntutorials\nspacy usage documentation\nlinguistic features\napi documentation\n\nThis tutorial introduces the basics of working with natural languages in python, including the following topics:\n\nExtract linguistic features: part-of-speech tags, dependencies, named entities\nWork with pre-trained statistical models\nFind words and phrases using Matcher and PhraseMatcher match rules\nBest practices for working with data structures Doc, Token Span, Vocab, Lexeme\nFind semantic similarities using word vectors\nWrite custom pipeline components with extension attributes\n\nConfigure Environment\n\nEnsure that spacy is installed.  Language models are also necessary:\n\\\\( python -m spacy download en\\core\\web\\_sm\nor, pip install https://github.com/explosion/spacy-models/releases/download/en\\core\\web\\sm-2.0.0/en\\core\\web\\sm-2.0.0.tar.gz --no-deps\n\\\\) python -m spacy validate\n$ python -m spacy download encoreweb_lg --force\n\nimport numpy as np\n\nfrom spacy.lang.en import English\n\nnlp = English()\n\nimport nltk\nprint( nltk.corpus.gutenberg.fileids())\n\nemma = nltk.corpus.gutenberg.raw('austen-emma.txt')\nemma = emma.replace('\\n',' ')\ndocEmma = nlp(emma)\n\nFinding words, phrases, names and concepts\n\n Documents, spans, and tokens\n\nProcess the text\ndoc = nlp(\"I like tree kangaroos and narwhals.\")\n\n Select the first token\nfirst_token = doc[0]\n\nPrint the first token's text\nprint(first_token.text)\n\n{{ output }}\nI\n{{ /output }}\n\n Process the text\ndoc = nlp(\"I like tree kangaroos and narwhals.\")\n\nA slice of the Doc for \"tree kangaroos\"\ntree_kangaroos = doc[2:4]\nprint(tree_kangaroos.text)\n\n A slice of the Doc for \"tree kangaroos and narwhals\" (without the \".\")\ntreekangaroosand_narwhals = doc[2:6]\nprint(treekangaroosand_narwhals.text)\n\n{{ output }}\ntree kangaroos\ntree kangaroos and narwhals\n{{ /output }}\n\nLexical attributes\n\n Process the text\ndoc = nlp(\"In 1990, more than 60% of people in East Asia were in extreme poverty. \"\n    \"Now less than 4% are.\")\n\nIterate over the tokens in the doc\nfor token in doc:\n     Check if the token resembles a number\n    if token.like_num:\n        # Get the next token in the document\n        next_token = doc[token.i + 1]\n        # Check if the next token's text equals '%'\n        if next_token.text == \"%\":\n            print(\"Percentage found:\", token.text)\n\n{{ output }}\nPercentage found: 60\nPercentage found: 4\n{{ /output }}\n\nContext-specific linguistic attributes (using models)\n\nThe model provides the binary weights that enable spaCy to make predictions.  It also includes the vocabulary, and meta information to tell spaCy which language class to use and how to configure the processing pipeline.  All models include a meta.json that defines the language to initialize, the pipeline component names to load as well as general meta information like the model name, version, license, data sources, author and accuracy figures (if available).  Model packages include a strings.json that stores the entries in the models vocabulary and the mapping to hashes. This allows spaCy to only communicate in hashes and look up the corresponding string if needed.\n\nThe encoreweblg (788 MB) compared to encorewebsm (10 MB):\n\nLAS: 90.07% vs 89.66%\nPOS: 96.98% vs 96.78%\nUAS: 91.83% vs 91.53%\nNER F-score: 86.62% vs 85.86%\nNER precision: 87.03% vs 86.33%\nNER recall: 86.20% vs 85.39%\n\nAll that while encoreweb_lg is 79 times larger, hence loads a lot more slowly.\n\nIn spaCy, attributes that return strings usually end with an underscore (pos_)  attributes without the underscore return an ID.\n\nThe dep_ attribute returns the predicted dependency label.\nThe head attribute returns the syntactic head token. You can also think of it as the parent token this word is attached to.\nThe doc.ents property lets you access the named entities predicted by the model.\n\nmodel package\n$ python -m spacy download encoreweb_sm\n\nload models\nimport spacy\nnlp = spacy.load('encoreweb_sm')\n\ndoc = nlp(\"She ate the pizza\")\n\niterate over the tokens\nfor token in doc:\n    print the text and the predicted part-of-speech tag\n    print(token.i, token.text, token.pos_)\n\n{{ output }}\n0 She PRON\n1 ate VERB\n2 the DET\n3 pizza NOUN\n{{ /output }}\n\nsyntatic dependency\nfor token in doc:\n    print(token.text, token.pos, token.dep, token.head.text)\n\n{{ output }}\nShe PRON nsubj ate\nate VERB ROOT ate\nthe DET det pizza\npizza NOUN dobj ate\n{{ /output }}\n\nprocess a text\ndoc = nlp(u\"Apple is looking at buying U.K. startup for $1 billion\")\n\nIterate over the predicted entities\nfor ent in doc.ents:\n     Print the entity text and its label\n    print(ent.text, ent.label_)\n\n{{ output }}\nApple ORG\nU.K. GPE\n$1 billion MONEY\n{{ /output }}\n\nfor tok in doc:\n    print( tok.text, tok.enttype, end=\" \")\n\n{{ output }}\nApple ORG is  looking  at  buying  U.K. GPE startup  for  $ MONEY 1 MONEY billion MONEY \n{{ /output }}\n\ncommon tags and labels\nprint( spacy.explain('GPE') )\nprint( spacy.explain('NNP') )\nprint( spacy.explain('dobj') )\n\n{{ output }}\nCountries, cities, states\nnoun, proper singular\ndirect object\n{{ /output }}\n\nimport spacy\nfrom spacy import displacy\nnlp = spacy.load(\"encoreweb_sm\")\ndoc1 = nlp(\"This is a sentence.\")\ndoc2 = nlp(\"This is another sentence.\")\ndisplacy.render([doc1, doc2], style=\"dep\")\n\nsvg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"en\" id=\"98185150183a41159336f6bbe30e0f1c-0\" class=\"displacy\" width=\"750\" height=\"312.0\" direction=\"ltr\" style=\"max-width: none; height: 312.0px; color: 000000; background: #ffffff; font-family: Arial; direction: ltr\"\ntext class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\"\n    tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\"This/tspan\n    tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\"DET/tspan\n/text\n\ntext class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\"\n    tspan class=\"displacy-word\" fill=\"currentColor\" x=\"225\"is/tspan\n    tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"225\"AUX/tspan\n/text\n\ntext class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\"\n    tspan class=\"displacy-word\" fill=\"currentColor\" x=\"400\"a/tspan\n    tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"400\"DET/tspan\n/text\n\ntext class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\"\n    tspan class=\"displacy-word\" fill=\"currentColor\" x=\"575\"sentence./tspan\n    tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"575\"NOUN/tspan\n/text\n\ng class=\"displacy-arrow\"\n    path class=\"displacy-arc\" id=\"arrow-98185150183a41159336f6bbe30e0f1c-0-0\" stroke-width=\"2px\" d=\"M70,177.0 C70,89.5 220.0,89.5 220.0,177.0\" fill=\"none\" stroke=\"currentColor\"/\n    text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\"\n        textPath xlink:href=\"#arrow-98185150183a41159336f6bbe30e0f1c-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\"nsubj/textPath\n    /text\n    path class=\"displacy-arrowhead\" d=\"M70,179.0 L62,167.0 78,167.0\" fill=\"currentColor\"/\n/g\n\ng class=\"displacy-arrow\"\n    path class=\"displacy-arc\" id=\"arrow-98185150183a41159336f6bbe30e0f1c-0-1\" stroke-width=\"2px\" d=\"M420,177.0 C420,89.5 570.0,89.5 570.0,177.0\" fill=\"none\" stroke=\"currentColor\"/\n    text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\"\n        textPath xlink:href=\"#arrow-98185150183a41159336f6bbe30e0f1c-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\"det/textPath\n    /text\n    path class=\"displacy-arrowhead\" d=\"M420,179.0 L412,167.0 428,167.0\" fill=\"currentColor\"/\n/g\n\ng class=\"displacy-arrow\"\n    path class=\"displacy-arc\" id=\"arrow-98185150183a41159336f6bbe30e0f1c-0-2\" stroke-width=\"2px\" d=\"M245,177.0 C245,2.0 575.0,2.0 575.0,177.0\" fill=\"none\" stroke=\"currentColor\"/\n    text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\"\n        textPath xlink:href=\"#arrow-98185150183a41159336f6bbe30e0f1c-0-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\"attr/textPath\n    /text\n    path class=\"displacy-arrowhead\" d=\"M575.0,179.0 L583.0,167.0 567.0,167.0\" fill=\"currentColor\"/\n/g\n/svg\n\nsvg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"en\" id=\"98185150183a41159336f6bbe30e0f1c-1\" class=\"displacy\" width=\"750\" height=\"312.0\" direction=\"ltr\" style=\"max-width: none; height: 312.0px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\"\ntext class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\"\n    tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\"This/tspan\n    tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\"DET/tspan\n/text\n\ntext class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\"\n    tspan class=\"displacy-word\" fill=\"currentColor\" x=\"225\"is/tspan\n    tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"225\"AUX/tspan\n/text\n\ntext class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\"\n    tspan class=\"displacy-word\" fill=\"currentColor\" x=\"400\"another/tspan\n    tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"400\"DET/tspan\n/text\n\ntext class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\"\n    tspan class=\"displacy-word\" fill=\"currentColor\" x=\"575\"sentence./tspan\n    tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"575\"NOUN/tspan\n/text\n\ng class=\"displacy-arrow\"\n    path class=\"displacy-arc\" id=\"arrow-98185150183a41159336f6bbe30e0f1c-1-0\" stroke-width=\"2px\" d=\"M70,177.0 C70,89.5 220.0,89.5 220.0,177.0\" fill=\"none\" stroke=\"currentColor\"/\n    text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\"\n        textPath xlink:href=\"#arrow-98185150183a41159336f6bbe30e0f1c-1-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\"nsubj/textPath\n    /text\n    path class=\"displacy-arrowhead\" d=\"M70,179.0 L62,167.0 78,167.0\" fill=\"currentColor\"/\n/g\n\ng class=\"displacy-arrow\"\n    path class=\"displacy-arc\" id=\"arrow-98185150183a41159336f6bbe30e0f1c-1-1\" stroke-width=\"2px\" d=\"M420,177.0 C420,89.5 570.0,89.5 570.0,177.0\" fill=\"none\" stroke=\"currentColor\"/\n    text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\"\n        textPath xlink:href=\"#arrow-98185150183a41159336f6bbe30e0f1c-1-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\"det/textPath\n    /text\n    path class=\"displacy-arrowhead\" d=\"M420,179.0 L412,167.0 428,167.0\" fill=\"currentColor\"/\n/g\n\ng class=\"displacy-arrow\"\n    path class=\"displacy-arc\" id=\"arrow-98185150183a41159336f6bbe30e0f1c-1-2\" stroke-width=\"2px\" d=\"M245,177.0 C245,2.0 575.0,2.0 575.0,177.0\" fill=\"none\" stroke=\"currentColor\"/\n    text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\"\n        textPath xlink:href=\"#arrow-98185150183a41159336f6bbe30e0f1c-1-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\"attr/textPath\n    /text\n    path class=\"displacy-arrowhead\" d=\"M575.0,179.0 L583.0,167.0 567.0,167.0\" fill=\"currentColor\"/\n/g\n/svg\n\nimport spacy\nfrom spacy import displacy\nnlp = spacy.load(\"encoreweb_sm\")\n\noptions = {\"compact\": True, \"bg\": \"#09a3d5\",\"color\": \"white\", \"font\": \"Source Sans Pro\"}\n\ntext = \"\"\"In ancient Rome, some neighbors live in three adjacent houses. In the center is the house of Senex, who lives there with wife Domina, son Hero, and several slaves, including head slave Hysterium and the musical's main character Pseudolus.\"\"\"\ndoc = nlp(text)\nsentence_spans = list(doc.sents)\ndisplacy.render(sentence_spans, style=\"dep\", options=options, jupyter=True)\n\nsvg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"en\" id=\"c2baa64957a84bfb9ce5180baa2e949c-0\" class=\"displacy\" width=\"1550\" height=\"437.0\" direction=\"ltr\" style=\"max-width: none; height: 437.0px; color: white; background: #09a3d5; font-family: Source Sans Pro; direction: ltr\"\ntext class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"347.0\"\n    tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\"In/tspan\n    tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\"ADP/tspan\n/text\n\ntext class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"347.0\"\n    tspan class=\"displacy-word\" fill=\"currentColor\" x=\"200\"ancient/tspan\n    tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"200\"ADJ/tspan\n/text\n\ntext class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"347.0\"\n    tspan class=\"displacy-word\" fill=\"currentColor\" x=\"350\"Rome,/tspan\n    tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"350\"PROPN/tspan\n/text\n\ntext class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"347.0\"\n    tspan class=\"displacy-word\" fill=\"currentColor\" x=\"500\"some/tspan\n    tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"500\"DET/tspan\n/text\n\ntext class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"347.0\"\n    tspan class=\"displacy-word\" fill=\"currentColor\" x=\"650\"neighbors/tspan\n    tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"650\"NOUN/tspan\n/text\n\ntext class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"347.0\"\n    tspan class=\"displacy-word\" fill=\"currentColor\" x=\"800\"live/tspan\n    tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"800\"VERB/tspan\n/text\n\ntext class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"347.0\"\n    tspan class=\"displacy-word\" fill=\"currentColor\" x=\"950\"in/tspan\n    tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"950\"ADP/tspan\n/text\n\ntext class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"347.0\"\n    tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1100\"three/tspan\n    tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1100\"NUM/tspan\n/text\n\ntext class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"347.0\"\n    tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1250\"adjacent/tspan\n    tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1250\"ADJ/tspan\n/text\n\ntext class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"347.0\"\n    tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1400\"houses./tspan\n    tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1400\"NOUN/tspan\n/text\n\ng class=\"displacy-arrow\"\n    path class=\"displacy-arc\" id=\"arrow-c2baa64957a84bfb9ce5180baa2e949c-0-0\" stroke-width=\"2px\" d=\"M62,302.0 62,202.0 800.0,202.0 800.0,302.0\" fill=\"none\" stroke=\"currentColor\"/\n    text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\"\n        textPath xlink:href=\"#arrow-c2baa64957a84bfb9ce5180baa2e949c-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\"prep/textPath\n    /text\n    path class=\"displacy-arrowhead\" d=\"M62,304.0 L58,296.0 66,296.0\" fill=\"currentColor\"/\n/g\n\ng class=\"displacy-arrow\"\n    path class=\"displacy-arc\" id=\"arrow-c2baa64957a84bfb9ce5180baa2e949c-0-1\" stroke-width=\"2px\" d=\"M212,302.0 212,277.0 341.0,277.0 341.0,302.0\" fill=\"none\" stroke=\"currentColor\"/\n    text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\"\n        textPath xlink:href=\"#arrow-c2baa64957a84bfb9ce5180baa2e949c-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\"amod/textPath\n    /text\n    path class=\"displacy-arrowhead\" d=\"M212,304.0 L208,296.0 216,296.0\" fill=\"currentColor\"/\n/g\n\ng class=\"displacy-arrow\"\n    path class=\"displacy-arc\" id=\"arrow-c2baa64957a84bfb9ce5180baa2e949c-0-2\" stroke-width=\"2px\" d=\"M62,302.0 62,252.0 344.0,252.0 344.0,302.0\" fill=\"none\" stroke=\"currentColor\"/\n    text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\"\n        textPath xlink:href=\"#arrow-c2baa64957a84bfb9ce5180baa2e949c-0-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\"pobj/textPath\n    /text\n    path class=\"displacy-arrowhead\" d=\"M344.0,304.0 L348.0,296.0 340.0,296.0\" fill=\"currentColor\"/\n/g\n\ng class=\"displacy-arrow\"\n    path class=\"displacy-arc\" id=\"arrow-c2baa64957a84bfb9ce5180baa2e949c-0-3\" stroke-width=\"2px\" d=\"M512,302.0 512,277.0 641.0,277.0 641.0,302.0\" fill=\"none\" stroke=\"currentColor\"/\n    text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\"\n        textPath xlink:href=\"#arrow-c2baa64957a84bfb9ce5180baa2e949c-0-3\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\"det/textPath\n    /text\n    path class=\"displacy-arrowhead\" d=\"M512,304.0 L508,296.0 516,296.0\" fill=\"currentColor\"/\n/g\n\ng class=\"displacy-arrow\"\n    path class=\"displacy-arc\" id=\"arrow-c2baa64957a84bfb9ce5180baa2e949c-0-4\" stroke-width=\"2px\" d=\"M662,302.0 662,277.0 791.0,277.0 791.0,302.0\" fill=\"none\" stroke=\"currentColor\"/\n    text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\"\n        textPath xlink:href=\"#arrow-c2baa64957a84bfb9ce5180baa2e949c-0-4\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\"nsubj/textPath\n    /text\n    path class=\"displacy-arrowhead\" d=\"M662,304.0 L658,296.0 666,296.0\" fill=\"currentColor\"/\n/g\n\ng class=\"displacy-arrow\"\n    path class=\"displacy-arc\" id=\"arrow-c2baa64957a84bfb9ce5180baa2e949c-0-5\" stroke-width=\"2px\" d=\"M812,302.0 812,277.0 941.0,277.0 941.0,302.0\" fill=\"none\" stroke=\"currentColor\"/\n    text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\"\n        textPath xlink:href=\"#arrow-c2baa64957a84bfb9ce5180baa2e949c-0-5\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\"prep/textPath\n    /text\n    path class=\"displacy-arrowhead\" d=\"M941.0,304.0 L945.0,296.0 937.0,296.0\" fill=\"currentColor\"/\n/g\n\ng class=\"displacy-arrow\"\n    path class=\"displacy-arc\" id=\"arrow-c2baa64957a84bfb9ce5180baa2e949c-0-6\" stroke-width=\"2px\" d=\"M1112,302.0 1112,252.0 1394.0,252.0 1394.0,302.0\" fill=\"none\" stroke=\"currentColor\"/\n    text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\"\n        textPath xlink:href=\"#arrow-c2baa64957a84bfb9ce5180baa2e949c-0-6\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\"nummod/textPath\n    /text\n    path class=\"displacy-arrowhead\" d=\"M1112,304.0 L1108,296.0 1116,296.0\" fill=\"currentColor\"/\n/g\n\ng class=\"displacy-arrow\"\n    path class=\"displacy-arc\" id=\"arrow-c2baa64957a84bfb9ce5180baa2e949c-0-7\" stroke-width=\"2px\" d=\"M1262,302.0 1262,277.0 1391.0,277.0 1391.0,302.0\" fill=\"none\" stroke=\"currentColor\"/\n    text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\"\n        textPath xlink:href=\"#arrow-c2baa64957a84bfb9ce5180baa2e949c-0-7\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\"amod/textPath\n    /text\n    path class=\"displacy-arrowhead\" d=\"M1262,304.0 L1258,296.0 1266,296.0\" fill=\"currentColor\"/\n/g\n\ng class=\"displacy-arrow\"\n    path class=\"displacy-arc\" id=\"arrow-c2baa64957a84bfb9ce5180baa2e949c-0-8\" stroke-width=\"2px\" d=\"M962,302.0 962,227.0 1397.0,227.0 1397.0,302.0\" fill=\"none\" stroke=\"currentColor\"/\n    text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\"\n        textPath xlink:href=\"#arrow-c2baa64957a84bfb9ce5180baa2e949c-0-8\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\"pobj/textPath\n    /text\n    path class=\"displacy-arrowhead\" d=\"M1397.0,304.0 L1401.0,296.0 1393.0,296.0\" fill=\"currentColor\"/\n/g\n/svg\n\nsvg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"en\" id=\"c2baa64957a84bfb9ce5180baa2e949c-1\" class=\"displacy\" width=\"4550\" height=\"437.0\" direction=\"ltr\" style=\"max-width: none; height: 437.0px; color: white; background: #09a3d5; font-family: Source Sans Pro; direction: ltr\"\ntext class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"347.0\"\n    tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\"In/tspan\n    tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\"ADP/tspan\n/text\n\ntext class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"347.0\"\n    tspan class=\"displacy-word\" fill=\"currentColor\" x=\"200\"the/tspan\n    tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"200\"DET/tspan\n/text\n\ntext class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"347.0\"\n    tspan class=\"displacy-word\" fill=\"currentColor\" x=\"350\"center/tspan\n    tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"350\"NOUN/tspan\n/text\n\ntext class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"347.0\"\n    tspan class=\"displacy-word\" fill=\"currentColor\" x=\"500\"is/tspan\n    tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"500\"AUX/tspan\n/text\n\ntext class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"347.0\"\n    tspan class=\"displacy-word\" fill=\"currentColor\" x=\"650\"the/tspan\n    tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"650\"DET/tspan\n/text\n\ntext class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"347.0\"\n    tspan class=\"displacy-word\" fill=\"currentColor\" x=\"800\"house/tspan\n    tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"800\"NOUN/tspan\n/text\n\ntext class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"347.0\"\n    tspan class=\"displacy-word\" fill=\"currentColor\" x=\"950\"of/tspan\n    tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"950\"ADP/tspan\n/text\n\ntext class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"347.0\"\n    tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1100\"Senex,/tspan\n    tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1100\"PROPN/tspan\n/text\n\ntext class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"347.0\"\n    tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1250\"who/tspan\n    tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1250\"PRON/tspan\n/text\n\ntext class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"347.0\"\n    tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1400\"lives/tspan\n    tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1400\"VERB/tspan\n/text\n\ntext class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"347.0\"\n    tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1550\"there/tspan\n    tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1550\"ADV/tspan\n/text\n\ntext class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"347.0\"\n    tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1700\"with/tspan\n    tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1700\"ADP/tspan\n/text\n\ntext class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"347.0\"\n    tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1850\"wife/tspan\n    tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1850\"NOUN/tspan\n/text\n\ntext class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"347.0\"\n    tspan class=\"displacy-word\" fill=\"currentColor\" x=\"2000\"Domina,/tspan\n    tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"2000\"PROPN/tspan\n/text\n\ntext class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"347.0\"\n    tspan class=\"displacy-word\" fill=\"currentColor\" x=\"2150\"son/tspan\n    tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"2150\"NOUN/tspan\n/text\n\ntext class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"347.0\"\n    tspan class=\"displacy-word\" fill=\"currentColor\" x=\"2300\"Hero,/tspan\n    tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"2300\"PROPN/tspan\n/text\n\ntext class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"347.0\"\n    tspan class=\"displacy-word\" fill=\"currentColor\" x=\"2450\"and/tspan\n    tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"2450\"CCONJ/tspan\n/text\n\ntext class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"347.0\"\n    tspan class=\"displacy-word\" fill=\"currentColor\" x=\"2600\"several/tspan\n    tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"2600\"ADJ/tspan\n/text\n\ntext class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"347.0\"\n    tspan class=\"displacy-word\" fill=\"currentColor\" x=\"2750\"slaves,/tspan\n    tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"2750\"NOUN/tspan\n/text\n\ntext class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"347.0\"\n    tspan class=\"displacy-word\" fill=\"currentColor\" x=\"2900\"including/tspan\n    tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"2900\"VERB/tspan\n/text\n\ntext class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"347.0\"\n    tspan class=\"displacy-word\" fill=\"currentColor\" x=\"3050\"head/tspan\n    tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"3050\"PROPN/tspan\n/text\n\ntext class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"347.0\"\n    tspan class=\"displacy-word\" fill=\"currentColor\" x=\"3200\"slave/tspan\n    tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"3200\"NOUN/tspan\n/text\n\ntext class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"347.0\"\n    tspan class=\"displacy-word\" fill=\"currentColor\" x=\"3350\"Hysterium/tspan\n    tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"3350\"PROPN/tspan\n/text\n\ntext class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"347.0\"\n    tspan class=\"displacy-word\" fill=\"currentColor\" x=\"3500\"and/tspan\n    tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"3500\"CCONJ/tspan\n/text\n\ntext class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"347.0\"\n    tspan class=\"displacy-word\" fill=\"currentColor\" x=\"3650\"the/tspan\n    tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"3650\"DET/tspan\n/text\n\ntext class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"347.0\"\n    tspan class=\"displacy-word\" fill=\"currentColor\" x=\"3800\"musical/tspan\n    tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"3800\"ADJ/tspan\n/text\n\ntext class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"347.0\"\n    tspan class=\"displacy-word\" fill=\"currentColor\" x=\"3950\"'s/tspan\n    tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"3950\"PART/tspan\n/text\n\ntext class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"347.0\"\n    tspan class=\"displacy-word\" fill=\"currentColor\" x=\"4100\"main/tspan\n    tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"4100\"ADJ/tspan\n/text\n\ntext class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"347.0\"\n    tspan class=\"displacy-word\" fill=\"currentColor\" x=\"4250\"character/tspan\n    tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"4250\"NOUN/tspan\n/text\n\ntext class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"347.0\"\n    tspan class=\"displacy-word\" fill=\"currentColor\" x=\"4400\"Pseudolus./tspan\n    tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"4400\"PROPN/tspan\n/text\n\ng class=\"displacy-arrow\"\n    path class=\"displacy-arc\" id=\"arrow-c2baa64957a84bfb9ce5180baa2e949c-1-0\" stroke-width=\"2px\" d=\"M62,302.0 62,227.0 497.0,227.0 497.0,302.0\" fill=\"none\" stroke=\"currentColor\"/\n    text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\"\n        textPath xlink:href=\"#arrow-c2baa64957a84bfb9ce5180baa2e949c-1-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\"prep/textPath\n    /text\n    path class=\"displacy-arrowhead\" d=\"M62,304.0 L58,296.0 66,296.0\" fill=\"currentColor\"/\n/g\n\ng class=\"displacy-arrow\"\n    path class=\"displacy-arc\" id=\"arrow-c2baa64957a84bfb9ce5180baa2e949c-1-1\" stroke-width=\"2px\" d=\"M212,302.0 212,277.0 341.0,277.0 341.0,302.0\" fill=\"none\" stroke=\"currentColor\"/\n    text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\"\n        textPath xlink:href=\"#arrow-c2baa64957a84bfb9ce5180baa2e949c-1-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\"det/textPath\n    /text\n    path class=\"displacy-arrowhead\" d=\"M212,304.0 L208,296.0 216,296.0\" fill=\"currentColor\"/\n/g\n\ng class=\"displacy-arrow\"\n    path class=\"displacy-arc\" id=\"arrow-c2baa64957a84bfb9ce5180baa2e949c-1-2\" stroke-width=\"2px\" d=\"M62,302.0 62,252.0 344.0,252.0 344.0,302.0\" fill=\"none\" stroke=\"currentColor\"/\n    text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\"\n        textPath xlink:href=\"#arrow-c2baa64957a84bfb9ce5180baa2e949c-1-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\"pobj/textPath\n    /text\n    path class=\"displacy-arrowhead\" d=\"M344.0,304.0 L348.0,296.0 340.0,296.0\" fill=\"currentColor\"/\n/g\n\ng class=\"displacy-arrow\"\n    path class=\"displacy-arc\" id=\"arrow-c2baa64957a84bfb9ce5180baa2e949c-1-3\" stroke-width=\"2px\" d=\"M662,302.0 662,277.0 791.0,277.0 791.0,302.0\" fill=\"none\" stroke=\"currentColor\"/\n    text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\"\n        textPath xlink:href=\"#arrow-c2baa64957a84bfb9ce5180baa2e949c-1-3\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\"det/textPath\n    /text\n    path class=\"displacy-arrowhead\" d=\"M662,304.0 L658,296.0 666,296.0\" fill=\"currentColor\"/\n/g\n\ng class=\"displacy-arrow\"\n    path class=\"displacy-arc\" id=\"arrow-c2baa64957a84bfb9ce5180baa2e949c-1-4\" stroke-width=\"2px\" d=\"M512,302.0 512,252.0 794.0,252.0 794.0,302.0\" fill=\"none\" stroke=\"currentColor\"/\n    text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\"\n        textPath xlink:href=\"#arrow-c2baa64957a84bfb9ce5180baa2e949c-1-4\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\"nsubj/textPath\n    /text\n    path class=\"displacy-arrowhead\" d=\"M794.0,304.0 L798.0,296.0 790.0,296.0\" fill=\"currentColor\"/\n/g\n\ng class=\"displacy-arrow\"\n    path class=\"displacy-arc\" id=\"arrow-c2baa64957a84bfb9ce5180baa2e949c-1-5\" stroke-width=\"2px\" d=\"M812,302.0 812,277.0 941.0,277.0 941.0,302.0\" fill=\"none\" stroke=\"currentColor\"/\n    text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\"\n        textPath xlink:href=\"#arrow-c2baa64957a84bfb9ce5180baa2e949c-1-5\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\"prep/textPath\n    /text\n    path class=\"displacy-arrowhead\" d=\"M941.0,304.0 L945.0,296.0 937.0,296.0\" fill=\"currentColor\"/\n/g\n\ng class=\"displacy-arrow\"\n    path class=\"displacy-arc\" id=\"arrow-c2baa64957a84bfb9ce5180baa2e949c-1-6\" stroke-width=\"2px\" d=\"M962,302.0 962,277.0 1091.0,277.0 1091.0,302.0\" fill=\"none\" stroke=\"currentColor\"/\n    text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\"\n        textPath xlink:href=\"#arrow-c2baa64957a84bfb9ce5180baa2e949c-1-6\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\"pobj/textPath\n    /text\n    path class=\"displacy-arrowhead\" d=\"M1091.0,304.0 L1095.0,296.0 1087.0,296.0\" fill=\"currentColor\"/\n/g\n\ng class=\"displacy-arrow\"\n    path class=\"displacy-arc\" id=\"arrow-c2baa64957a84bfb9ce5180baa2e949c-1-7\" stroke-width=\"2px\" d=\"M1262,302.0 1262,277.0 1391.0,277.0 1391.0,302.0\" fill=\"none\" stroke=\"currentColor\"/\n    text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\"\n        textPath xlink:href=\"#arrow-c2baa64957a84bfb9ce5180baa2e949c-1-7\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\"nsubj/textPath\n    /text\n    path class=\"displacy-arrowhead\" d=\"M1262,304.0 L1258,296.0 1266,296.0\" fill=\"currentColor\"/\n/g\n\ng class=\"displacy-arrow\"\n    path class=\"displacy-arc\" id=\"arrow-c2baa64957a84bfb9ce5180baa2e949c-1-8\" stroke-width=\"2px\" d=\"M1112,302.0 1112,252.0 1394.0,252.0 1394.0,302.0\" fill=\"none\" stroke=\"currentColor\"/\n    text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\"\n        textPath xlink:href=\"#arrow-c2baa64957a84bfb9ce5180baa2e949c-1-8\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\"relcl/textPath\n    /text\n    path class=\"displacy-arrowhead\" d=\"M1394.0,304.0 L1398.0,296.0 1390.0,296.0\" fill=\"currentColor\"/\n/g\n\ng class=\"displacy-arrow\"\n    path class=\"displacy-arc\" id=\"arrow-c2baa64957a84bfb9ce5180baa2e949c-1-9\" stroke-width=\"2px\" d=\"M1412,302.0 1412,277.0 1541.0,277.0 1541.0,302.0\" fill=\"none\" stroke=\"currentColor\"/\n    text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\"\n        textPath xlink:href=\"#arrow-c2baa64957a84bfb9ce5180baa2e949c-1-9\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\"advmod/textPath\n    /text\n    path class=\"displacy-arrowhead\" d=\"M1541.0,304.0 L1545.0,296.0 1537.0,296.0\" fill=\"currentColor\"/\n/g\n\ng class=\"displacy-arrow\"\n    path class=\"displacy-arc\" id=\"arrow-c2baa64957a84bfb9ce5180baa2e949c-1-10\" stroke-width=\"2px\" d=\"M1412,302.0 1412,252.0 1694.0,252.0 1694.0,302.0\" fill=\"none\" stroke=\"currentColor\"/\n    text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\"\n        textPath xlink:href=\"#arrow-c2baa64957a84bfb9ce5180baa2e949c-1-10\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\"prep/textPath\n    /text\n    path class=\"displacy-arrowhead\" d=\"M1694.0,304.0 L1698.0,296.0 1690.0,296.0\" fill=\"currentColor\"/\n/g\n\ng class=\"displacy-arrow\"\n    path class=\"displacy-arc\" id=\"arrow-c2baa64957a84bfb9ce5180baa2e949c-1-11\" stroke-width=\"2px\" d=\"M1712,302.0 1712,277.0 1841.0,277.0 1841.0,302.0\" fill=\"none\" stroke=\"currentColor\"/\n    text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\"\n        textPath xlink:href=\"#arrow-c2baa64957a84bfb9ce5180baa2e949c-1-11\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\"pobj/textPath\n    /text\n    path class=\"displacy-arrowhead\" d=\"M1841.0,304.0 L1845.0,296.0 1837.0,296.0\" fill=\"currentColor\"/\n/g\n\ng class=\"displacy-arrow\"\n    path class=\"displacy-arc\" id=\"arrow-c2baa64957a84bfb9ce5180baa2e949c-1-12\" stroke-width=\"2px\" d=\"M1862,302.0 1862,277.0 1991.0,277.0 1991.0,302.0\" fill=\"none\" stroke=\"currentColor\"/\n    text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\"\n        textPath xlink:href=\"#arrow-c2baa64957a84bfb9ce5180baa2e949c-1-12\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\"appos/textPath\n    /text\n    path class=\"displacy-arrowhead\" d=\"M1991.0,304.0 L1995.0,296.0 1987.0,296.0\" fill=\"currentColor\"/\n/g\n\ng class=\"displacy-arrow\"\n    path class=\"displacy-arc\" id=\"arrow-c2baa64957a84bfb9ce5180baa2e949c-1-13\" stroke-width=\"2px\" d=\"M2162,302.0 2162,277.0 2291.0,277.0 2291.0,302.0\" fill=\"none\" stroke=\"currentColor\"/\n    text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\"\n        textPath xlink:href=\"#arrow-c2baa64957a84bfb9ce5180baa2e949c-1-13\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\"compound/textPath\n    /text\n    path class=\"displacy-arrowhead\" d=\"M2162,304.0 L2158,296.0 2166,296.0\" fill=\"currentColor\"/\n/g\n\ng class=\"displacy-arrow\"\n    path class=\"displacy-arc\" id=\"arrow-c2baa64957a84bfb9ce5180baa2e949c-1-14\" stroke-width=\"2px\" d=\"M2012,302.0 2012,252.0 2294.0,252.0 2294.0,302.0\" fill=\"none\" stroke=\"currentColor\"/\n    text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\"\n        textPath xlink:href=\"#arrow-c2baa64957a84bfb9ce5180baa2e949c-1-14\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\"conj/textPath\n    /text\n    path class=\"displacy-arrowhead\" d=\"M2294.0,304.0 L2298.0,296.0 2290.0,296.0\" fill=\"currentColor\"/\n/g\n\ng class=\"displacy-arrow\"\n    path class=\"displacy-arc\" id=\"arrow-c2baa64957a84bfb9ce5180baa2e949c-1-15\" stroke-width=\"2px\" d=\"M2312,302.0 2312,277.0 2441.0,277.0 2441.0,302.0\" fill=\"none\" stroke=\"currentColor\"/\n    text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\"\n        textPath xlink:href=\"#arrow-c2baa64957a84bfb9ce5180baa2e949c-1-15\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\"cc/textPath\n    /text\n    path class=\"displacy-arrowhead\" d=\"M2441.0,304.0 L2445.0,296.0 2437.0,296.0\" fill=\"currentColor\"/\n/g\n\ng class=\"displacy-arrow\"\n    path class=\"displacy-arc\" id=\"arrow-c2baa64957a84bfb9ce5180baa2e949c-1-16\" stroke-width=\"2px\" d=\"M2612,302.0 2612,277.0 2741.0,277.0 2741.0,302.0\" fill=\"none\" stroke=\"currentColor\"/\n    text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\"\n        textPath xlink:href=\"#arrow-c2baa64957a84bfb9ce5180baa2e949c-1-16\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\"amod/textPath\n    /text\n    path class=\"displacy-arrowhead\" d=\"M2612,304.0 L2608,296.0 2616,296.0\" fill=\"currentColor\"/\n/g\n\ng class=\"displacy-arrow\"\n    path class=\"displacy-arc\" id=\"arrow-c2baa64957a84bfb9ce5180baa2e949c-1-17\" stroke-width=\"2px\" d=\"M2312,302.0 2312,227.0 2747.0,227.0 2747.0,302.0\" fill=\"none\" stroke=\"currentColor\"/\n    text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\"\n        textPath xlink:href=\"#arrow-c2baa64957a84bfb9ce5180baa2e949c-1-17\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\"conj/textPath\n    /text\n    path class=\"displacy-arrowhead\" d=\"M2747.0,304.0 L2751.0,296.0 2743.0,296.0\" fill=\"currentColor\"/\n/g\n\ng class=\"displacy-arrow\"\n    path class=\"displacy-arc\" id=\"arrow-c2baa64957a84bfb9ce5180baa2e949c-1-18\" stroke-width=\"2px\" d=\"M2762,302.0 2762,277.0 2891.0,277.0 2891.0,302.0\" fill=\"none\" stroke=\"currentColor\"/\n    text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\"\n        textPath xlink:href=\"#arrow-c2baa64957a84bfb9ce5180baa2e949c-1-18\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\"prep/textPath\n    /text\n    path class=\"displacy-arrowhead\" d=\"M2891.0,304.0 L2895.0,296.0 2887.0,296.0\" fill=\"currentColor\"/\n/g\n\ng class=\"displacy-arrow\"\n    path class=\"displacy-arc\" id=\"arrow-c2baa64957a84bfb9ce5180baa2e949c-1-19\" stroke-width=\"2px\" d=\"M3062,302.0 3062,252.0 3344.0,252.0 3344.0,302.0\" fill=\"none\" stroke=\"currentColor\"/\n    text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\"\n        textPath xlink:href=\"#arrow-c2baa64957a84bfb9ce5180baa2e949c-1-19\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\"compound/textPath\n    /text\n    path class=\"displacy-arrowhead\" d=\"M3062,304.0 L3058,296.0 3066,296.0\" fill=\"currentColor\"/\n/g\n\ng class=\"displacy-arrow\"\n    path class=\"displacy-arc\" id=\"arrow-c2baa64957a84bfb9ce5180baa2e949c-1-20\" stroke-width=\"2px\" d=\"M3212,302.0 3212,277.0 3341.0,277.0 3341.0,302.0\" fill=\"none\" stroke=\"currentColor\"/\n    text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\"\n        textPath xlink:href=\"#arrow-c2baa64957a84bfb9ce5180baa2e949c-1-20\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\"compound/textPath\n    /text\n    path class=\"displacy-arrowhead\" d=\"M3212,304.0 L3208,296.0 3216,296.0\" fill=\"currentColor\"/\n/g\n\ng class=\"displacy-arrow\"\n    path class=\"displacy-arc\" id=\"arrow-c2baa64957a84bfb9ce5180baa2e949c-1-21\" stroke-width=\"2px\" d=\"M2912,302.0 2912,227.0 3347.0,227.0 3347.0,302.0\" fill=\"none\" stroke=\"currentColor\"/\n    text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\"\n        textPath xlink:href=\"#arrow-c2baa64957a84bfb9ce5180baa2e949c-1-21\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\"pobj/textPath\n    /text\n    path class=\"displacy-arrowhead\" d=\"M3347.0,304.0 L3351.0,296.0 3343.0,296.0\" fill=\"currentColor\"/\n/g\n\ng class=\"displacy-arrow\"\n    path class=\"displacy-arc\" id=\"arrow-c2baa64957a84bfb9ce5180baa2e949c-1-22\" stroke-width=\"2px\" d=\"M3362,302.0 3362,277.0 3491.0,277.0 3491.0,302.0\" fill=\"none\" stroke=\"currentColor\"/\n    text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\"\n        textPath xlink:href=\"#arrow-c2baa64957a84bfb9ce5180baa2e949c-1-22\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\"cc/textPath\n    /text\n    path class=\"displacy-arrowhead\" d=\"M3491.0,304.0 L3495.0,296.0 3487.0,296.0\" fill=\"currentColor\"/\n/g\n\ng class=\"displacy-arrow\"\n    path class=\"displacy-arc\" id=\"arrow-c2baa64957a84bfb9ce5180baa2e949c-1-23\" stroke-width=\"2px\" d=\"M3662,302.0 3662,277.0 3791.0,277.0 3791.0,302.0\" fill=\"none\" stroke=\"currentColor\"/\n    text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\"\n        textPath xlink:href=\"#arrow-c2baa64957a84bfb9ce5180baa2e949c-1-23\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\"det/textPath\n    /text\n    path class=\"displacy-arrowhead\" d=\"M3662,304.0 L3658,296.0 3666,296.0\" fill=\"currentColor\"/\n/g\n\ng class=\"displacy-arrow\"\n    path class=\"displacy-arc\" id=\"arrow-c2baa64957a84bfb9ce5180baa2e949c-1-24\" stroke-width=\"2px\" d=\"M3812,302.0 3812,227.0 4247.0,227.0 4247.0,302.0\" fill=\"none\" stroke=\"currentColor\"/\n    text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\"\n        textPath xlink:href=\"#arrow-c2baa64957a84bfb9ce5180baa2e949c-1-24\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\"poss/textPath\n    /text\n    path class=\"displacy-arrowhead\" d=\"M3812,304.0 L3808,296.0 3816,296.0\" fill=\"currentColor\"/\n/g\n\ng class=\"displacy-arrow\"\n    path class=\"displacy-arc\" id=\"arrow-c2baa64957a84bfb9ce5180baa2e949c-1-25\" stroke-width=\"2px\" d=\"M3812,302.0 3812,277.0 3941.0,277.0 3941.0,302.0\" fill=\"none\" stroke=\"currentColor\"/\n    text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\"\n        textPath xlink:href=\"#arrow-c2baa64957a84bfb9ce5180baa2e949c-1-25\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\"case/textPath\n    /text\n    path class=\"displacy-arrowhead\" d=\"M3941.0,304.0 L3945.0,296.0 3937.0,296.0\" fill=\"currentColor\"/\n/g\n\ng class=\"displacy-arrow\"\n    path class=\"displacy-arc\" id=\"arrow-c2baa64957a84bfb9ce5180baa2e949c-1-26\" stroke-width=\"2px\" d=\"M4112,302.0 4112,277.0 4241.0,277.0 4241.0,302.0\" fill=\"none\" stroke=\"currentColor\"/\n    text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\"\n        textPath xlink:href=\"#arrow-c2baa64957a84bfb9ce5180baa2e949c-1-26\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\"amod/textPath\n    /text\n    path class=\"displacy-arrowhead\" d=\"M4112,304.0 L4108,296.0 4116,296.0\" fill=\"currentColor\"/\n/g\n\ng class=\"displacy-arrow\"\n    path class=\"displacy-arc\" id=\"arrow-c2baa64957a84bfb9ce5180baa2e949c-1-27\" stroke-width=\"2px\" d=\"M3362,302.0 3362,202.0 4250.0,202.0 4250.0,302.0\" fill=\"none\" stroke=\"currentColor\"/\n    text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\"\n        textPath xlink:href=\"#arrow-c2baa64957a84bfb9ce5180baa2e949c-1-27\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\"conj/textPath\n    /text\n    path class=\"displacy-arrowhead\" d=\"M4250.0,304.0 L4254.0,296.0 4246.0,296.0\" fill=\"currentColor\"/\n/g\n\ng class=\"displacy-arrow\"\n    path class=\"displacy-arc\" id=\"arrow-c2baa64957a84bfb9ce5180baa2e949c-1-28\" stroke-width=\"2px\" d=\"M4262,302.0 4262,277.0 4391.0,277.0 4391.0,302.0\" fill=\"none\" stroke=\"currentColor\"/\n    text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\"\n        textPath xlink:href=\"#arrow-c2baa64957a84bfb9ce5180baa2e949c-1-28\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\"appos/textPath\n    /text\n    path class=\"displacy-arrowhead\" d=\"M4391.0,304.0 L4395.0,296.0 4387.0,296.0\" fill=\"currentColor\"/\n/g\n/svg\n\nsvg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"en\" id=\"c2baa64957a84bfb9ce5180baa2e949c-2\" class=\"displacy\" width=\"2150\" height=\"362.0\" direction=\"ltr\" style=\"max-width: none; height: 362.0px; color: white; background: #09a3d5; font-family: Source Sans Pro; direction: ltr\"\ntext class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"272.0\"\n    tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\"A/tspan\n    tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\"DET/tspan\n/text\n\ntext class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"272.0\"\n    tspan class=\"displacy-word\" fill=\"currentColor\" x=\"200\"slave/tspan\n    tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"200\"NOUN/tspan\n/text\n\ntext class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"272.0\"\n    tspan class=\"displacy-word\" fill=\"currentColor\" x=\"350\"belonging/tspan\n    tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"350\"VERB/tspan\n/text\n\ntext class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"272.0\"\n    tspan class=\"displacy-word\" fill=\"currentColor\" x=\"500\"to/tspan\n    tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"500\"ADP/tspan\n/text\n\ntext class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"272.0\"\n    tspan class=\"displacy-word\" fill=\"currentColor\" x=\"650\"Hero,/tspan\n    tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"650\"PROPN/tspan\n/text\n\ntext class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"272.0\"\n    tspan class=\"displacy-word\" fill=\"currentColor\" x=\"800\"Pseudolus/tspan\n    tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"800\"PROPN/tspan\n/text\n\ntext class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"272.0\"\n    tspan class=\"displacy-word\" fill=\"currentColor\" x=\"950\"wishes/tspan\n    tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"950\"VERB/tspan\n/text\n\ntext class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"272.0\"\n    tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1100\"to/tspan\n    tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1100\"PART/tspan\n/text\n\ntext class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"272.0\"\n    tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1250\"buy,/tspan\n    tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1250\"VERB/tspan\n/text\n\ntext class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"272.0\"\n    tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1400\"win,/tspan\n    tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1400\"VERB/tspan\n/text\n\ntext class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"272.0\"\n    tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1550\"or/tspan\n    tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1550\"CCONJ/tspan\n/text\n\ntext class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"272.0\"\n    tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1700\"steal/tspan\n    tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1700\"VERB/tspan\n/text\n\ntext class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"272.0\"\n    tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1850\"his/tspan\n    tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1850\"PRON/tspan\n/text\n\ntext class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"272.0\"\n    tspan class=\"displacy-word\" fill=\"currentColor\" x=\"2000\"freedom./tspan\n    tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"2000\"NOUN/tspan\n/text\n\ng class=\"displacy-arrow\"\n    path class=\"displacy-arc\" id=\"arrow-c2baa64957a84bfb9ce5180baa2e949c-2-0\" stroke-width=\"2px\" d=\"M62,227.0 62,202.0 194.0,202.0 194.0,227.0\" fill=\"none\" stroke=\"currentColor\"/\n    text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\"\n        textPath xlink:href=\"#arrow-c2baa64957a84bfb9ce5180baa2e949c-2-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\"det/textPath\n    /text\n    path class=\"displacy-arrowhead\" d=\"M62,229.0 L58,221.0 66,221.0\" fill=\"currentColor\"/\n/g\n\ng class=\"displacy-arrow\"\n    path class=\"displacy-arc\" id=\"arrow-c2baa64957a84bfb9ce5180baa2e949c-2-1\" stroke-width=\"2px\" d=\"M212,227.0 212,152.0 950.0,152.0 950.0,227.0\" fill=\"none\" stroke=\"currentColor\"/\n    text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\"\n        textPath xlink:href=\"#arrow-c2baa64957a84bfb9ce5180baa2e949c-2-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\"npadvmod/textPath\n    /text\n    path class=\"displacy-arrowhead\" d=\"M212,229.0 L208,221.0 216,221.0\" fill=\"currentColor\"/\n/g\n\ng class=\"displacy-arrow\"\n    path class=\"displacy-arc\" id=\"arrow-c2baa64957a84bfb9ce5180baa2e949c-2-2\" stroke-width=\"2px\" d=\"M212,227.0 212,202.0 344.0,202.0 344.0,227.0\" fill=\"none\" stroke=\"currentColor\"/\n    text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\"\n        textPath xlink:href=\"#arrow-c2baa64957a84bfb9ce5180baa2e949c-2-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\"acl/textPath\n    /text\n    path class=\"displacy-arrowhead\" d=\"M344.0,229.0 L348.0,221.0 340.0,221.0\" fill=\"currentColor\"/\n/g\n\ng class=\"displacy-arrow\"\n    path class=\"displacy-arc\" id=\"arrow-c2baa64957a84bfb9ce5180baa2e949c-2-3\" stroke-width=\"2px\" d=\"M362,227.0 362,202.0 494.0,202.0 494.0,227.0\" fill=\"none\" stroke=\"currentColor\"/\n    text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\"\n        textPath xlink:href=\"#arrow-c2baa64957a84bfb9ce5180baa2e949c-2-3\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\"prep/textPath\n    /text\n    path class=\"displacy-arrowhead\" d=\"M494.0,229.0 L498.0,221.0 490.0,221.0\" fill=\"currentColor\"/\n/g\n\ng class=\"displacy-arrow\"\n    path class=\"displacy-arc\" id=\"arrow-c2baa64957a84bfb9ce5180baa2e949c-2-4\" stroke-width=\"2px\" d=\"M512,227.0 512,202.0 644.0,202.0 644.0,227.0\" fill=\"none\" stroke=\"currentColor\"/\n    text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\"\n        textPath xlink:href=\"#arrow-c2baa64957a84bfb9ce5180baa2e949c-2-4\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\"pobj/textPath\n    /text\n    path class=\"displacy-arrowhead\" d=\"M644.0,229.0 L648.0,221.0 640.0,221.0\" fill=\"currentColor\"/\n/g\n\ng class=\"displacy-arrow\"\n    path class=\"displacy-arc\" id=\"arrow-c2baa64957a84bfb9ce5180baa2e949c-2-5\" stroke-width=\"2px\" d=\"M812,227.0 812,202.0 944.0,202.0 944.0,227.0\" fill=\"none\" stroke=\"currentColor\"/\n    text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\"\n        textPath xlink:href=\"#arrow-c2baa64957a84bfb9ce5180baa2e949c-2-5\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\"nsubj/textPath\n    /text\n    path class=\"displacy-arrowhead\" d=\"M812,229.0 L808,221.0 816,221.0\" fill=\"currentColor\"/\n/g\n\ng class=\"displacy-arrow\"\n    path class=\"displacy-arc\" id=\"arrow-c2baa64957a84bfb9ce5180baa2e949c-2-6\" stroke-width=\"2px\" d=\"M1112,227.0 1112,202.0 1244.0,202.0 1244.0,227.0\" fill=\"none\" stroke=\"currentColor\"/\n    text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\"\n        textPath xlink:href=\"#arrow-c2baa64957a84bfb9ce5180baa2e949c-2-6\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\"aux/textPath\n    /text\n    path class=\"displacy-arrowhead\" d=\"M1112,229.0 L1108,221.0 1116,221.0\" fill=\"currentColor\"/\n/g\n\ng class=\"displacy-arrow\"\n    path class=\"displacy-arc\" id=\"arrow-c2baa64957a84bfb9ce5180baa2e949c-2-7\" stroke-width=\"2px\" d=\"M962,227.0 962,177.0 1247.0,177.0 1247.0,227.0\" fill=\"none\" stroke=\"currentColor\"/\n    text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\"\n        textPath xlink:href=\"#arrow-c2baa64957a84bfb9ce5180baa2e949c-2-7\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\"xcomp/textPath\n    /text\n    path class=\"displacy-arrowhead\" d=\"M1247.0,229.0 L1251.0,221.0 1243.0,221.0\" fill=\"currentColor\"/\n/g\n\ng class=\"displacy-arrow\"\n    path class=\"displacy-arc\" id=\"arrow-c2baa64957a84bfb9ce5180baa2e949c-2-8\" stroke-width=\"2px\" d=\"M1262,227.0 1262,202.0 1394.0,202.0 1394.0,227.0\" fill=\"none\" stroke=\"currentColor\"/\n    text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\"\n        textPath xlink:href=\"#arrow-c2baa64957a84bfb9ce5180baa2e949c-2-8\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\"conj/textPath\n    /text\n    path class=\"displacy-arrowhead\" d=\"M1394.0,229.0 L1398.0,221.0 1390.0,221.0\" fill=\"currentColor\"/\n/g\n\ng class=\"displacy-arrow\"\n    path class=\"displacy-arc\" id=\"arrow-c2baa64957a84bfb9ce5180baa2e949c-2-9\" stroke-width=\"2px\" d=\"M1412,227.0 1412,202.0 1544.0,202.0 1544.0,227.0\" fill=\"none\" stroke=\"currentColor\"/\n    text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\"\n        textPath xlink:href=\"#arrow-c2baa64957a84bfb9ce5180baa2e949c-2-9\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\"cc/textPath\n    /text\n    path class=\"displacy-arrowhead\" d=\"M1544.0,229.0 L1548.0,221.0 1540.0,221.0\" fill=\"currentColor\"/\n/g\n\ng class=\"displacy-arrow\"\n    path class=\"displacy-arc\" id=\"arrow-c2baa64957a84bfb9ce5180baa2e949c-2-10\" stroke-width=\"2px\" d=\"M1412,227.0 1412,177.0 1697.0,177.0 1697.0,227.0\" fill=\"none\" stroke=\"currentColor\"/\n    text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\"\n        textPath xlink:href=\"#arrow-c2baa64957a84bfb9ce5180baa2e949c-2-10\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\"conj/textPath\n    /text\n    path class=\"displacy-arrowhead\" d=\"M1697.0,229.0 L1701.0,221.0 1693.0,221.0\" fill=\"currentColor\"/\n/g\n\ng class=\"displacy-arrow\"\n    path class=\"displacy-arc\" id=\"arrow-c2baa64957a84bfb9ce5180baa2e949c-2-11\" stroke-width=\"2px\" d=\"M1862,227.0 1862,202.0 1994.0,202.0 1994.0,227.0\" fill=\"none\" stroke=\"currentColor\"/\n    text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\"\n        textPath xlink:href=\"#arrow-c2baa64957a84bfb9ce5180baa2e949c-2-11\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\"poss/textPath\n    /text\n    path class=\"displacy-arrowhead\" d=\"M1862,229.0 L1858,221.0 1866,221.0\" fill=\"currentColor\"/\n/g\n\ng class=\"displacy-arrow\"\n    path class=\"displacy-arc\" id=\"arrow-c2baa64957a84bfb9ce5180baa2e949c-2-12\" stroke-width=\"2px\" d=\"M1712,227.0 1712,177.0 1997.0,177.0 1997.0,227.0\" fill=\"none\" stroke=\"currentColor\"/\n    text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\"\n        textPath xlink:href=\"#arrow-c2baa64957a84bfb9ce5180baa2e949c-2-12\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\"dobj/textPath\n    /text\n    path class=\"displacy-arrowhead\" d=\"M1997.0,229.0 L2001.0,221.0 1993.0,221.0\" fill=\"currentColor\"/\n/g\n/svg\n\nsvg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"en\" id=\"c2baa64957a84bfb9ce5180baa2e949c-3\" class=\"displacy\" width=\"6050\" height=\"587.0\" direction=\"ltr\" style=\"max-width: none; height: 587.0px; color: white; background: #09a3d5; font-family: Source Sans Pro; direction: ltr\"\ntext class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"497.0\"\n    tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\"One/tspan\n    tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\"NUM/tspan\n/text\n\ntext class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"497.0\"\n    tspan class=\"displacy-word\" fill=\"currentColor\" x=\"200\"of/tspan\n    tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"200\"ADP/tspan\n/text\n\ntext class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"497.0\"\n    tspan class=\"displacy-word\" fill=\"currentColor\" x=\"350\"the/tspan\n    tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"350\"DET/tspan\n/text\n\ntext class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"497.0\"\n    tspan class=\"displacy-word\" fill=\"currentColor\" x=\"500\"neighboring/tspan\n    tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"500\"NOUN/tspan\n/text\n\ntext class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"497.0\"\n    tspan class=\"displacy-word\" fill=\"currentColor\" x=\"650\"houses/tspan\n    tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"650\"NOUN/tspan\n/text\n\ntext class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"497.0\"\n    tspan class=\"displacy-word\" fill=\"currentColor\" x=\"800\"is/tspan\n    tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"800\"AUX/tspan\n/text\n\ntext class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"497.0\"\n    tspan class=\"displacy-word\" fill=\"currentColor\" x=\"950\"owned/tspan\n    tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"950\"VERB/tspan\n/text\n\ntext class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"497.0\"\n    tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1100\"by/tspan\n    tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1100\"ADP/tspan\n/text\n\ntext class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"497.0\"\n    tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1250\"Marcus/tspan\n    tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1250\"PROPN/tspan\n/text\n\ntext class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"497.0\"\n    tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1400\"Lycus,/tspan\n    tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1400\"PROPN/tspan\n/text\n\ntext class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"497.0\"\n    tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1550\"who/tspan\n    tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1550\"PRON/tspan\n/text\n\ntext class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"497.0\"\n    tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1700\"is/tspan\n    tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1700\"AUX/tspan\n/text\n\ntext class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"497.0\"\n    tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1850\"a/tspan\n    tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1850\"DET/tspan\n/text\n\ntext class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"497.0\"\n    tspan class=\"displacy-word\" fill=\"currentColor\" x=\"2000\"buyer/tspan\n    tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"2000\"NOUN/tspan\n/text\n\ntext class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"497.0\"\n    tspan class=\"displacy-word\" fill=\"currentColor\" x=\"2150\"and/tspan\n    tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"2150\"CCONJ/tspan\n/text\n\ntext class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"497.0\"\n    tspan class=\"displacy-word\" fill=\"currentColor\" x=\"2300\"seller/tspan\n    tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"2300\"NOUN/tspan\n/text\n\ntext class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"497.0\"\n    tspan class=\"displacy-word\" fill=\"currentColor\" x=\"2450\"of/tspan\n    tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"2450\"ADP/tspan\n/text\n\ntext class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"497.0\"\n    tspan class=\"displacy-word\" fill=\"currentColor\" x=\"2600\"beautiful/tspan\n    tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"2600\"ADJ/tspan\n/text\n\ntext class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"497.0\"\n    tspan class=\"displacy-word\" fill=\"currentColor\" x=\"2750\"women;/tspan\n    tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"2750\"NOUN/tspan\n/text\n\ntext class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"497.0\"\n    tspan class=\"displacy-word\" fill=\"currentColor\" x=\"2900\"the/tspan\n    tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"2900\"DET/tspan\n/text\n\ntext class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"497.0\"\n    tspan class=\"displacy-word\" fill=\"currentColor\" x=\"3050\"other/tspan\n    tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"3050\"ADJ/tspan\n/text\n\ntext class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"497.0\"\n    tspan class=\"displacy-word\" fill=\"currentColor\" x=\"3200\"belongs/tspan\n    tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"3200\"VERB/tspan\n/text\n\ntext class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"497.0\"\n    tspan class=\"displacy-word\" fill=\"currentColor\" x=\"3350\"to/tspan\n    tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"3350\"ADP/tspan\n/text\n\ntext class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"497.0\"\n    tspan class=\"displacy-word\" fill=\"currentColor\" x=\"3500\"the/tspan\n    tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"3500\"DET/tspan\n/text\n\ntext class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"497.0\"\n    tspan class=\"displacy-word\" fill=\"currentColor\" x=\"3650\"ancient/tspan\n    tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"3650\"ADJ/tspan\n/text\n\ntext class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"497.0\"\n    tspan class=\"displacy-word\" fill=\"currentColor\" x=\"3800\"Erronius,/tspan\n    tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"3800\"PROPN/tspan\n/text\n\ntext class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"497.0\"\n    tspan class=\"displacy-word\" fill=\"currentColor\" x=\"3950\"who/tspan\n    tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"3950\"PRON/tspan\n/text\n\ntext class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"497.0\"\n    tspan class=\"displacy-word\" fill=\"currentColor\" x=\"4100\"is/tspan\n    tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"4100\"AUX/tspan\n/text\n\ntext class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"497.0\"\n    tspan class=\"displacy-word\" fill=\"currentColor\" x=\"4250\"abroad/tspan\n    tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"4250\"ADV/tspan\n/text\n\ntext class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"497.0\"\n    tspan class=\"displacy-word\" fill=\"currentColor\" x=\"4400\"searching/tspan\n    tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"4400\"VERB/tspan\n/text\n\ntext class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"497.0\"\n    tspan class=\"displacy-word\" fill=\"currentColor\" x=\"4550\"for/tspan\n    tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"4550\"ADP/tspan\n/text\n\ntext class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"497.0\"\n    tspan class=\"displacy-word\" fill=\"currentColor\" x=\"4700\"his/tspan\n    tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"4700\"PRON/tspan\n/text\n\ntext class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"497.0\"\n    tspan class=\"displacy-word\" fill=\"currentColor\" x=\"4850\"long-/tspan\n    tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"4850\"ADV/tspan\n/text\n\ntext class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"497.0\"\n    tspan class=\"displacy-word\" fill=\"currentColor\" x=\"5000\"lost/tspan\n    tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"5000\"VERB/tspan\n/text\n\ntext class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"497.0\"\n    tspan class=\"displacy-word\" fill=\"currentColor\" x=\"5150\"children (/tspan\n    tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"5150\"NOUN/tspan\n/text\n\ntext class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"497.0\"\n    tspan class=\"displacy-word\" fill=\"currentColor\" x=\"5300\"stolen/tspan\n    tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"5300\"VERB/tspan\n/text\n\ntext class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"497.0\"\n    tspan class=\"displacy-word\" fill=\"currentColor\" x=\"5450\"in/tspan\n    tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"5450\"ADP/tspan\n/text\n\ntext class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"497.0\"\n    tspan class=\"displacy-word\" fill=\"currentColor\" x=\"5600\"infancy/tspan\n    tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"5600\"NOUN/tspan\n/text\n\ntext class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"497.0\"\n    tspan class=\"displacy-word\" fill=\"currentColor\" x=\"5750\"by/tspan\n    tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"5750\"ADP/tspan\n/text\n\ntext class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"497.0\"\n    tspan class=\"displacy-word\" fill=\"currentColor\" x=\"5900\"pirates)./tspan\n    tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"5900\"NOUN/tspan\n/text\n\ng class=\"displacy-arrow\"\n    path class=\"displacy-arc\" id=\"arrow-c2baa64957a84bfb9ce5180baa2e949c-3-0\" stroke-width=\"2px\" d=\"M62,452.0 62,327.0 947.0,327.0 947.0,452.0\" fill=\"none\" stroke=\"currentColor\"/\n    text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\"\n        textPath xlink:href=\"#arrow-c2baa64957a84bfb9ce5180baa2e949c-3-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\"nsubjpass/textPath\n    /text\n    path class=\"displacy-arrowhead\" d=\"M62,454.0 L58,446.0 66,446.0\" fill=\"currentColor\"/\n/g\n\ng class=\"displacy-arrow\"\n    path class=\"displacy-arc\" id=\"arrow-c2baa64957a84bfb9ce5180baa2e949c-3-1\" stroke-width=\"2px\" d=\"M62,452.0 62,427.0 185.0,427.0 185.0,452.0\" fill=\"none\" stroke=\"currentColor\"/\n    text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\"\n        textPath xlink:href=\"#arrow-c2baa64957a84bfb9ce5180baa2e949c-3-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\"prep/textPath\n    /text\n    path class=\"displacy-arrowhead\" d=\"M185.0,454.0 L189.0,446.0 181.0,446.0\" fill=\"currentColor\"/\n/g\n\ng class=\"displacy-arrow\"\n    path class=\"displacy-arc\" id=\"arrow-c2baa64957a84bfb9ce5180baa2e949c-3-2\" stroke-width=\"2px\" d=\"M362,452.0 362,402.0 638.0,402.0 638.0,452.0\" fill=\"none\" stroke=\"currentColor\"/\n    text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\"\n        textPath xlink:href=\"#arrow-c2baa64957a84bfb9ce5180baa2e949c-3-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\"det/textPath\n    /text\n    path class=\"displacy-arrowhead\" d=\"M362,454.0 L358,446.0 366,446.0\" fill=\"currentColor\"/\n/g\n\ng class=\"displacy-arrow\"\n    path class=\"displacy-arc\" id=\"arrow-c2baa64957a84bfb9ce5180baa2e949c-3-3\" stroke-width=\"2px\" d=\"M512,452.0 512,427.0 635.0,427.0 635.0,452.0\" fill=\"none\" stroke=\"currentColor\"/\n    text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\"\n        textPath xlink:href=\"#arrow-c2baa64957a84bfb9ce5180baa2e949c-3-3\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\"amod/textPath\n    /text\n    path class=\"displacy-arrowhead\" d=\"M512,454.0 L508,446.0 516,446.0\" fill=\"currentColor\"/\n/g\n\ng class=\"displacy-arrow\"\n    path class=\"displacy-arc\" id=\"arrow-c2baa64957a84bfb9ce5180baa2e949c-3-4\" stroke-width=\"2px\" d=\"M212,452.0 212,377.0 641.0,377.0 641.0,452.0\" fill=\"none\" stroke=\"currentColor\"/\n    text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\"\n        textPath xlink:href=\"#arrow-c2baa64957a84bfb9ce5180baa2e949c-3-4\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\"pobj/textPath\n    /text\n    path class=\"displacy-arrowhead\" d=\"M641.0,454.0 L645.0,446.0 637.0,446.0\" fill=\"currentColor\"/\n/g\n\ng class=\"displacy-arrow\"\n    path class=\"displacy-arc\" id=\"arrow-c2baa64957a84bfb9ce5180baa2e949c-3-5\" stroke-width=\"2px\" d=\"M812,452.0 812,427.0 935.0,427.0 935.0,452.0\" fill=\"none\" stroke=\"currentColor\"/\n    text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\"\n        textPath xlink:href=\"#arrow-c2baa64957a84bfb9ce5180baa2e949c-3-5\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\"auxpass/textPath\n    /text\n    path class=\"displacy-arrowhead\" d=\"M812,454.0 L808,446.0 816,446.0\" fill=\"currentColor\"/\n/g\n\ng class=\"displacy-arrow\"\n    path class=\"displacy-arc\" id=\"arrow-c2baa64957a84bfb9ce5180baa2e949c-3-6\" stroke-width=\"2px\" d=\"M962,452.0 962,302.0 3200.0,302.0 3200.0,452.0\" fill=\"none\" stroke=\"currentColor\"/\n    text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\"\n        textPath xlink:href=\"#arrow-c2baa64957a84bfb9ce5180baa2e949c-3-6\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\"ccomp/textPath\n    /text\n    path class=\"displacy-arrowhead\" d=\"M962,454.0 L958,446.0 966,446.0\" fill=\"currentColor\"/\n/g\n\ng class=\"displacy-arrow\"\n    path class=\"displacy-arc\" id=\"arrow-c2baa64957a84bfb9ce5180baa2e949c-3-7\" stroke-width=\"2px\" d=\"M962,452.0 962,427.0 1085.0,427.0 1085.0,452.0\" fill=\"none\" stroke=\"currentColor\"/\n    text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\"\n        textPath xlink:href=\"#arrow-c2baa64957a84bfb9ce5180baa2e949c-3-7\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\"agent/textPath\n    /text\n    path class=\"displacy-arrowhead\" d=\"M1085.0,454.0 L1089.0,446.0 1081.0,446.0\" fill=\"currentColor\"/\n/g\n\ng class=\"displacy-arrow\"\n    path class=\"displacy-arc\" id=\"arrow-c2baa64957a84bfb9ce5180baa2e949c-3-8\" stroke-width=\"2px\" d=\"M1262,452.0 1262,427.0 1385.0,427.0 1385.0,452.0\" fill=\"none\" stroke=\"currentColor\"/\n    text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\"\n        textPath xlink:href=\"#arrow-c2baa64957a84bfb9ce5180baa2e949c-3-8\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\"compound/textPath\n    /text\n    path class=\"displacy-arrowhead\" d=\"M1262,454.0 L1258,446.0 1266,446.0\" fill=\"currentColor\"/\n/g\n\ng class=\"displacy-arrow\"\n    path class=\"displacy-arc\" id=\"arrow-c2baa64957a84bfb9ce5180baa2e949c-3-9\" stroke-width=\"2px\" d=\"M1112,452.0 1112,402.0 1388.0,402.0 1388.0,452.0\" fill=\"none\" stroke=\"currentColor\"/\n    text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\"\n        textPath xlink:href=\"#arrow-c2baa64957a84bfb9ce5180baa2e949c-3-9\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\"pobj/textPath\n    /text\n    path class=\"displacy-arrowhead\" d=\"M1388.0,454.0 L1392.0,446.0 1384.0,446.0\" fill=\"currentColor\"/\n/g\n\ng class=\"displacy-arrow\"\n    path class=\"displacy-arc\" id=\"arrow-c2baa64957a84bfb9ce5180baa2e949c-3-10\" stroke-width=\"2px\" d=\"M1562,452.0 1562,427.0 1685.0,427.0 1685.0,452.0\" fill=\"none\" stroke=\"currentColor\"/\n    text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\"\n        textPath xlink:href=\"#arrow-c2baa64957a84bfb9ce5180baa2e949c-3-10\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\"nsubj/textPath\n    /text\n    path class=\"displacy-arrowhead\" d=\"M1562,454.0 L1558,446.0 1566,446.0\" fill=\"currentColor\"/\n/g\n\ng class=\"displacy-arrow\"\n    path class=\"displacy-arc\" id=\"arrow-c2baa64957a84bfb9ce5180baa2e949c-3-11\" stroke-width=\"2px\" d=\"M1412,452.0 1412,402.0 1688.0,402.0 1688.0,452.0\" fill=\"none\" stroke=\"currentColor\"/\n    text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\"\n        textPath xlink:href=\"#arrow-c2baa64957a84bfb9ce5180baa2e949c-3-11\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\"relcl/textPath\n    /text\n    path class=\"displacy-arrowhead\" d=\"M1688.0,454.0 L1692.0,446.0 1684.0,446.0\" fill=\"currentColor\"/\n/g\n\ng class=\"displacy-arrow\"\n    path class=\"displacy-arc\" id=\"arrow-c2baa64957a84bfb9ce5180baa2e949c-3-12\" stroke-width=\"2px\" d=\"M1862,452.0 1862,427.0 1985.0,427.0 1985.0,452.0\" fill=\"none\" stroke=\"currentColor\"/\n    text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\"\n        textPath xlink:href=\"#arrow-c2baa64957a84bfb9ce5180baa2e949c-3-12\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\"det/textPath\n    /text\n    path class=\"displacy-arrowhead\" d=\"M1862,454.0 L1858,446.0 1866,446.0\" fill=\"currentColor\"/\n/g\n\ng class=\"displacy-arrow\"\n    path class=\"displacy-arc\" id=\"arrow-c2baa64957a84bfb9ce5180baa2e949c-3-13\" stroke-width=\"2px\" d=\"M1712,452.0 1712,402.0 1988.0,402.0 1988.0,452.0\" fill=\"none\" stroke=\"currentColor\"/\n    text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\"\n        textPath xlink:href=\"#arrow-c2baa64957a84bfb9ce5180baa2e949c-3-13\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\"attr/textPath\n    /text\n    path class=\"displacy-arrowhead\" d=\"M1988.0,454.0 L1992.0,446.0 1984.0,446.0\" fill=\"currentColor\"/\n/g\n\ng class=\"displacy-arrow\"\n    path class=\"displacy-arc\" id=\"arrow-c2baa64957a84bfb9ce5180baa2e949c-3-14\" stroke-width=\"2px\" d=\"M2012,452.0 2012,427.0 2135.0,427.0 2135.0,452.0\" fill=\"none\" stroke=\"currentColor\"/\n    text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\"\n        textPath xlink:href=\"#arrow-c2baa64957a84bfb9ce5180baa2e949c-3-14\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\"cc/textPath\n    /text\n    path class=\"displacy-arrowhead\" d=\"M2135.0,454.0 L2139.0,446.0 2131.0,446.0\" fill=\"currentColor\"/\n/g\n\ng class=\"displacy-arrow\"\n    path class=\"displacy-arc\" id=\"arrow-c2baa64957a84bfb9ce5180baa2e949c-3-15\" stroke-width=\"2px\" d=\"M2012,452.0 2012,402.0 2288.0,402.0 2288.0,452.0\" fill=\"none\" stroke=\"currentColor\"/\n    text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\"\n        textPath xlink:href=\"#arrow-c2baa64957a84bfb9ce5180baa2e949c-3-15\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\"conj/textPath\n    /text\n    path class=\"displacy-arrowhead\" d=\"M2288.0,454.0 L2292.0,446.0 2284.0,446.0\" fill=\"currentColor\"/\n/g\n\ng class=\"displacy-arrow\"\n    path class=\"displacy-arc\" id=\"arrow-c2baa64957a84bfb9ce5180baa2e949c-3-16\" stroke-width=\"2px\" d=\"M2012,452.0 2012,377.0 2441.0,377.0 2441.0,452.0\" fill=\"none\" stroke=\"currentColor\"/\n    text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\"\n        textPath xlink:href=\"#arrow-c2baa64957a84bfb9ce5180baa2e949c-3-16\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\"prep/textPath\n    /text\n    path class=\"displacy-arrowhead\" d=\"M2441.0,454.0 L2445.0,446.0 2437.0,446.0\" fill=\"currentColor\"/\n/g\n\ng class=\"displacy-arrow\"\n    path class=\"displacy-arc\" id=\"arrow-c2baa64957a84bfb9ce5180baa2e949c-3-17\" stroke-width=\"2px\" d=\"M2612,452.0 2612,427.0 2735.0,427.0 2735.0,452.0\" fill=\"none\" stroke=\"currentColor\"/\n    text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\"\n        textPath xlink:href=\"#arrow-c2baa64957a84bfb9ce5180baa2e949c-3-17\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\"amod/textPath\n    /text\n    path class=\"displacy-arrowhead\" d=\"M2612,454.0 L2608,446.0 2616,446.0\" fill=\"currentColor\"/\n/g\n\ng class=\"displacy-arrow\"\n    path class=\"displacy-arc\" id=\"arrow-c2baa64957a84bfb9ce5180baa2e949c-3-18\" stroke-width=\"2px\" d=\"M2462,452.0 2462,402.0 2738.0,402.0 2738.0,452.0\" fill=\"none\" stroke=\"currentColor\"/\n    text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\"\n        textPath xlink:href=\"#arrow-c2baa64957a84bfb9ce5180baa2e949c-3-18\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\"pobj/textPath\n    /text\n    path class=\"displacy-arrowhead\" d=\"M2738.0,454.0 L2742.0,446.0 2734.0,446.0\" fill=\"currentColor\"/\n/g\n\ng class=\"displacy-arrow\"\n    path class=\"displacy-arc\" id=\"arrow-c2baa64957a84bfb9ce5180baa2e949c-3-19\" stroke-width=\"2px\" d=\"M2912,452.0 2912,427.0 3035.0,427.0 3035.0,452.0\" fill=\"none\" stroke=\"currentColor\"/\n    text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\"\n        textPath xlink:href=\"#arrow-c2baa64957a84bfb9ce5180baa2e949c-3-19\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\"det/textPath\n    /text\n    path class=\"displacy-arrowhead\" d=\"M2912,454.0 L2908,446.0 2916,446.0\" fill=\"currentColor\"/\n/g\n\ng class=\"displacy-arrow\"\n    path class=\"displacy-arc\" id=\"arrow-c2baa64957a84bfb9ce5180baa2e949c-3-20\" stroke-width=\"2px\" d=\"M3062,452.0 3062,427.0 3185.0,427.0 3185.0,452.0\" fill=\"none\" stroke=\"currentColor\"/\n    text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\"\n        textPath xlink:href=\"#arrow-c2baa64957a84bfb9ce5180baa2e949c-3-20\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\"nsubj/textPath\n    /text\n    path class=\"displacy-arrowhead\" d=\"M3062,454.0 L3058,446.0 3066,446.0\" fill=\"currentColor\"/\n/g\n\ng class=\"displacy-arrow\"\n    path class=\"displacy-arc\" id=\"arrow-c2baa64957a84bfb9ce5180baa2e949c-3-21\" stroke-width=\"2px\" d=\"M3212,452.0 3212,427.0 3335.0,427.0 3335.0,452.0\" fill=\"none\" stroke=\"currentColor\"/\n    text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\"\n        textPath xlink:href=\"#arrow-c2baa64957a84bfb9ce5180baa2e949c-3-21\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\"prep/textPath\n    /text\n    path class=\"displacy-arrowhead\" d=\"M3335.0,454.0 L3339.0,446.0 3331.0,446.0\" fill=\"currentColor\"/\n/g\n\ng class=\"displacy-arrow\"\n    path class=\"displacy-arc\" id=\"arrow-c2baa64957a84bfb9ce5180baa2e949c-3-22\" stroke-width=\"2px\" d=\"M3512,452.0 3512,402.0 3788.0,402.0 3788.0,452.0\" fill=\"none\" stroke=\"currentColor\"/\n    text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\"\n        textPath xlink:href=\"#arrow-c2baa64957a84bfb9ce5180baa2e949c-3-22\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\"det/textPath\n    /text\n    path class=\"displacy-arrowhead\" d=\"M3512,454.0 L3508,446.0 3516,446.0\" fill=\"currentColor\"/\n/g\n\ng class=\"displacy-arrow\"\n    path class=\"displacy-arc\" id=\"arrow-c2baa64957a84bfb9ce5180baa2e949c-3-23\" stroke-width=\"2px\" d=\"M3662,452.0 3662,427.0 3785.0,427.0 3785.0,452.0\" fill=\"none\" stroke=\"currentColor\"/\n    text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\"\n        textPath xlink:href=\"#arrow-c2baa64957a84bfb9ce5180baa2e949c-3-23\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\"amod/textPath\n    /text\n    path class=\"displacy-arrowhead\" d=\"M3662,454.0 L3658,446.0 3666,446.0\" fill=\"currentColor\"/\n/g\n\ng class=\"displacy-arrow\"\n    path class=\"displacy-arc\" id=\"arrow-c2baa64957a84bfb9ce5180baa2e949c-3-24\" stroke-width=\"2px\" d=\"M3362,452.0 3362,377.0 3791.0,377.0 3791.0,452.0\" fill=\"none\" stroke=\"currentColor\"/\n    text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\"\n        textPath xlink:href=\"#arrow-c2baa64957a84bfb9ce5180baa2e949c-3-24\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\"pobj/textPath\n    /text\n    path class=\"displacy-arrowhead\" d=\"M3791.0,454.0 L3795.0,446.0 3787.0,446.0\" fill=\"currentColor\"/\n/g\n\ng class=\"displacy-arrow\"\n    path class=\"displacy-arc\" id=\"arrow-c2baa64957a84bfb9ce5180baa2e949c-3-25\" stroke-width=\"2px\" d=\"M3962,452.0 3962,427.0 4085.0,427.0 4085.0,452.0\" fill=\"none\" stroke=\"currentColor\"/\n    text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\"\n        textPath xlink:href=\"#arrow-c2baa64957a84bfb9ce5180baa2e949c-3-25\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\"nsubj/textPath\n    /text\n    path class=\"displacy-arrowhead\" d=\"M3962,454.0 L3958,446.0 3966,446.0\" fill=\"currentColor\"/\n/g\n\ng class=\"displacy-arrow\"\n    path class=\"displacy-arc\" id=\"arrow-c2baa64957a84bfb9ce5180baa2e949c-3-26\" stroke-width=\"2px\" d=\"M3812,452.0 3812,402.0 4088.0,402.0 4088.0,452.0\" fill=\"none\" stroke=\"currentColor\"/\n    text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\"\n        textPath xlink:href=\"#arrow-c2baa64957a84bfb9ce5180baa2e949c-3-26\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\"relcl/textPath\n    /text\n    path class=\"displacy-arrowhead\" d=\"M4088.0,454.0 L4092.0,446.0 4084.0,446.0\" fill=\"currentColor\"/\n/g\n\ng class=\"displacy-arrow\"\n    path class=\"displacy-arc\" id=\"arrow-c2baa64957a84bfb9ce5180baa2e949c-3-27\" stroke-width=\"2px\" d=\"M4112,452.0 4112,427.0 4235.0,427.0 4235.0,452.0\" fill=\"none\" stroke=\"currentColor\"/\n    text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\"\n        textPath xlink:href=\"#arrow-c2baa64957a84bfb9ce5180baa2e949c-3-27\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\"advmod/textPath\n    /text\n    path class=\"displacy-arrowhead\" d=\"M4235.0,454.0 L4239.0,446.0 4231.0,446.0\" fill=\"currentColor\"/\n/g\n\ng class=\"displacy-arrow\"\n    path class=\"displacy-arc\" id=\"arrow-c2baa64957a84bfb9ce5180baa2e949c-3-28\" stroke-width=\"2px\" d=\"M4112,452.0 4112,402.0 4388.0,402.0 4388.0,452.0\" fill=\"none\" stroke=\"currentColor\"/\n    text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\"\n        textPath xlink:href=\"#arrow-c2baa64957a84bfb9ce5180baa2e949c-3-28\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\"advcl/textPath\n    /text\n    path class=\"displacy-arrowhead\" d=\"M4388.0,454.0 L4392.0,446.0 4384.0,446.0\" fill=\"currentColor\"/\n/g\n\ng class=\"displacy-arrow\"\n    path class=\"displacy-arc\" id=\"arrow-c2baa64957a84bfb9ce5180baa2e949c-3-29\" stroke-width=\"2px\" d=\"M4412,452.0 4412,427.0 4535.0,427.0 4535.0,452.0\" fill=\"none\" stroke=\"currentColor\"/\n    text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\"\n        textPath xlink:href=\"#arrow-c2baa64957a84bfb9ce5180baa2e949c-3-29\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\"prep/textPath\n    /text\n    path class=\"displacy-arrowhead\" d=\"M4535.0,454.0 L4539.0,446.0 4531.0,446.0\" fill=\"currentColor\"/\n/g\n\ng class=\"displacy-arrow\"\n    path class=\"displacy-arc\" id=\"arrow-c2baa64957a84bfb9ce5180baa2e949c-3-30\" stroke-width=\"2px\" d=\"M4712,452.0 4712,377.0 5141.0,377.0 5141.0,452.0\" fill=\"none\" stroke=\"currentColor\"/\n    text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\"\n        textPath xlink:href=\"#arrow-c2baa64957a84bfb9ce5180baa2e949c-3-30\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\"poss/textPath\n    /text\n    path class=\"displacy-arrowhead\" d=\"M4712,454.0 L4708,446.0 4716,446.0\" fill=\"currentColor\"/\n/g\n\ng class=\"displacy-arrow\"\n    path class=\"displacy-arc\" id=\"arrow-c2baa64957a84bfb9ce5180baa2e949c-3-31\" stroke-width=\"2px\" d=\"M4862,452.0 4862,427.0 4985.0,427.0 4985.0,452.0\" fill=\"none\" stroke=\"currentColor\"/\n    text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\"\n        textPath xlink:href=\"#arrow-c2baa64957a84bfb9ce5180baa2e949c-3-31\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\"advmod/textPath\n    /text\n    path class=\"displacy-arrowhead\" d=\"M4862,454.0 L4858,446.0 4866,446.0\" fill=\"currentColor\"/\n/g\n\ng class=\"displacy-arrow\"\n    path class=\"displacy-arc\" id=\"arrow-c2baa64957a84bfb9ce5180baa2e949c-3-32\" stroke-width=\"2px\" d=\"M5012,452.0 5012,427.0 5135.0,427.0 5135.0,452.0\" fill=\"none\" stroke=\"currentColor\"/\n    text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\"\n        textPath xlink:href=\"#arrow-c2baa64957a84bfb9ce5180baa2e949c-3-32\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\"amod/textPath\n    /text\n    path class=\"displacy-arrowhead\" d=\"M5012,454.0 L5008,446.0 5016,446.0\" fill=\"currentColor\"/\n/g\n\ng class=\"displacy-arrow\"\n    path class=\"displacy-arc\" id=\"arrow-c2baa64957a84bfb9ce5180baa2e949c-3-33\" stroke-width=\"2px\" d=\"M4562,452.0 4562,352.0 5144.0,352.0 5144.0,452.0\" fill=\"none\" stroke=\"currentColor\"/\n    text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\"\n        textPath xlink:href=\"#arrow-c2baa64957a84bfb9ce5180baa2e949c-3-33\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\"pobj/textPath\n    /text\n    path class=\"displacy-arrowhead\" d=\"M5144.0,454.0 L5148.0,446.0 5140.0,446.0\" fill=\"currentColor\"/\n/g\n\ng class=\"displacy-arrow\"\n    path class=\"displacy-arc\" id=\"arrow-c2baa64957a84bfb9ce5180baa2e949c-3-34\" stroke-width=\"2px\" d=\"M5162,452.0 5162,427.0 5285.0,427.0 5285.0,452.0\" fill=\"none\" stroke=\"currentColor\"/\n    text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\"\n        textPath xlink:href=\"#arrow-c2baa64957a84bfb9ce5180baa2e949c-3-34\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\"acl/textPath\n    /text\n    path class=\"displacy-arrowhead\" d=\"M5285.0,454.0 L5289.0,446.0 5281.0,446.0\" fill=\"currentColor\"/\n/g\n\ng class=\"displacy-arrow\"\n    path class=\"displacy-arc\" id=\"arrow-c2baa64957a84bfb9ce5180baa2e949c-3-35\" stroke-width=\"2px\" d=\"M5312,452.0 5312,427.0 5435.0,427.0 5435.0,452.0\" fill=\"none\" stroke=\"currentColor\"/\n    text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\"\n        textPath xlink:href=\"#arrow-c2baa64957a84bfb9ce5180baa2e949c-3-35\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\"prep/textPath\n    /text\n    path class=\"displacy-arrowhead\" d=\"M5435.0,454.0 L5439.0,446.0 5431.0,446.0\" fill=\"currentColor\"/\n/g\n\ng class=\"displacy-arrow\"\n    path class=\"displacy-arc\" id=\"arrow-c2baa64957a84bfb9ce5180baa2e949c-3-36\" stroke-width=\"2px\" d=\"M5462,452.0 5462,427.0 5585.0,427.0 5585.0,452.0\" fill=\"none\" stroke=\"currentColor\"/\n    text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\"\n        textPath xlink:href=\"#arrow-c2baa64957a84bfb9ce5180baa2e949c-3-36\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\"pobj/textPath\n    /text\n    path class=\"displacy-arrowhead\" d=\"M5585.0,454.0 L5589.0,446.0 5581.0,446.0\" fill=\"currentColor\"/\n/g\n\ng class=\"displacy-arrow\"\n    path class=\"displacy-arc\" id=\"arrow-c2baa64957a84bfb9ce5180baa2e949c-3-37\" stroke-width=\"2px\" d=\"M5312,452.0 5312,377.0 5741.0,377.0 5741.0,452.0\" fill=\"none\" stroke=\"currentColor\"/\n    text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\"\n        textPath xlink:href=\"#arrow-c2baa64957a84bfb9ce5180baa2e949c-3-37\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\"agent/textPath\n    /text\n    path class=\"displacy-arrowhead\" d=\"M5741.0,454.0 L5745.0,446.0 5737.0,446.0\" fill=\"currentColor\"/\n/g\n\ng class=\"displacy-arrow\"\n    path class=\"displacy-arc\" id=\"arrow-c2baa64957a84bfb9ce5180baa2e949c-3-38\" stroke-width=\"2px\" d=\"M5762,452.0 5762,427.0 5885.0,427.0 5885.0,452.0\" fill=\"none\" stroke=\"currentColor\"/\n    text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\"\n        textPath xlink:href=\"#arrow-c2baa64957a84bfb9ce5180baa2e949c-3-38\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\"pobj/textPath\n    /text\n    path class=\"displacy-arrowhead\" d=\"M5885.0,454.0 L5889.0,446.0 5881.0,446.0\" fill=\"currentColor\"/\n/g\n/svg\n\nsvg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"en\" id=\"c2baa64957a84bfb9ce5180baa2e949c-4\" class=\"displacy\" width=\"2450\" height=\"512.0\" direction=\"ltr\" style=\"max-width: none; height: 512.0px; color: white; background: #09a3d5; font-family: Source Sans Pro; direction: ltr\"\ntext class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"422.0\"\n    tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\"One/tspan\n    tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\"NUM/tspan\n/text\n\ntext class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"422.0\"\n    tspan class=\"displacy-word\" fill=\"currentColor\" x=\"200\"day,/tspan\n    tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"200\"NOUN/tspan\n/text\n\ntext class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"422.0\"\n    tspan class=\"displacy-word\" fill=\"currentColor\" x=\"350\"Senex/tspan\n    tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"350\"PROPN/tspan\n/text\n\ntext class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"422.0\"\n    tspan class=\"displacy-word\" fill=\"currentColor\" x=\"500\"and/tspan\n    tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"500\"CCONJ/tspan\n/text\n\ntext class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"422.0\"\n    tspan class=\"displacy-word\" fill=\"currentColor\" x=\"650\"Domina/tspan\n    tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"650\"PROPN/tspan\n/text\n\ntext class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"422.0\"\n    tspan class=\"displacy-word\" fill=\"currentColor\" x=\"800\"go/tspan\n    tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"800\"VERB/tspan\n/text\n\ntext class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"422.0\"\n    tspan class=\"displacy-word\" fill=\"currentColor\" x=\"950\"on/tspan\n    tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"950\"ADP/tspan\n/text\n\ntext class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"422.0\"\n    tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1100\"a/tspan\n    tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1100\"DET/tspan\n/text\n\ntext class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"422.0\"\n    tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1250\"trip/tspan\n    tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1250\"NOUN/tspan\n/text\n\ntext class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"422.0\"\n    tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1400\"and/tspan\n    tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1400\"CCONJ/tspan\n/text\n\ntext class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"422.0\"\n    tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1550\"leave/tspan\n    tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1550\"VERB/tspan\n/text\n\ntext class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"422.0\"\n    tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1700\"Pseudolus/tspan\n    tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1700\"PROPN/tspan\n/text\n\ntext class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"422.0\"\n    tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1850\"in/tspan\n    tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1850\"ADP/tspan\n/text\n\ntext class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"422.0\"\n    tspan class=\"displacy-word\" fill=\"currentColor\" x=\"2000\"charge/tspan\n    tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"2000\"NOUN/tspan\n/text\n\ntext class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"422.0\"\n    tspan class=\"displacy-word\" fill=\"currentColor\" x=\"2150\"of/tspan\n    tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"2150\"ADP/tspan\n/text\n\ntext class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"422.0\"\n    tspan class=\"displacy-word\" fill=\"currentColor\" x=\"2300\"Hero./tspan\n    tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"2300\"PROPN/tspan\n/text\n\ng class=\"displacy-arrow\"\n    path class=\"displacy-arc\" id=\"arrow-c2baa64957a84bfb9ce5180baa2e949c-4-0\" stroke-width=\"2px\" d=\"M62,377.0 62,352.0 188.0,352.0 188.0,377.0\" fill=\"none\" stroke=\"currentColor\"/\n    text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\"\n        textPath xlink:href=\"#arrow-c2baa64957a84bfb9ce5180baa2e949c-4-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\"nummod/textPath\n    /text\n    path class=\"displacy-arrowhead\" d=\"M62,379.0 L58,371.0 66,371.0\" fill=\"currentColor\"/\n/g\n\ng class=\"displacy-arrow\"\n    path class=\"displacy-arc\" id=\"arrow-c2baa64957a84bfb9ce5180baa2e949c-4-1\" stroke-width=\"2px\" d=\"M212,377.0 212,277.0 797.0,277.0 797.0,377.0\" fill=\"none\" stroke=\"currentColor\"/\n    text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\"\n        textPath xlink:href=\"#arrow-c2baa64957a84bfb9ce5180baa2e949c-4-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\"npadvmod/textPath\n    /text\n    path class=\"displacy-arrowhead\" d=\"M212,379.0 L208,371.0 216,371.0\" fill=\"currentColor\"/\n/g\n\ng class=\"displacy-arrow\"\n    path class=\"displacy-arc\" id=\"arrow-c2baa64957a84bfb9ce5180baa2e949c-4-2\" stroke-width=\"2px\" d=\"M362,377.0 362,302.0 794.0,302.0 794.0,377.0\" fill=\"none\" stroke=\"currentColor\"/\n    text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\"\n        textPath xlink:href=\"#arrow-c2baa64957a84bfb9ce5180baa2e949c-4-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\"nsubj/textPath\n    /text\n    path class=\"displacy-arrowhead\" d=\"M362,379.0 L358,371.0 366,371.0\" fill=\"currentColor\"/\n/g\n\ng class=\"displacy-arrow\"\n    path class=\"displacy-arc\" id=\"arrow-c2baa64957a84bfb9ce5180baa2e949c-4-3\" stroke-width=\"2px\" d=\"M362,377.0 362,352.0 488.0,352.0 488.0,377.0\" fill=\"none\" stroke=\"currentColor\"/\n    text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\"\n        textPath xlink:href=\"#arrow-c2baa64957a84bfb9ce5180baa2e949c-4-3\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\"cc/textPath\n    /text\n    path class=\"displacy-arrowhead\" d=\"M488.0,379.0 L492.0,371.0 484.0,371.0\" fill=\"currentColor\"/\n/g\n\ng class=\"displacy-arrow\"\n    path class=\"displacy-arc\" id=\"arrow-c2baa64957a84bfb9ce5180baa2e949c-4-4\" stroke-width=\"2px\" d=\"M362,377.0 362,327.0 641.0,327.0 641.0,377.0\" fill=\"none\" stroke=\"currentColor\"/\n    text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\"\n        textPath xlink:href=\"#arrow-c2baa64957a84bfb9ce5180baa2e949c-4-4\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\"conj/textPath\n    /text\n    path class=\"displacy-arrowhead\" d=\"M641.0,379.0 L645.0,371.0 637.0,371.0\" fill=\"currentColor\"/\n/g\n\ng class=\"displacy-arrow\"\n    path class=\"displacy-arc\" id=\"arrow-c2baa64957a84bfb9ce5180baa2e949c-4-5\" stroke-width=\"2px\" d=\"M812,377.0 812,352.0 938.0,352.0 938.0,377.0\" fill=\"none\" stroke=\"currentColor\"/\n    text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\"\n        textPath xlink:href=\"#arrow-c2baa64957a84bfb9ce5180baa2e949c-4-5\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\"prep/textPath\n    /text\n    path class=\"displacy-arrowhead\" d=\"M938.0,379.0 L942.0,371.0 934.0,371.0\" fill=\"currentColor\"/\n/g\n\ng class=\"displacy-arrow\"\n    path class=\"displacy-arc\" id=\"arrow-c2baa64957a84bfb9ce5180baa2e949c-4-6\" stroke-width=\"2px\" d=\"M1112,377.0 1112,352.0 1238.0,352.0 1238.0,377.0\" fill=\"none\" stroke=\"currentColor\"/\n    text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\"\n        textPath xlink:href=\"#arrow-c2baa64957a84bfb9ce5180baa2e949c-4-6\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\"det/textPath\n    /text\n    path class=\"displacy-arrowhead\" d=\"M1112,379.0 L1108,371.0 1116,371.0\" fill=\"currentColor\"/\n/g\n\ng class=\"displacy-arrow\"\n    path class=\"displacy-arc\" id=\"arrow-c2baa64957a84bfb9ce5180baa2e949c-4-7\" stroke-width=\"2px\" d=\"M962,377.0 962,327.0 1241.0,327.0 1241.0,377.0\" fill=\"none\" stroke=\"currentColor\"/\n    text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\"\n        textPath xlink:href=\"#arrow-c2baa64957a84bfb9ce5180baa2e949c-4-7\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\"pobj/textPath\n    /text\n    path class=\"displacy-arrowhead\" d=\"M1241.0,379.0 L1245.0,371.0 1237.0,371.0\" fill=\"currentColor\"/\n/g\n\ng class=\"displacy-arrow\"\n    path class=\"displacy-arc\" id=\"arrow-c2baa64957a84bfb9ce5180baa2e949c-4-8\" stroke-width=\"2px\" d=\"M812,377.0 812,277.0 1397.0,277.0 1397.0,377.0\" fill=\"none\" stroke=\"currentColor\"/\n    text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\"\n        textPath xlink:href=\"#arrow-c2baa64957a84bfb9ce5180baa2e949c-4-8\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\"cc/textPath\n    /text\n    path class=\"displacy-arrowhead\" d=\"M1397.0,379.0 L1401.0,371.0 1393.0,371.0\" fill=\"currentColor\"/\n/g\n\ng class=\"displacy-arrow\"\n    path class=\"displacy-arc\" id=\"arrow-c2baa64957a84bfb9ce5180baa2e949c-4-9\" stroke-width=\"2px\" d=\"M812,377.0 812,252.0 1550.0,252.0 1550.0,377.0\" fill=\"none\" stroke=\"currentColor\"/\n    text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\"\n        textPath xlink:href=\"#arrow-c2baa64957a84bfb9ce5180baa2e949c-4-9\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\"conj/textPath\n    /text\n    path class=\"displacy-arrowhead\" d=\"M1550.0,379.0 L1554.0,371.0 1546.0,371.0\" fill=\"currentColor\"/\n/g\n\ng class=\"displacy-arrow\"\n    path class=\"displacy-arc\" id=\"arrow-c2baa64957a84bfb9ce5180baa2e949c-4-10\" stroke-width=\"2px\" d=\"M1562,377.0 1562,352.0 1688.0,352.0 1688.0,377.0\" fill=\"none\" stroke=\"currentColor\"/\n    text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\"\n        textPath xlink:href=\"#arrow-c2baa64957a84bfb9ce5180baa2e949c-4-10\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\"dobj/textPath\n    /text\n    path class=\"displacy-arrowhead\" d=\"M1688.0,379.0 L1692.0,371.0 1684.0,371.0\" fill=\"currentColor\"/\n/g\n\ng class=\"displacy-arrow\"\n    path class=\"displacy-arc\" id=\"arrow-c2baa64957a84bfb9ce5180baa2e949c-4-11\" stroke-width=\"2px\" d=\"M1562,377.0 1562,327.0 1841.0,327.0 1841.0,377.0\" fill=\"none\" stroke=\"currentColor\"/\n    text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\"\n        textPath xlink:href=\"#arrow-c2baa64957a84bfb9ce5180baa2e949c-4-11\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\"prep/textPath\n    /text\n    path class=\"displacy-arrowhead\" d=\"M1841.0,379.0 L1845.0,371.0 1837.0,371.0\" fill=\"currentColor\"/\n/g\n\ng class=\"displacy-arrow\"\n    path class=\"displacy-arc\" id=\"arrow-c2baa64957a84bfb9ce5180baa2e949c-4-12\" stroke-width=\"2px\" d=\"M1862,377.0 1862,352.0 1988.0,352.0 1988.0,377.0\" fill=\"none\" stroke=\"currentColor\"/\n    text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\"\n        textPath xlink:href=\"#arrow-c2baa64957a84bfb9ce5180baa2e949c-4-12\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\"pobj/textPath\n    /text\n    path class=\"displacy-arrowhead\" d=\"M1988.0,379.0 L1992.0,371.0 1984.0,371.0\" fill=\"currentColor\"/\n/g\n\ng class=\"displacy-arrow\"\n    path class=\"displacy-arc\" id=\"arrow-c2baa64957a84bfb9ce5180baa2e949c-4-13\" stroke-width=\"2px\" d=\"M2012,377.0 2012,352.0 2138.0,352.0 2138.0,377.0\" fill=\"none\" stroke=\"currentColor\"/\n    text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\"\n        textPath xlink:href=\"#arrow-c2baa64957a84bfb9ce5180baa2e949c-4-13\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\"prep/textPath\n    /text\n    path class=\"displacy-arrowhead\" d=\"M2138.0,379.0 L2142.0,371.0 2134.0,371.0\" fill=\"currentColor\"/\n/g\n\ng class=\"displacy-arrow\"\n    path class=\"displacy-arc\" id=\"arrow-c2baa64957a84bfb9ce5180baa2e949c-4-14\" stroke-width=\"2px\" d=\"M2162,377.0 2162,352.0 2288.0,352.0 2288.0,377.0\" fill=\"none\" stroke=\"currentColor\"/\n    text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\"\n        textPath xlink:href=\"#arrow-c2baa64957a84bfb9ce5180baa2e949c-4-14\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\"pobj/textPath\n    /text\n    path class=\"displacy-arrowhead\" d=\"M2288.0,379.0 L2292.0,371.0 2284.0,371.0\" fill=\"currentColor\"/\n/g\n/svg\n\nsvg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"en\" id=\"c2baa64957a84bfb9ce5180baa2e949c-5\" class=\"displacy\" width=\"3950\" height=\"512.0\" direction=\"ltr\" style=\"max-width: none; height: 512.0px; color: white; background: #09a3d5; font-family: Source Sans Pro; direction: ltr\"\ntext class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"422.0\"\n    tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\"Hero/tspan\n    tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\"NOUN/tspan\n/text\n\ntext class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"422.0\"\n    tspan class=\"displacy-word\" fill=\"currentColor\" x=\"200\"confides/tspan\n    tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"200\"VERB/tspan\n/text\n\ntext class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"422.0\"\n    tspan class=\"displacy-word\" fill=\"currentColor\" x=\"350\"in/tspan\n    tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"350\"ADP/tspan\n/text\n\ntext class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"422.0\"\n    tspan class=\"displacy-word\" fill=\"currentColor\" x=\"500\"Pseudolus/tspan\n    tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"500\"PROPN/tspan\n/text\n\ntext class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"422.0\"\n    tspan class=\"displacy-word\" fill=\"currentColor\" x=\"650\"that/tspan\n    tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"650\"SCONJ/tspan\n/text\n\ntext class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"422.0\"\n    tspan class=\"displacy-word\" fill=\"currentColor\" x=\"800\"he/tspan\n    tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"800\"PRON/tspan\n/text\n\ntext class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"422.0\"\n    tspan class=\"displacy-word\" fill=\"currentColor\" x=\"950\"is/tspan\n    tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"950\"AUX/tspan\n/text\n\ntext class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"422.0\"\n    tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1100\"in/tspan\n    tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1100\"ADP/tspan\n/text\n\ntext class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"422.0\"\n    tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1250\"love/tspan\n    tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1250\"NOUN/tspan\n/text\n\ntext class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"422.0\"\n    tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1400\"with/tspan\n    tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1400\"ADP/tspan\n/text\n\ntext class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"422.0\"\n    tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1550\"the/tspan\n    tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1550\"DET/tspan\n/text\n\ntext class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"422.0\"\n    tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1700\"lovely/tspan\n    tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1700\"ADJ/tspan\n/text\n\ntext class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"422.0\"\n    tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1850\"Philia,/tspan\n    tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1850\"PROPN/tspan\n/text\n\ntext class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"422.0\"\n    tspan class=\"displacy-word\" fill=\"currentColor\" x=\"2000\"one/tspan\n    tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"2000\"NUM/tspan\n/text\n\ntext class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"422.0\"\n    tspan class=\"displacy-word\" fill=\"currentColor\" x=\"2150\"of/tspan\n    tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"2150\"ADP/tspan\n/text\n\ntext class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"422.0\"\n    tspan class=\"displacy-word\" fill=\"currentColor\" x=\"2300\"the/tspan\n    tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"2300\"DET/tspan\n/text\n\ntext class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"422.0\"\n    tspan class=\"displacy-word\" fill=\"currentColor\" x=\"2450\"courtesans/tspan\n    tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"2450\"NOUN/tspan\n/text\n\ntext class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"422.0\"\n    tspan class=\"displacy-word\" fill=\"currentColor\" x=\"2600\"in/tspan\n    tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"2600\"ADP/tspan\n/text\n\ntext class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"422.0\"\n    tspan class=\"displacy-word\" fill=\"currentColor\" x=\"2750\"the/tspan\n    tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"2750\"DET/tspan\n/text\n\ntext class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"422.0\"\n    tspan class=\"displacy-word\" fill=\"currentColor\" x=\"2900\"House/tspan\n    tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"2900\"PROPN/tspan\n/text\n\ntext class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"422.0\"\n    tspan class=\"displacy-word\" fill=\"currentColor\" x=\"3050\"of/tspan\n    tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"3050\"ADP/tspan\n/text\n\ntext class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"422.0\"\n    tspan class=\"displacy-word\" fill=\"currentColor\" x=\"3200\"Lycus (/tspan\n    tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"3200\"PROPN/tspan\n/text\n\ntext class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"422.0\"\n    tspan class=\"displacy-word\" fill=\"currentColor\" x=\"3350\"albeit/tspan\n    tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"3350\"SCONJ/tspan\n/text\n\ntext class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"422.0\"\n    tspan class=\"displacy-word\" fill=\"currentColor\" x=\"3500\"still/tspan\n    tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"3500\"ADV/tspan\n/text\n\ntext class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"422.0\"\n    tspan class=\"displacy-word\" fill=\"currentColor\" x=\"3650\"a/tspan\n    tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"3650\"DET/tspan\n/text\n\ntext class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"422.0\"\n    tspan class=\"displacy-word\" fill=\"currentColor\" x=\"3800\"virgin)./tspan\n    tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"3800\"NOUN/tspan\n/text\n\ng class=\"displacy-arrow\"\n    path class=\"displacy-arc\" id=\"arrow-c2baa64957a84bfb9ce5180baa2e949c-5-0\" stroke-width=\"2px\" d=\"M62,377.0 62,352.0 188.0,352.0 188.0,377.0\" fill=\"none\" stroke=\"currentColor\"/\n    text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\"\n        textPath xlink:href=\"#arrow-c2baa64957a84bfb9ce5180baa2e949c-5-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\"nsubj/textPath\n    /text\n    path class=\"displacy-arrowhead\" d=\"M62,379.0 L58,371.0 66,371.0\" fill=\"currentColor\"/\n/g\n\ng class=\"displacy-arrow\"\n    path class=\"displacy-arc\" id=\"arrow-c2baa64957a84bfb9ce5180baa2e949c-5-1\" stroke-width=\"2px\" d=\"M212,377.0 212,352.0 338.0,352.0 338.0,377.0\" fill=\"none\" stroke=\"currentColor\"/\n    text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\"\n        textPath xlink:href=\"#arrow-c2baa64957a84bfb9ce5180baa2e949c-5-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\"prep/textPath\n    /text\n    path class=\"displacy-arrowhead\" d=\"M338.0,379.0 L342.0,371.0 334.0,371.0\" fill=\"currentColor\"/\n/g\n\ng class=\"displacy-arrow\"\n    path class=\"displacy-arc\" id=\"arrow-c2baa64957a84bfb9ce5180baa2e949c-5-2\" stroke-width=\"2px\" d=\"M362,377.0 362,352.0 488.0,352.0 488.0,377.0\" fill=\"none\" stroke=\"currentColor\"/\n    text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\"\n        textPath xlink:href=\"#arrow-c2baa64957a84bfb9ce5180baa2e949c-5-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\"pobj/textPath\n    /text\n    path class=\"displacy-arrowhead\" d=\"M488.0,379.0 L492.0,371.0 484.0,371.0\" fill=\"currentColor\"/\n/g\n\ng class=\"displacy-arrow\"\n    path class=\"displacy-arc\" id=\"arrow-c2baa64957a84bfb9ce5180baa2e949c-5-3\" stroke-width=\"2px\" d=\"M662,377.0 662,327.0 941.0,327.0 941.0,377.0\" fill=\"none\" stroke=\"currentColor\"/\n    text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\"\n        textPath xlink:href=\"#arrow-c2baa64957a84bfb9ce5180baa2e949c-5-3\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\"mark/textPath\n    /text\n    path class=\"displacy-arrowhead\" d=\"M662,379.0 L658,371.0 666,371.0\" fill=\"currentColor\"/\n/g\n\ng class=\"displacy-arrow\"\n    path class=\"displacy-arc\" id=\"arrow-c2baa64957a84bfb9ce5180baa2e949c-5-4\" stroke-width=\"2px\" d=\"M812,377.0 812,352.0 938.0,352.0 938.0,377.0\" fill=\"none\" stroke=\"currentColor\"/\n    text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\"\n        textPath xlink:href=\"#arrow-c2baa64957a84bfb9ce5180baa2e949c-5-4\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\"nsubj/textPath\n    /text\n    path class=\"displacy-arrowhead\" d=\"M812,379.0 L808,371.0 816,371.0\" fill=\"currentColor\"/\n/g\n\ng class=\"displacy-arrow\"\n    path class=\"displacy-arc\" id=\"arrow-c2baa64957a84bfb9ce5180baa2e949c-5-5\" stroke-width=\"2px\" d=\"M212,377.0 212,277.0 947.0,277.0 947.0,377.0\" fill=\"none\" stroke=\"currentColor\"/\n    text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\"\n        textPath xlink:href=\"#arrow-c2baa64957a84bfb9ce5180baa2e949c-5-5\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\"ccomp/textPath\n    /text\n    path class=\"displacy-arrowhead\" d=\"M947.0,379.0 L951.0,371.0 943.0,371.0\" fill=\"currentColor\"/\n/g\n\ng class=\"displacy-arrow\"\n    path class=\"displacy-arc\" id=\"arrow-c2baa64957a84bfb9ce5180baa2e949c-5-6\" stroke-width=\"2px\" d=\"M962,377.0 962,352.0 1088.0,352.0 1088.0,377.0\" fill=\"none\" stroke=\"currentColor\"/\n    text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\"\n        textPath xlink:href=\"#arrow-c2baa64957a84bfb9ce5180baa2e949c-5-6\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\"prep/textPath\n    /text\n    path class=\"displacy-arrowhead\" d=\"M1088.0,379.0 L1092.0,371.0 1084.0,371.0\" fill=\"currentColor\"/\n/g\n\ng class=\"displacy-arrow\"\n    path class=\"displacy-arc\" id=\"arrow-c2baa64957a84bfb9ce5180baa2e949c-5-7\" stroke-width=\"2px\" d=\"M1112,377.0 1112,352.0 1238.0,352.0 1238.0,377.0\" fill=\"none\" stroke=\"currentColor\"/\n    text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\"\n        textPath xlink:href=\"#arrow-c2baa64957a84bfb9ce5180baa2e949c-5-7\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\"pobj/textPath\n    /text\n    path class=\"displacy-arrowhead\" d=\"M1238.0,379.0 L1242.0,371.0 1234.0,371.0\" fill=\"currentColor\"/\n/g\n\ng class=\"displacy-arrow\"\n    path class=\"displacy-arc\" id=\"arrow-c2baa64957a84bfb9ce5180baa2e949c-5-8\" stroke-width=\"2px\" d=\"M1262,377.0 1262,352.0 1388.0,352.0 1388.0,377.0\" fill=\"none\" stroke=\"currentColor\"/\n    text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\"\n        textPath xlink:href=\"#arrow-c2baa64957a84bfb9ce5180baa2e949c-5-8\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\"prep/textPath\n    /text\n    path class=\"displacy-arrowhead\" d=\"M1388.0,379.0 L1392.0,371.0 1384.0,371.0\" fill=\"currentColor\"/\n/g\n\ng class=\"displacy-arrow\"\n    path class=\"displacy-arc\" id=\"arrow-c2baa64957a84bfb9ce5180baa2e949c-5-9\" stroke-width=\"2px\" d=\"M1562,377.0 1562,327.0 1841.0,327.0 1841.0,377.0\" fill=\"none\" stroke=\"currentColor\"/\n    text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\"\n        textPath xlink:href=\"#arrow-c2baa64957a84bfb9ce5180baa2e949c-5-9\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\"det/textPath\n    /text\n    path class=\"displacy-arrowhead\" d=\"M1562,379.0 L1558,371.0 1566,371.0\" fill=\"currentColor\"/\n/g\n\ng class=\"displacy-arrow\"\n    path class=\"displacy-arc\" id=\"arrow-c2baa64957a84bfb9ce5180baa2e949c-5-10\" stroke-width=\"2px\" d=\"M1712,377.0 1712,352.0 1838.0,352.0 1838.0,377.0\" fill=\"none\" stroke=\"currentColor\"/\n    text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\"\n        textPath xlink:href=\"#arrow-c2baa64957a84bfb9ce5180baa2e949c-5-10\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\"amod/textPath\n    /text\n    path class=\"displacy-arrowhead\" d=\"M1712,379.0 L1708,371.0 1716,371.0\" fill=\"currentColor\"/\n/g\n\ng class=\"displacy-arrow\"\n    path class=\"displacy-arc\" id=\"arrow-c2baa64957a84bfb9ce5180baa2e949c-5-11\" stroke-width=\"2px\" d=\"M1412,377.0 1412,302.0 1844.0,302.0 1844.0,377.0\" fill=\"none\" stroke=\"currentColor\"/\n    text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\"\n        textPath xlink:href=\"#arrow-c2baa64957a84bfb9ce5180baa2e949c-5-11\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\"pobj/textPath\n    /text\n    path class=\"displacy-arrowhead\" d=\"M1844.0,379.0 L1848.0,371.0 1840.0,371.0\" fill=\"currentColor\"/\n/g\n\ng class=\"displacy-arrow\"\n    path class=\"displacy-arc\" id=\"arrow-c2baa64957a84bfb9ce5180baa2e949c-5-12\" stroke-width=\"2px\" d=\"M1862,377.0 1862,352.0 1988.0,352.0 1988.0,377.0\" fill=\"none\" stroke=\"currentColor\"/\n    text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\"\n        textPath xlink:href=\"#arrow-c2baa64957a84bfb9ce5180baa2e949c-5-12\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\"appos/textPath\n    /text\n    path class=\"displacy-arrowhead\" d=\"M1988.0,379.0 L1992.0,371.0 1984.0,371.0\" fill=\"currentColor\"/\n/g\n\ng class=\"displacy-arrow\"\n    path class=\"displacy-arc\" id=\"arrow-c2baa64957a84bfb9ce5180baa2e949c-5-13\" stroke-width=\"2px\" d=\"M2012,377.0 2012,352.0 2138.0,352.0 2138.0,377.0\" fill=\"none\" stroke=\"currentColor\"/\n    text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\"\n        textPath xlink:href=\"#arrow-c2baa64957a84bfb9ce5180baa2e949c-5-13\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\"prep/textPath\n    /text\n    path class=\"displacy-arrowhead\" d=\"M2138.0,379.0 L2142.0,371.0 2134.0,371.0\" fill=\"currentColor\"/\n/g\n\ng class=\"displacy-arrow\"\n    path class=\"displacy-arc\" id=\"arrow-c2baa64957a84bfb9ce5180baa2e949c-5-14\" stroke-width=\"2px\" d=\"M2312,377.0 2312,352.0 2438.0,352.0 2438.0,377.0\" fill=\"none\" stroke=\"currentColor\"/\n    text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\"\n        textPath xlink:href=\"#arrow-c2baa64957a84bfb9ce5180baa2e949c-5-14\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\"det/textPath\n    /text\n    path class=\"displacy-arrowhead\" d=\"M2312,379.0 L2308,371.0 2316,371.0\" fill=\"currentColor\"/\n/g\n\ng class=\"displacy-arrow\"\n    path class=\"displacy-arc\" id=\"arrow-c2baa64957a84bfb9ce5180baa2e949c-5-15\" stroke-width=\"2px\" d=\"M2162,377.0 2162,327.0 2441.0,327.0 2441.0,377.0\" fill=\"none\" stroke=\"currentColor\"/\n    text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\"\n        textPath xlink:href=\"#arrow-c2baa64957a84bfb9ce5180baa2e949c-5-15\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\"pobj/textPath\n    /text\n    path class=\"displacy-arrowhead\" d=\"M2441.0,379.0 L2445.0,371.0 2437.0,371.0\" fill=\"currentColor\"/\n/g\n\ng class=\"displacy-arrow\"\n    path class=\"displacy-arc\" id=\"arrow-c2baa64957a84bfb9ce5180baa2e949c-5-16\" stroke-width=\"2px\" d=\"M2462,377.0 2462,352.0 2588.0,352.0 2588.0,377.0\" fill=\"none\" stroke=\"currentColor\"/\n    text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\"\n        textPath xlink:href=\"#arrow-c2baa64957a84bfb9ce5180baa2e949c-5-16\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\"prep/textPath\n    /text\n    path class=\"displacy-arrowhead\" d=\"M2588.0,379.0 L2592.0,371.0 2584.0,371.0\" fill=\"currentColor\"/\n/g\n\ng class=\"displacy-arrow\"\n    path class=\"displacy-arc\" id=\"arrow-c2baa64957a84bfb9ce5180baa2e949c-5-17\" stroke-width=\"2px\" d=\"M2762,377.0 2762,352.0 2888.0,352.0 2888.0,377.0\" fill=\"none\" stroke=\"currentColor\"/\n    text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\"\n        textPath xlink:href=\"#arrow-c2baa64957a84bfb9ce5180baa2e949c-5-17\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\"det/textPath\n    /text\n    path class=\"displacy-arrowhead\" d=\"M2762,379.0 L2758,371.0 2766,371.0\" fill=\"currentColor\"/\n/g\n\ng class=\"displacy-arrow\"\n    path class=\"displacy-arc\" id=\"arrow-c2baa64957a84bfb9ce5180baa2e949c-5-18\" stroke-width=\"2px\" d=\"M2612,377.0 2612,327.0 2891.0,327.0 2891.0,377.0\" fill=\"none\" stroke=\"currentColor\"/\n    text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\"\n        textPath xlink:href=\"#arrow-c2baa64957a84bfb9ce5180baa2e949c-5-18\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\"pobj/textPath\n    /text\n    path class=\"displacy-arrowhead\" d=\"M2891.0,379.0 L2895.0,371.0 2887.0,371.0\" fill=\"currentColor\"/\n/g\n\ng class=\"displacy-arrow\"\n    path class=\"displacy-arc\" id=\"arrow-c2baa64957a84bfb9ce5180baa2e949c-5-19\" stroke-width=\"2px\" d=\"M2912,377.0 2912,352.0 3038.0,352.0 3038.0,377.0\" fill=\"none\" stroke=\"currentColor\"/\n    text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\"\n        textPath xlink:href=\"#arrow-c2baa64957a84bfb9ce5180baa2e949c-5-19\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\"prep/textPath\n    /text\n    path class=\"displacy-arrowhead\" d=\"M3038.0,379.0 L3042.0,371.0 3034.0,371.0\" fill=\"currentColor\"/\n/g\n\ng class=\"displacy-arrow\"\n    path class=\"displacy-arc\" id=\"arrow-c2baa64957a84bfb9ce5180baa2e949c-5-20\" stroke-width=\"2px\" d=\"M3062,377.0 3062,352.0 3188.0,352.0 3188.0,377.0\" fill=\"none\" stroke=\"currentColor\"/\n    text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\"\n        textPath xlink:href=\"#arrow-c2baa64957a84bfb9ce5180baa2e949c-5-20\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\"pobj/textPath\n    /text\n    path class=\"displacy-arrowhead\" d=\"M3188.0,379.0 L3192.0,371.0 3184.0,371.0\" fill=\"currentColor\"/\n/g\n\ng class=\"displacy-arrow\"\n    path class=\"displacy-arc\" id=\"arrow-c2baa64957a84bfb9ce5180baa2e949c-5-21\" stroke-width=\"2px\" d=\"M962,377.0 962,252.0 3350.0,252.0 3350.0,377.0\" fill=\"none\" stroke=\"currentColor\"/\n    text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\"\n        textPath xlink:href=\"#arrow-c2baa64957a84bfb9ce5180baa2e949c-5-21\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\"advmod/textPath\n    /text\n    path class=\"displacy-arrowhead\" d=\"M3350.0,379.0 L3354.0,371.0 3346.0,371.0\" fill=\"currentColor\"/\n/g\n\ng class=\"displacy-arrow\"\n    path class=\"displacy-arc\" id=\"arrow-c2baa64957a84bfb9ce5180baa2e949c-5-22\" stroke-width=\"2px\" d=\"M3512,377.0 3512,327.0 3791.0,327.0 3791.0,377.0\" fill=\"none\" stroke=\"currentColor\"/\n    text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\"\n        textPath xlink:href=\"#arrow-c2baa64957a84bfb9ce5180baa2e949c-5-22\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\"advmod/textPath\n    /text\n    path class=\"displacy-arrowhead\" d=\"M3512,379.0 L3508,371.0 3516,371.0\" fill=\"currentColor\"/\n/g\n\ng class=\"displacy-arrow\"\n    path class=\"displacy-arc\" id=\"arrow-c2baa64957a84bfb9ce5180baa2e949c-5-23\" stroke-width=\"2px\" d=\"M3662,377.0 3662,352.0 3788.0,352.0 3788.0,377.0\" fill=\"none\" stroke=\"currentColor\"/\n    text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\"\n        textPath xlink:href=\"#arrow-c2baa64957a84bfb9ce5180baa2e949c-5-23\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\"det/textPath\n    /text\n    path class=\"displacy-arrowhead\" d=\"M3662,379.0 L3658,371.0 3666,371.0\" fill=\"currentColor\"/\n/g\n\ng class=\"displacy-arrow\"\n    path class=\"displacy-arc\" id=\"arrow-c2baa64957a84bfb9ce5180baa2e949c-5-24\" stroke-width=\"2px\" d=\"M3362,377.0 3362,302.0 3794.0,302.0 3794.0,377.0\" fill=\"none\" stroke=\"currentColor\"/\n    text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\"\n        textPath xlink:href=\"#arrow-c2baa64957a84bfb9ce5180baa2e949c-5-24\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\"pobj/textPath\n    /text\n    path class=\"displacy-arrowhead\" d=\"M3794.0,379.0 L3798.0,371.0 3790.0,371.0\" fill=\"currentColor\"/\n/g\n/svg\n\nimport spacy\nfrom spacy import displacy\n\ntext = \"When Sebastian Thrun started working on self-driving cars at Google in 2007, few people outside of the company took him seriously.\"\n\nnlp = spacy.load(\"encoreweb_sm\")\ndoc = nlp(text)\ndisplacy.render(doc, style=\"ent\")\n\ndiv class=\"entities\" style=\"line-height: 2.5; direction: ltr\"When \nmark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\"\n    Sebastian Thrun\n    span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\"PERSON/span\n/mark\n started working on self-driving cars at \nmark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\"\n    Google\n    span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\"ORG/span\n/mark\n in \nmark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\"\n    2007\n    span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\"DATE/span\n/mark\n, few people outside of the company took him seriously./div\n\ncolors = {\"ORG\": \"linear-gradient(90deg, #aa9cfc, #fc9ce7)\"}\noptions = {\"ents\": [\"ORG\"], \"colors\": colors}\n\ndisplacy.render(doc, style=\"ent\", options=options)\n\ndiv class=\"entities\" style=\"line-height: 2.5; direction: ltr\"When Sebastian Thrun started working on self-driving cars at \nmark class=\"entity\" style=\"background: linear-gradient(90deg, #aa9cfc, #fc9ce7); padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\"\n    Google\n    span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\"ORG/span\n/mark\n in 2007, few people outside of the company took him seriously./div\n\n{\n    \"words\": [\n        {\"text\": \"This\", \"tag\": \"DT\"},\n        {\"text\": \"is\", \"tag\": \"VBZ\"},\n        {\"text\": \"a\", \"tag\": \"DT\"},\n        {\"text\": \"sentence\", \"tag\": \"NN\"}\n    ],\n    \"arcs\": [\n        {\"start\": 0, \"end\": 1, \"label\": \"nsubj\", \"dir\": \"left\"},\n        {\"start\": 2, \"end\": 3, \"label\": \"det\", \"dir\": \"left\"},\n        {\"start\": 1, \"end\": 3, \"label\": \"attr\", \"dir\": \"right\"}\n    ]\n}\n\nex = [{\"text\": \"But Google is starting from behind.\",\n       \"ents\": [{\"start\": 4, \"end\": 10, \"label\": \"ORG\"}],\n       \"title\": None}]\nhtml = displacy.render(ex, style=\"ent\", manual=True)\n\ndiv class=\"entities\" style=\"line-height: 2.5; direction: ltr\"But \nmark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\"\n    Google\n    span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\"ORG/span\n/mark\n is starting from behind./div\n\nRule-based matching\n\nMatch exact token texts: [{'TEXT': 'iPhone'}, {'TEXT': 'X'}]\nMatch lexical attributes: [{'LOWER': 'iphone'}, {'LOWER': 'x'}]\nMatch any token attributes: [{'LEMMA': 'buy'}, {'POS': 'NOUN'}]\n\n Import the Matcher\nfrom spacy.matcher import Matcher\n\ntext = \"New iPhone X release date leaked as Apple reveals pre-orders by mistake\"\n\nInitialize the matcher with the shared vocab\nmatcher = Matcher(nlp.vocab)\n\n Add the pattern to the matcher\npattern = [{'TEXT': 'iPhone'}, {'TEXT': 'X'}]\nmatcher.add('IPHONE_PATTERN', None, pattern)\n\nProcess some text\ndoc = nlp(\"New iPhone X release date leaked\")\n\n Call the matcher on the doc\nmatches = matcher(doc)\n\nmatch_id: hash value of the pattern name\nstart: start index of matched span\nend: end index of matched span\n\n Iterate over the matches\nfor match_id, start, end in matches:\n    # Get the matched span\n    matched_span = doc[start:end]\n    print(matched_span.text)\n\n{{ output }}\n[(9528407286733565721, 1, 3)]\n{{ /output }}\n\nWrite a pattern that matches a form of \"download\" plus proper noun\npattern = [{\"LEMMA\": \"download\"}, {\"POS\": \"PROPN\"}]\n Write a pattern for adjective plus one or two nouns\npattern = [{\"POS\": _}, {\"POS\": _}, {\"POS\": _, \"OP\": _}]\n\nLarge-scale data analysis with spaCy\n\n Vocab, hashes, lexeme\n\nvocab stores data shared across multiple documents.  The doc contains words in context with their part-of-speech tags and dependencies. The string store maintains the text of the vocab hashes.\n\nA lexeme object is an hash entry in the vocabulary vocab.  lexemes hold context-independent information about a word, like the text, or whether the the word consists of alphabetic characters.  Don't have part-of-speech tags, dependencies or entity labels. Those depend on the context.\n\nnlp.vocab.length\n\n{{ output }}\n498\n{{ /output }}\n\nHashes can't be reversed  that's why we need to provide the shared vocab\ncoffee_hash = nlp.vocab.strings['coffee']\nprint(coffee_hash)\n\n{{ output }}\n3197928453018144401\n{{ /output }}\n\n Raises an error if we haven't seen the string before\nstring = nlp.vocab.strings[3197928453018144401]\n\ndoc = nlp(\"I love coffee\")\nprint('hash value:', nlp.vocab.strings['coffee'], doc.vocab.strings['coffee'])\nprint('string value:', nlp.vocab.strings[3197928453018144401])\n\n{{ output }}\nhash value: 3197928453018144401 3197928453018144401\nstring value: coffee\n{{ /output }}\n\ncontains the context-independent information\ndoc = nlp(\"I love coffee\")\nlexeme = nlp.vocab['coffee']\n\n Print the lexical attributes\nprint(lexeme.text, lexeme.orth, lexeme.is_alpha)\n\n{{ output }}\ncoffee 3197928453018144401 True\n{{ /output }}\n\nDoc, span, and token\n\nDoc is created automatically when you process a text with the nlp object. But you can also instantiate the class manually.  It takes three arguments: the shared vocab, the words and the spaces.\n\nA Span is a slice of a Doc consisting of one or more tokens. The Span takes at least three arguments: the doc it refers to, and the start and end index of the span (with end index exclusive).\n\nDoc and Span are very powerful and hold references and relationships of words and sentences\n\nConvert result to strings as late as possible\nUse token attributes if available  for example, token.i for the token index.  This will let you reuse it in spaCy.\n\n Create an nlp object\nfrom spacy.lang.en import English\nnlp = English()\n\nImport the Doc class\nfrom spacy.tokens import Doc\n\n The words and spaces to create the doc from\nwords = ['Hello', 'world', '!']\nspaces = [True, False, False]\n\nCreate a doc manually\ndoc = Doc(nlp.vocab, words=words, spaces=spaces)\ndoc\n\n{{ output }}\nHello world!\n{{ /output }}\n\n Import the Doc class\nfrom spacy.tokens import Span\n\nCreate a doc manually\ndoc = Doc(nlp.vocab, words=words, spaces=spaces)\n\n Create a span manually\nspan = Span(doc, 0, 2)\n\nCreate a span with a label\nspanwithlabel = Span(doc, 0, 2, label=\"GREETING\")\n\n Add span to the doc.ents\ndoc.ents = [spanwithlabel]\n\nPrint entities' text and labels\nprint([(ent.text, ent.label_) for ent in doc.ents])\n\n{{ output }}\n[('I like', 'GREETING')]\n{{ /output }}\n\n Similarity and vectors\n\nIn order to use similarity, you need a larger spaCy model that has word vectors included (encoreweblg, encorewebmd  but not _sm).  That is because similarity is determined using word vectors.  Word vectors are generated using an algorithm like Word2Vec and lots of text.  The default distance is cosine similarity, but can be adjusted.\n\nFor a more in-depth look, the source code for .similarity shows:\n\nreturn numpy.dot(self.vector, other.vector) / (self.vectornorm * other.vectornorm)\n\nLoad a larger model with vectors\nnlp = spacy.load('encoreweb_lg')\n\n Compare two documents\ndoc1 = nlp(\"I like fast food\")\ndoc2 = nlp(\"I like pizza\")\nprint(doc1.similarity(doc2))\n\ndoc = nlp(\"I like pizza and pasta\")\ntoken1 = doc[2]\ntoken2 = doc[4]\nprint(token1.similarity(token2))\n\n{{ output }}\n0.8627203210548107\n0.7369546\n{{ /output }}\n\nnlp = spacy.load('encoreweb_sm')\ndoc1 = nlp(\"I\")\nprint( doc1.vector.shape )\n\n{{ output }}\n(96,)\n{{ /output }}\n\nnlp = spacy.load('encoreweb_lg')\ndoc1 = nlp(\"I\")\nprint( doc1.vector.shape )\n\n{{ output }}\n(300,)\n{{ /output }}\n\nnlp = spacy.load('encoreweb_sm')\n\ndoc1 = nlp(\"I\")\ndoc2 = nlp(\"like\")\ndoc3 = nlp(\"I like\")\ndoc4 = nlp(\"I like pizza\")\n\nprint( doc1.vector.shape, ' ', doc1.vector_norm )\nprint( doc2.vector.shape, ' ', doc2.vector_norm )\nprint( doc3.vector.shape, ' ', doc3.vector_norm )\nprint( doc4.vector.shape, ' ', doc4.vector_norm )\n\n{{ output }}\n(96,)   23.1725315055188\n(96,)   21.75560300132138\n(96,)   17.23478412191207\n(96,)   14.848700829346688\n{{ /output }}\n\ndoc1[0].vector == doc3[0].vector\n\n{{ output }}\narray([False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False])\n{{ /output }}\n\nprint( np.dot(doc1.vector, doc2.vector) )\nprint( np.linalg.norm(doc2.vector, ord=2) )\nprint( np.linalg.norm(doc1.vector, ord=2) == np.linalg.norm(doc2.vector, ord=2) )\nprint( doc2.vector_norm )\n\n{{ output }}\n21.871986\n4.6767497\nTrue\n4.676749731219555\n{{ /output }}\n\ndoc1 = nlp(\"pizza like I\")\ndoc2 = nlp(\"I like pizza\")\ndoc3 = nlp(\"pizza I like\")\ndoc4 = nlp(\"like pizza I\")\ndoc5 = nlp(\"I pizza like\")\ndoc6 = nlp(\"like I pizza\")\n\nlDoc = [doc1, doc2, doc3, doc4, doc5, doc6]\nresult = np.zeros((6,6))\nfor i,doc1 in enumerate(lDoc):\n    for j, doc2 in enumerate(lDoc):\n        result[i,j] = doc1.similarity(doc2)\n\nresult\n\n{{ output }}\narray([[1.        , 0.99999994, 0.99999994, 0.99999995, 0.99999994,\n        0.99999994],\n       [0.99999994, 1.        , 0.99999993, 0.99999994, 0.99999993,\n        0.99999992],\n       [0.99999994, 0.99999993, 1.        , 0.99999994, 0.99999993,\n        0.99999993],\n       [0.99999995, 0.99999994, 0.99999994, 1.        , 0.99999994,\n        0.99999994],\n       [0.99999994, 0.99999993, 0.99999993, 0.99999994, 1.        ,\n        0.99999993],\n       [0.99999994, 0.99999992, 0.99999993, 0.99999994, 0.99999993,\n        ]])\n{{ /output }}\n\nnlp = spacy.load('encoreweb_lg')\n\ndoc1 = nlp(\"apples oranges fruit\")\nprint( doc1[0].vector_norm )\nprint( doc1[1].vector_norm )\nprint( doc1[2].vector_norm )\n\nprint( doc1[0].similarity(doc1[1]))\nprint( doc1[0].similarity(doc1[2]))\n\n{{ output }}\n6.895898\n6.949064\n7.294794\n0.77809423\n0.72417974\n{{ /output }}\n\ndoc1 = nlp(\"apples\")\ndoc2 = nlp(\"apples apples apples apples apples apples apples apples apples apples apples apples apples apples apples apples apples apples\")\n\nprint(doc1.vector_norm)\nprint(doc2.vector_norm)\nprint(doc1.similarity(doc2))\n\n{{ output }}\n6.895897646384268\n6.895897762990182\n1.0000000930092277\n{{ /output }}\n\ndoc1 = nlp(\"apples fruit\")\ndoc2 = nlp(\"apples apples apples apples apples apples apples apples apples apples apples apples apples apples apples apples apples apples fruit\")\n\nprint(doc1.vector_norm)\nprint(doc2.vector_norm)\nprint(doc1.similarity(doc2))\n\n{{ output }}\n6.588359567392134\n6.816139083280562\n0.9383865534490474\n{{ /output }}\n\nLoad a larger model with vectors\nnlp = spacy.load('encoreweb_lg')\n\ndoc = nlp(\"I have a banana\")\nAccess the word vector via the token.vector attribute\nvector = doc[3].vector\nprint( type(vector) )\nprint( vector.shape)\n\n{{ output }}\nclass 'numpy.ndarray'\n(300,)\n{{ /output }}\n\nvector[0:10]\n\n{{ output }}\narray([ 0.20228 , -0.076618,  0.37032 ,  0.032845, -0.41957 ,  0.072069,\n       -0.37476 ,  0.05746 , -0.012401,  0.52949 ], dtype=float32)\n{{ /output }}\n\nno universal definition for similarity \ndoc1 = nlp(\"I like cats\")\ndoc2 = nlp(\"I hate cats\")\n\nprint(doc1.similarity(doc2))\n\n{{ output }}\n0.9501447503553421\n{{ /output }}\n\nPattern matching\n\nimport spacy\nfrom spacy.matcher import Matcher\n\nnlp = spacy.load(\"encoreweb_sm\")\ndoc = nlp(\n    \"Twitch Prime, the perks program for Amazon Prime members offering free \"\n    \"loot, games and other benefits, is ditching one of its best features: \"\n    \"ad-free viewing. According to an email sent out to Amazon Prime members \"\n    \"today, ad-free viewing will no longer be included as a part of Twitch \"\n    \"Prime for new members, beginning on September 14. However, members with \"\n    \"existing annual subscriptions will be able to continue to enjoy ad-free \"\n    \"viewing until their subscription comes up for renewal. Those with \"\n    \"monthly subscriptions will have access to ad-free viewing until October 15.\"\n)\n\n Create the match patterns\npattern1 = [{\"LOWER\": \"Amazon\"}, {\"IS_TITLE\": True, \"POS\": \"PROPN\"}]\npattern2 = [{\"LOWER\": \"ad-free\"}, {\"POS\": \"NOUN\"}]\n\nInitialize the Matcher and add the patterns\nmatcher = Matcher(nlp.vocab)\nmatcher.add(\"PATTERN1\", None, pattern1)\nmatcher.add(\"PATTERN2\", None, pattern2)\n\n Iterate over the matches\nfor match_id, start, end in matcher(doc):\n    # Print pattern string name and text of matched span\n    print(doc.vocab.strings[match_id], doc[start:end].text)\n\nimport json\nfrom spacy.lang.en import English\n\nwith open(\"exercises/countries.json\") as f:\n    COUNTRIES = json.loads(f.read())\n\nnlp = English()\ndoc = nlp(\"Czech Republic may help Slovakia protect its airspace\")\n\nImport the PhraseMatcher and initialize it\nfrom spacy.matcher import PhraseMatcher\n\nmatcher = PhraseMatcher(nlp.vocab)\n\n Create pattern Doc objects and add them to the matcher\nThis is the faster version of: [nlp(country) for country in COUNTRIES]\npatterns = list(nlp.pipe(COUNTRIES))\nmatcher.add(\"COUNTRY\", None, *patterns)\n\n Call the matcher on the test document and print the result\nmatches = matcher(doc)\nprint([doc[start:end] for match_id, start, end in matches])\n\nProcessing Pipelines\n\n OOB pipeline components\n\nFirst, the tokenizer is applied to turn the string of text into a Doc object. Next, a series of pipeline components is applied to the Doc in order. In this case, the tagger, then the parser, then the entity recognizer. Finally, the processed Doc is returned, so you can work with it.\n\n|Name   | Description  | Creates  |\n|---|---|---|\n|tagger   | Part-of-speech tagger  | Token.tag  |\n|parser   | Dependency parser  | Token.dep, Token.head, Doc.sents, Doc.noun_chunks  |\n|ner   | Named entity recognizer  |  Doc.ents, Token.entiob, Token.enttype |\n|textcat   | Text classifier  | Doc.cats  |\n\nBecause text categories are always very specific, the text classifier is not included in any of the pre-trained models by default. But you can use it to train your own system.\n\ninitialize the language, add the pipeline and load in the binary model weights\nnlp = spacy.load(\"encoreweb_sm\")\n\ndoc = nlp(\"This is a sentence.\")\n\nlist of pipeline component names\nprint(nlp.pipe_names)\n\n{{ output }}\n['tagger', 'parser', 'ner']\n{{ /output }}\n\nlist of (name, component) tuples\nprint(nlp.pipeline)\n\n{{ output }}\n[('tagger', spacy.pipeline.pipes.Tagger object at 0x7f4d64e3ada0), ('parser', spacy.pipeline.pipes.DependencyParser object at 0x7f4d4ab97108), ('ner', spacy.pipeline.pipes.EntityRecognizer object at 0x7f4d4ab97228)]\n{{ /output }}\n\n Custom pipeline components\n\nCustom components are executed automatically when you call the nlp object on a text.  They're especially useful for adding your own custom metadata to documents and tokens.  You can also use them to update built-in attributes, like the named entity spans.\n\nA custom component:\n\ntakes a doc, modifies it and returns it\ncan be added using the nlp.add_pipe method\n\nCustom components can only modify the Doc and cant be used to update weights of other components directly.\n\ndef custom_component(doc, last,first,before,after ):\n    # Do something to the doc here\n    return doc\n\nnlp.addpipe(customcomponent)\n\nsimple component\n\n Create the nlp object\nnlp = spacy.load('encoreweb_sm')\n\nDefine a custom component\ndef custom_component(doc):\n     Print the doc's length\n    print('Doc length:', len(doc))\n    # Return the doc object\n    return doc\n\nAdd the component first in the pipeline\nnlp.addpipe(customcomponent, first=True)\n\n Print the pipeline component names\nprint('Pipeline:', nlp.pipe_names)\n\nProcess a text\ndoc = nlp(\"Hello world!\")\n\n{{ output }}\nPipeline: ['custom_component', 'tagger', 'parser', 'ner']\nDoc length: 3\n{{ /output }}\n\nimport spacy\nfrom spacy.matcher import PhraseMatcher\nfrom spacy.tokens import Span\n\nnlp = spacy.load(\"encoreweb_sm\")\nanimals = [\"Golden Retriever\", \"cat\", \"turtle\", \"Rattus norvegicus\"]\nanimal_patterns = list(nlp.pipe(animals))\nprint(\"animalpatterns:\", animalpatterns)\nmatcher = PhraseMatcher(nlp.vocab)\nmatcher.add(\"ANIMAL\", None, *animal_patterns)\n\n Define the custom component\ndef animal_component(doc):\n    # Apply the matcher to the doc\n    matches = matcher(doc)\n    # Create a Span for each match and assign the label 'ANIMAL'\n    spans = [Span(doc, start, end, label=\"ANIMAL\") for match_id, start, end in matches]\n    # Overwrite the doc.ents with the matched spans\n    doc.ents = spans\n    return doc\n\nAdd the component to the pipeline after the 'ner' component\nnlp.addpipe(animalcomponent, after=\"ner\")\nprint(nlp.pipe_names)\n\n Process the text and print the text and label for the doc.ents\ndoc = nlp(\"I have a cat and a Golden Retriever\")\nprint([(ent.text, ent.label_) for ent in doc.ents])\n\n{{ output }}\nanimal_patterns: [Golden Retriever, cat, turtle, Rattus norvegicus]\n['tagger', 'parser', 'ner', 'animal_component']\n[('cat', 'ANIMAL'), ('Golden Retriever', 'ANIMAL')]\n{{ /output }}\n\nCustom span attributes\n\nCustom attributes allow\n\nadd custom metadata to documents, tokens and spans\naccessible via the ._ property to distinguish from built-in attr\nregistered on the global Doc, Token or Span using the set_extension method\n\nAttribute extensions\nProperty extensions\nMethod extensions\n\ndoc._.title = 'My document'\ntoken..iscolor = True\nspan..hascolor = False\n\n Import global classes\nfrom spacy.tokens import Doc, Token, Span\n\nSet extensions on the Doc, Token and Span\nDoc.set_extension('title', default=None)\nToken.setextension('iscolor', default=False)\nSpan.setextension('hascolor', default=False)\n\nAttribute extension\nfrom spacy.tokens import Token\n\nSet extension on the Token with default value\nToken.setextension('iscolor', default=False)\ndoc = nlp(\"The sky is blue.\")\n Overwrite extension attribute value\ndoc[3]..iscolor = True\n\nProperty (getter/setter) extension: Token\nfrom spacy.tokens import Token\n\n Define getter function\ndef getiscolor(token):\n    colors = ['red', 'yellow', 'blue']\n    return token.text in colors\n\nSet extension on the Token with getter\nToken.setextension('iscolor', getter=getiscolor, force=True)\n\ndoc = nlp(\"The sky is blue.\")\nprint(doc[3]..iscolor, '-', doc[3].text)\n\n{{ output }}\nTrue - blue\n{{ /output }}\n\nProperty (getter/setter) extension: Span\nfrom spacy.tokens import Span\n\nDefine getter function\ndef gethascolor(span):\n    colors = ['red', 'yellow', 'blue']\n    return any(token.text in colors for token in span)\n\n Set extension on the Span with getter\nSpan.setextension('hascolor', getter=gethascolor)\n\ndoc = nlp(\"The sky is blue.\")\nprint(doc[1:4]..hascolor, '-', doc[1:4].text)\nprint(doc[0:2]..hascolor, '-', doc[0:2].text)\n\n{{ output }}\nTrue - sky is blue\nFalse - The sky\n{{ /output }}\n\nMethod (pass an argument) extension\nfrom spacy.tokens import Doc\n\n Define method with arguments\ndef hastoken(doc, tokentext):\n    indoc = tokentext in [token.text for token in doc]\n    return in_doc\n\nSet extension on the Doc with method\nDoc.setextension('hastoken', method=has_token)\n\ndoc = nlp(\"The sky is blue.\")\nprint(doc..hastoken('blue'), '- blue')\nprint(doc..hastoken('cloud'), '- cloud')\n\n{{ output }}\nTrue - blue\nFalse - cloud\n{{ /output }}\n\n Scaling and performance\n\nStreaming\n\nUse nlp.pipe method\nProcesses texts as a stream, yields Doc objects\nMuch faster than calling nlp on each text\n\n%timeit \ndocs = [nlp(text) for text in LOTSOFTEXTS]\nbad\n\n%timeit\ndocs = list(nlp.pipe(LOTSOFTEXTS))\ngood\n\nthis idiom is useful for associating metadata with the doc\nfrom spacy.tokens import Doc\n\nDoc.set_extension('id', default=None)\nDoc.setextension('pagenumber', default=None)\n\ndata = [\n    ('This is a text', {'id': 1, 'page_number': 15}),\n    ('And another text', {'id': 2, 'page_number': 16}),\n]\n\nfor doc, context in nlp.pipe(data, as_tuples=True):\n    doc._.id = context['id']\n    doc..pagenumber = context['page_number']\n\nPipeline configuration\n\nOnly run the models you need.\n\nslow\ndoc = nlp(\"Hello world\")\n\nfast - only runs tokenizer, not all models\ndoc = nlp.make_doc(\"Hello world!\")\n\ndisable tagger and parser\nrestores them after the with block\nwith nlp.disable_pipes('tagger', 'parser'):\n     Process the text and print the entities\n    doc = nlp(text)\n    print(doc.ents)\n\nTraining a neural network model\n\nList of english models, here\n\nSpaCy supports updating existing models with more examples, and training new models.\n\nUpdate an existing model: a few hundred to a few thousand examples\nTrain a new category: a few thousand to a million examples; spaCy's English models: 2 million words\n\nThis is essential for text classification, very useful for entity recognition and a little less critical for tagging and parsing.\n\n Creating training data\n\nThe entity recognizer predicts entities in context, it also needs to be trained on entities and their surrounding context.\n\nUse Matcher to quickly create training data for NER models.\n\nCreate a doc object for each text using nlp.pipe.\nMatch on the doc and create a list of matched spans.\nGet (start character, end character, label) tuples of matched spans.\nFormat each example as a tuple of the text and a dict, mapping 'entities' to the entity tuples.\nAppend the example to TRAINING_DATA and inspect the printed data.\n\nimport json\nfrom spacy.matcher import Matcher\nfrom spacy.lang.en import English\n\nTEXTS = \"New iPhone X release date leaked as Apple reveals pre-orders by mistake\"\n\nnlp = English()\nmatcher = Matcher(nlp.vocab)\n\nTwo tokens whose lowercase forms match 'iphone' and 'x'\npattern1 = [{\"LOWER\": \"iphone\"}, {\"LOWER\": \"x\"}]\n\n Token whose lowercase form matches 'iphone' and an optional digit\npattern2 = [{\"LOWER\": \"iphone\"}, {\"IS_DIGIT\": True, \"OP\": \"?\"}]\n\nAdd patterns to the matcher\nmatcher.add(\"GADGET\", None, pattern1, pattern2)\n\nimport json\nfrom spacy.matcher import Matcher\nfrom spacy.lang.en import English\n\nwith open(\"exercises/iphone.json\") as f:\n    TEXTS = json.loads(f.read())\n\nnlp = English()\nmatcher = Matcher(nlp.vocab)\npattern1 = [{\"LOWER\": \"iphone\"}, {\"LOWER\": \"x\"}]\npattern2 = [{\"LOWER\": \"iphone\"}, {\"IS_DIGIT\": True, \"OP\": \"?\"}]\nmatcher.add(\"GADGET\", None, pattern1, pattern2)\n\nTRAINING_DATA = []\n\n Create a Doc object for each text in TEXTS\nfor doc in nlp.pipe(TEXTS):\n    # Match on the doc and create a list of matched spans\n    spans = [doc[start:end] for match_id, start, end in matcher(doc)]\n    # Get (start character, end character, label) tuples of matches\n    entities = [(span.startchar, span.endchar, \"GADGET\") for span in spans]\n    # Format the matches as a (doc.text, entities) tuple\n    training_example = (doc.text, {\"entities\": entities})\n    # Append the example to the training data\n    TRAININGDATA.append(trainingexample)\n\nprint(*TRAINING_DATA, sep=\"\\n\")\n\nTraining the model\n\nLoop for a number of times.\nShuffle the training data.\nDivide the data into batches.\nUpdate the model for each batch.\nSave the updated model.\n\nimport spacy\nimport random\nimport json\n\nwith open(\"exercises/gadgets.json\") as f:\n    TRAINING_DATA = json.loads(f.read())\n\nnlp = spacy.blank(\"en\")\nner = nlp.create_pipe(\"ner\")\nnlp.add_pipe(ner)\nner.add_label(\"GADGET\")\n\n Start the training\nnlp.begin_training()\n\nLoop for 10 iterations\nfor itn in range(10):\n     Shuffle the training data\n    random.shuffle(TRAINING_DATA)\n    losses = {}\n\n    # Batch the examples and iterate over them\n    for batch in spacy.util.minibatch(TRAINING_DATA, size=2):\n        texts = [text for text, entities in batch]\n        annotations = [entities for text, entities in batch]\n\n        # Update the model\n        nlp.update(texts, annotations, losses=losses)\n        print(losses)\n\nProblems with updating:\n\nif you don't provide examples of original labels, then it will 'forget' them by adjusting too much to the new data\nlabel scheme needs to be consistent and not too specific, for example: CLOTHING is better than ADULTCLOTHING and CHILDRENSCLOTHING\n\nYou can create those additional examples by running the existing model over data and extracting the entity spans you care about.  You can then mix those examples in with your existing data and update the model with annotations of all labels.\n\nIf the decision is difficult to make based on the context, the model can struggle to learn it.  The label scheme also needs to be consistent and not too specific.  You can always add a rule-based system later to go from generic to specific.\n\nApplications\n\n Working on customer environment\n\nSerialization refers to the process of converting an object in memory to a byte stream that can be stored on disk or sent over a network.  This SpaCy guide provides the latest recommendations, ref.\n\nThe DocBin class lets you efficiently serialize the information from a collection of Doc objects. You can control which information is serialized by passing a list of attribute IDs, and optionally also specify whether the user data is serialized. The DocBin is faster and produces smaller data sizes than pickle, and allows you to deserialize without executing arbitrary Python code. \n\nTypical serialization\n\n Load a larger model with vectors\nnlp = spacy.load('encoreweb_lg')\n\nCompare two documents\ndoc1 = nlp(\"I like fast food\")\ndoc2 = nlp(\"I like pizza\")\nprint(doc1.similarity(doc2))\n\n{{ output }}\n---------------------------------------------------------------------------\n{{ /output }}\n\n{{ output }}\nNameError                                 Traceback (most recent call last)\n{{ /output }}\n\n{{ output }}\nipython-input-3-a430716dafad in module()\n      1  Load a larger model with vectors\n---- 2 nlp = spacy.load('encoreweb_lg')\n      3 \n      4 # Compare two documents\n      5 doc1 = nlp(\"I like fast food\")\n{{ /output }}\n\n{{ output }}\nNameError: name 'spacy' is not defined\n{{ /output }}\n\n! ls ../tmp;\n\n{{ output }}\nspacy-pizza.bz\tspacy-pizza.mdl\n{{ /output }}\n\nimport pickle\n\ndata_dict = {'doc1':doc1,'nlp':nlp}\nfilename = '../tmp/spacy-pizza.mdl'\noutfile = open(filename,'wb')\n\npickle.dump(data_dict, outfile)\noutfile.close()\n\n{{ output }}\n---------------------------------------------------------------------------\n{{ /output }}\n\n{{ output }}\nNameError                                 Traceback (most recent call last)\n{{ /output }}\n\n{{ output }}\nipython-input-2-9c7a736efa99 in module()\n      1 import pickle\n      2 \n---- 3 data_dict = {'doc1':doc1,'nlp':nlp}\n      4 filename = '../tmp/spacy-pizza.mdl'\n      5 outfile = open(filename,'wb')\n{{ /output }}\n\n{{ output }}\nNameError: name 'doc1' is not defined\n{{ /output }}\n\ninfile = open(filename,'rb')\nnew_dict = pickle.load(infile)\ninfile.close()\n\nnew_dict['doc1'].similarity(doc2)\n\n{{ output }}\n/opt/conda/envs/beakerx/lib/python3.6/runpy.py:193: ModelsWarning: [W007] The model you're using has no word vectors loaded, so the result of the Doc.similarity method will be based on the tagger, parser and NER, which may not give useful similarity judgements. This may happen if you're using one of the small models, e.g. encoreweb_sm, which don't ship with word vectors and only use context-sensitive tensors. You can always add your own word vectors, or use one of the larger models instead if available.\n  \"main\", mod_spec)\n{{ /output }}\n\n{{ output }}\n0.953127971438058\n{{ /output }}\n\nSerialization with compression\n\nimport bz2\nimport pickle\n\nfilename = '../tmp/spacy-pizza.bz'\nsfile = bz2.BZ2File('smallerfile', 'w')\npickle.dump(data_dict, sfile)\noutfile.close()\n\noutfile = bz2.BZ2File(filename, 'wb')\npickle.dump(data_dict, outfile, protocol=2)\noutfile.close()\n\n! ls ../tmp\n\n{{ output }}\nspacy-pizza.bz\tspacy-pizza.mdl\n{{ /output }}\n\ninfile = bz2.BZ2File(filename, 'rb')\nmyobj = pickle.load(infile)\ninfile.close()\n\nmyobj\n\n{{ output }}\n{'doc1': This is a sentence., 'nlp': spacy.lang.en.English at 0x7f4d606145c0}\n{{ /output }}\n\nmyobj['doc1'].similarity(doc2)\n\n{{ output }}\n/opt/conda/envs/beakerx/lib/python3.6/runpy.py:193: ModelsWarning: [W007] The model you're using has no word vectors loaded, so the result of the Doc.similarity method will be based on the tagger, parser and NER, which may not give useful similarity judgements. This may happen if you're using one of the small models, e.g. encoreweb_sm, which don't ship with word vectors and only use context-sensitive tensors. You can always add your own word vectors, or use one of the larger models instead if available.\n  \"main\", mod_spec)\n{{ /output }}\n\n{{ output }}\n0.953127971438058\n{{ /output }}\n\nSpaCy method for encapsulating texts\n\nfast method\nfrom spacy.attrs import LOWER, POS, ENTTYPE, ISALPHA\ndoc = nlp(text)\n\nAll strings mapped to integers, for easy export to numpy\nnparray = doc.toarray([LOWER, POS, ENTTYPE, ISALPHA])\nnparray = doc.toarray(\"POS\")\n\nimport pickle\nserialized = pickle.dumps(np_array, protocol=0)  protocol 0 is printable ASCII\ndeserialized_array = pickle.loads(serialized)\n\ncomprehensive approach\nimport spacy\nfrom spacy.tokens import DocBin\n\ndocbin = DocBin(attrs=[\"LEMMA\", \"ENTIOB\", \"ENTTYPE\"], storeuser_data=True)\ntexts = [\"Some text\", \"Lots of texts...\", \"...\"]\nnlp = spacy.load(\"encoreweb_sm\")\nfor doc in nlp.pipe(texts):\n    doc_bin.add(doc)\nbytesdata = docbin.tobytes()    .todisk(\"/path\")\n\nDeserialize later, e.g. in a new process\nnlp = spacy.blank(\"en\")\ndocbin = DocBin().frombytes(bytesdata)    .fromdisk(\"/path\")\ndocs = list(docbin.getdocs(nlp.vocab))\n\ndocs = list(docbin.getdocs(nlp.vocab))\nDoc.setextension(\"mycustom_attr\", default=None)\nprint([doc..mycustom_attr for doc in docs])\n\nPickle Doc to include dependencies\n\nWhen pickling spaCys objects like the Doc or the EntityRecognizer, keep in mind that they all require the shared Vocab (which includes the string to hash mappings, label schemes and optional vectors). This means that their pickled representations can become very large, especially if you have word vectors loaded, because it wont only include the object itself, but also the entire shared vocab it depends on.\n\ndoc = nlp(\"This is a sentence.\")\nassert len(nlp.vocab)  0\n\ndata = {\"doc\":doc, \"nlp\":nlp}\n",
        "tags": [
            "nlp",
            "spacy",
            "nltk"
        ]
    },
    {
        "uri": "/posts/blog_nlp-regular_expressions_workflow",
        "title": "Solving Textual Problems with Regular Expressions",
        "content": "\n\nRegular Expressions provide an important foundation for learning systems.  They are useful for quick and direct approaches to solving problems without creating mounds of training data, nor the infrastructure for deploying a model.  While they are a common programming technique, and simple enough to employ, they tend to be used so infrequently that you must re-learn them each time you wish to apply.    This post summarizes the basic regex syntax, strategies, and workflow in hopes it will decrease the time needed to implement.  A few different languages are used in examples, for various scenario.  Happy re-learning!\n\nRegex Basics\n\n Operators\n\nCharacter classes\n\nabc, 123, \\d, \\D: matches exact character, exact digit, any digit, any non-digit\n\n\\s, \\S, \\w, \\W : matches white space, non-white space, alphanumeric word, non-alphanumeric word\n\nBoundaries\n\n^__, __$, \\b, \\B: start of string, end of string, word boundary, not word boundary\n\nQuantifiers\n\nx*: matches zero or multiple x\n\nx+: matches one or multiple x\n\nx{m,n}: matches x repeat m to n times. a{4} represent aaaa\n\nx?: optional - matches one or zero x\n\nGroups, Ranges, and Capture\n\n[xyz], (x|y|z): equals x or y or z\n\n__: not x or y or z\n\n[x-z]: matches anyone between x and y\n\n^x, __: means any character that is not x, not any in group x|y|z\n\n(xyz), (xy(z)): capture group, capture group and sub-group\n\nSyntax patterns\n\nRegEx libraries typically provide functionality and components using similar patterns, such as the following:\n\npattern - encapsulate the expression that is sought using above syntax (mostly language agnostic)\nfind - apply a pattern, directly to text and return nothing, or a regex object\nmatch - apply the pattern to text and return boolean whether a match, or exact match, exists\nsub - substitute a pattern for a string\nconvenience functionality \n\n Common Solution Approaches\n\nExample data\n\nWe will use the following file for example data.\n\n%%bash\nls Data/Bloomberg_Chat\n\n{{ output }}\nexample_chat.txt\n\n{{ /output }}\n\nWe will read-in and parse each line using a method similar to the following:\n\nimport java.io.InputStream\nnew File(\"./Data/BloombergChat/examplechat.txt\").withInputStream { stream -\n    stream.eachLine { line -\n        println line\n    }}\n\n{{ output }}\nMessage: 0\n\nMessage Sent: 02/13/2019 08:42:15\n\nSubject: Instant Bloomberg  Persistent\n\n02/13/2019 08:42:15  User_01,has joined the room\n\n02/19/2019 00:56:29  User_105,Says   Cupiditate voluptas sunt velit. Accusantium aliquid expedita excepturi quis laborum autem. Quas occaecati et atque est repellat dolores. Laudantium in molestiae consequatur voluptate ipsa. \n\n02/19/2019 00:55:35  User_68,has left the room\n\n{{ /output }}\n\n{{ output }}\nnull\n{{ /output }}\n\nWalking\n\nWalking is one of the most direct approaches.  In the Walking method, you slowly move from the left to the right of your text, matching patterns along the way.  Your target text will everything at the end of the string.\n\nimport java.io.InputStream\nnew File(\"./Data/BloombergChat/examplechat.txt\").withInputStream { stream -\n    stream.eachLine { line -\n        //find beginning\n        trgt = line =~ ~/^Message\\sSent:\\s(.*)$/\n        if(trgt){println trgt0}\n    }}\n\n{{ output }}\n02/13/2019 08:42:15\n{{ /output }}\n\n{{ output }}\nnull\n{{ /output }}\n\n Bracketing\n\nThe Bracketing method is taken from the similar technique used in field artillery to range your inteded target.  First, pattern the string that begins just before your target text.  Next, pattern the string that ends just after your target text.  Your target text will be in the middle.\n\nimport java.io.InputStream\nnew File(\"./Data/BloombergChat/examplechat.txt\").withInputStream { stream -\n    stream.eachLine { line -\n        //find beginning\n        tmp1 = line =~ ~/^Message\\sSent:\\s(.*)$/\n        if(tmp1){\n            //find end\n            trgt = tmp10 =~ ~/.+?(?=\\s\\d{2}:\\d{2}:\\d{2})/\n            if(trgt){\n                println trgt[0]\n            }\n        }\n    }}\n\n{{ output }}\n02/13/2019\n{{ /output }}\n\n{{ output }}\nnull\n{{ /output }}\n\nDivide and conquer\n\nHere, you have a few targets that you are interested in capturing.  Create nested capture groups within the original capture.\n\nimport java.io.InputStream\nnew File(\"./Data/BloombergChat/examplechat.txt\").withInputStream { stream -\n    stream.eachLine { line -\n        trgt = line =~ ~/^((\\d{2}\\S\\d{2}\\S\\d{4}\\s\\d{2}:\\d{2}:\\d{2})\\s(+))(.*)$/\n        if(trgt){\n            println (\"--------Begin line---------\")\n            println trgt0                //dtv\n            println trgt0                //member\n            println trgt0                //content\n            println (\"---------End line----------\")\n        }\n    }}\n\n{{ output }}\n--------Begin line---------\n02/13/2019 08:42:15\n User_01\n,has joined the room\n---------End line----------\n--------Begin line---------\n02/19/2019 00:56:29\n User_105\n,Says   Cupiditate voluptas sunt velit. Accusantium aliquid expedita excepturi quis laborum autem. Quas occaecati et atque est repellat dolores. Laudantium in molestiae consequatur voluptate ipsa. \n---------End line----------\n--------Begin line---------\n02/19/2019 00:55:35\n User_68\n,has left the room\n---------End line----------\n{{ /output }}\n\n{{ output }}\nnull\n{{ /output }}\n\n Parsing\n\nIn this approach, you want to parse all pieces of a data into their respective fields.  This is often used when getting semi-structured data, such as log files, into a structured format, such as a table.  This is an example from pyspark.\n\n%python #METHOD-1: RegEx\nfrom pyspark.sql import Row\nimport re\nparts = [\n    r'(?Phost\\S+)',                   # host \n    r'\\S+',                             # indent (unused)\n    r'(?Puser\\S+)',                   # user \n    r'\\[(?Ptime.+)\\]',                # time \n    r'\"(?Prequest.*)\"',               # request \n    r'(?Pstatus[0-9]+)',              # status \n    r'(?Psize\\S+)',                   # size \n    r'\"(?Preferrer.*)\"',              # referrer \n    r'\"(?Pagent.*)\"',                 # user agent \n]\npattern = re.compile(r'\\s+'.join(parts)+r'\\s*\\Z')\n\nprs = logs.map(lambda x: pattern.match(x).groupdict() )\nrows = prs.map(lambda x: Row(**x))\ndfLogs = rows.toDF()\ndfLogs.show()\n+--------------------+-------------+--------------------+--------------------+-----+------+--------------------+----+\n|               agent|         host|            referrer|             request| size|status|                time|user|\n+--------------------+-------------+--------------------+--------------------+-----+------+--------------------+----+\n|Mozilla/5.0 (comp...| 66.249.69.97|                   -|GET /071300/24215...|  514|   404|24/Sep/2014:22:25...|   -|\n|Mozilla/5.0 (X11;...|71.19.157.174|                   -| GET /error HTTP/1.1|  505|   404|24/Sep/2014:22:26...|   -|\n|Mozilla/5.0 (X11;...|71.19.157.174|                   -|GET /favicon.ico ...| 1713|   200|24/Sep/2014:22:26...|   -|\n|Mozilla/5.0 (X11;...|71.19.157.174|                   -|      GET / HTTP/1.1|18785|   200|24/Sep/2014:22:26...|   -|\n|Mozilla/5.0 (X11;...|71.19.157.174|http://www.holden...|GET /jobmineimg.p...|  222|   200|24/Sep/2014:22:26...|   -|\n|Mozilla/5.0 (X11;...|71.19.157.174|                   -|GET /error78978 H...|  505|   404|24/Sep/2014:22:26...|   -|\n+--------------------+-------------+--------------------+--------------------+-----+------+--------------------+----+\nConvenience structures\n\nLanguages can have sytax conveniences to make working with regex much easier.  This can include making patterns part of case statements, such as is done in groovy and scala, and allowing for raw string input, such as in groovy and python.\n\nIn addition, programmers can make their life easier by creating specific data structures that can hold the output of target matches.\n\n Language: Groovy\n\nThe following functionality is commonly used with groovy:\n    \n~string - pattern operator\n=~ - find pattern \n==~ - exact match operator\nswitch-case - convenience functionality\n\nThe pattern operator (~string)\n\nimport java.util.regex.Pattern\n\ndef pattern = ~/([Gg])roovy/\npattern.class == Pattern\n\n{{ output }}\ntrue\n{{ /output }}\n\n//The slashy form of a Groovy string has a huge advantage over double (or single) quoted string - you dont have to escape backslashes.\n( /Version \\d+\\.\\d+\\.\\d+/ == 'Version \\\\d+\\\\.\\\\d+\\\\.\\\\d+' )\n\n{{ output }}\ntrue\n{{ /output }}\n\np = ~/foo/\np = ~'foo'                                                        \np = ~\"foo\"                                                        \np = ~$/dollar/slashy $ string/$                                   \n//p = ~\"${pattern}\"\n\n{{ output }}\ndollar/slashy $ string\n{{ /output }}\n\n The find operator (=~)\n\nimport java.util.regex.Matcher\n\ndef matcher = \"My code is groovier and better when I use Groovy there\" =~ /\\S+er\\b/ \nprintln matcher.find()\nprintln matcher.size() == 2 \nmatcher[0..-1] == [\"groovier\", \"better\"] \n\n{{ output }}\ntrue\ntrue\n{{ /output }}\n\n{{ output }}\ntrue\n{{ /output }}\n\nif (\"My code is groovier and better when I use Groovy there\" =~ /\\S+er\\b/) {\n    \"At least one element matches the pattern\"\n}\n\n{{ output }}\nAt least one element matches the pattern\n{{ /output }}\n\ndef (first,second) = \"My code is groovier and better when I use Groovy there\" =~ /\\S+er\\b/\nfirst == \"groovier\" & second == \"better\"\n\n{{ output }}\ntrue\n{{ /output }}\n\n// With grouping we get a multidimensional array\ndef group = ('groovy and grails, ruby and rails' =~ /(\\w+) and (\\w+)/)\nprintln group.hasGroup()\nprintln 2 == group.size()\nprintln ['groovy and grails', 'groovy', 'grails'] == group[0]\nprintln 'rails' == group1\n\nThe exact match operator (==~)\n\n\"My code is groovier and better when I use Groovy there\" ==~ /\\S+er\\b/    //no exact match = only two words\n\n{{ output }}\nfalse\n{{ /output }}\n\n\"My code is groovier and better when I use Groovy there\" ==~ /^My code .* there$/    //exact match of beginning and end of string\n\n{{ output }}\ntrue\n{{ /output }}\n\n The pattern with switch case\n\ndef input = \"test\"\n\nswitch (input) {\n    case ~/\\d{3}/:\n        \"The number has 3 digits\"\n        break\n\n    case ~/\\w{4}/:\n        \"The word has 4 letters\"\n        break\n\n    default:\n        \"Unrecognized...\"\n}\n\n{{ output }}\nThe word has 4 letters\n{{ /output }}\n\nLanguage: Python\n\n Reading files\n\nYou can read-in a file with the following:\n\nfile_object  = open(filename, mode)\n\nThe mode argument has a default value of r - read value, if omitted. The modes are: \n\nr  Read mode which is used when the file is only being read \nw  Write mode which is used to edit and write new information to the file (any existing files with the same name will be erased when this mode is activated) \na  Appending mode, which is used to add new data to the end of the file; that is new information is automatically amended to the end \nr+  Special read and write mode, which is used to handle both actions when working with a file \n\nBy using the with statement, you ensure proper handling of the file, including closing it when work is completed.\n\n%%python\nwith open(\"./Data/BloombergChat/examplechat.txt\") as file:\n    data = file.read() \n    print(data) \n\n{{ output }}\nMessage#: 0\n\nMessage Sent: 02/13/2019 08:42:15\n\nSubject: Instant Bloomberg  Persistent\n\n02/13/2019 08:42:15  User_01,has joined the room\n\n02/19/2019 00:56:29  User_105,Says   Cupiditate voluptas sunt velit. Accusantium aliquid expedita excepturi quis laborum autem. Quas occaecati et atque est repellat dolores. Laudantium in molestiae consequatur voluptate ipsa. \n\n02/19/2019 00:55:35  User_68,has left the room\n\n{{ /output }}\n\nOrdinary string manipulation\n\nBefore moving straight to regular expressions, users should take advantage of Python's built-in string manipulation functionality.  Bracketing textual start/end anchors with simple tools can keep your code clean and readable.  The following is an example of adding all text as a string, then using string methods and list comprehensions to select targets. \n\n%%python\nwith open(\"./Data/BloombergChat/examplechat.txt\") as file:\n    data = file.read()\n    content = (data.split(',has left the room')[0]).split('has joined the room')[1]\n    lines = content.replace('\\n', ' ').split('.')\n    quote = [x.strip() for x in lines]\nquote  \n\n{{ output }}\n['02/19/2019 00:56:29  User_105,Says   Cupiditate voluptas sunt velit',\n 'Accusantium aliquid expedita excepturi quis laborum autem',\n 'Quas occaecati et atque est repellat dolores',\n 'Laudantium in molestiae consequatur voluptate ipsa',\n '02/19/2019 00:55:35  User_68']\n{{ /output }}\n\n Using RegEx\n\nRegualar expressions are more powerful not only for their patterns, but also because they can be compiled and used over large amounts of data.\n\nUse raw strings instead of regular Python strings. Raw strings begin with r\"some text\" and tell Python not to interpret backslashes and special metacharacters in the string.  This allows you to pass them to the regular expression engine, directly.\n\nAn example is using r\"\\n\\w\" instead of \"\\\\n\\\\w\".\n\nBelow, we use the following methods from the re module:\n\nre.search() - stop with first match\nre.findall() / re.finditer() - search over entire string, returns a list (or iterator) of all captured data\nre.compile() method to speed-up processing on larger data.  This is especially useful with a big data framework, such as Apache Spark\nre.sub() - find and replace\n\n%%python\nimport re\n\nregexDate = re.compile(r\"Message#:\\s(\\d+)\")\n\nwith open(\"./Data/BloombergChat/examplechat.txt\") as file:\n    data = file.read() \n    grp = (re.search(regexDate, data)).group(0) \n    print(grp)\n\n{{ output }}\nMessage#: 0\n{{ /output }}\n\nLanguage: JavaScript\n\n/\\w+\\d+/ - match a string of alpha-numeric characters\nRegExp(\"\\\\w+\\\\d+\") - constructor notation\nRegExp.test() - test for a match\nRegExp.exec() - returns matching results\ninputStr.search() - find a match\ninputStr.match() - returns an index of matches\ninputStr.replace() - substitute a match with a string\n\nThe flags are either appended after the regular expression in the literal notation, or passed into the constructor in the normal notation.\n\ng - allows you to run RegExp.exec() multiple times to find every match in the input string until the method returns null.\ni - makes the pattern case insensitive so that it matches strings of different capitalizations\nm - is necessary if your input string has newline characters (\\n), this flag allows the start and end metacharacter (^ and $ respectively) to match at the beginning and end of each line instead of at the beginning and end of the whole input string\nu - interpret the regular expression as unicode codepoints\n\n%%javascript\nvar fs = require('fs');\nfs.readFile( _dirname + '/Data/BloombergChat/example_chat.txt', function (err, data) {\n  if (err) {\n    throw err; \n  }\n  console.log(data.toString());\n});\n\n%%javascript\n\nconsole.log('hi')\n//process.stdout.write(\"hello: \");\nprocess.stdout.write(\"Downloading \");\n\n References\n\ngroovy regex operators\nthorough cheatsheet\nwell-designed exercises\nmatch until a pattern\n",
        "tags": [
            "NLP",
            "RegEx"
        ]
    },
    {
        "uri": "/posts/blog_page-todo",
        "title": "List of ToDo Posts",
        "content": "\n\nThis is a list of blog posts that are referenced, but not yet complete.\n\nList of Future Posts\n\nGeneral Machine Learning\n\nscoring metrics, model performance metrics, and graphs\nimbalanced data\nfeature engineering\nmodels in-depth\n\nNatural Language Processing\n\nfunctional programming\nnumpy\nnltk / spaCy\ngensim\nword2vec\nfasttext\nnlp overview\n\nGeneral Data Concepts\n\ndatawarehousing\ninfrastructure architectures\nserverless deployments\n\nBusiness and Sales\n\npricing pyramid\nmatching problems and solutions\nmarketing - business development - sales cycle and org structure\n",
        "tags": [
            "blog",
            "tag2"
        ]
    },
    {
        "uri": "/posts/blog_programming_java-groovy",
        "title": "Introduction to Groovy for Data Science on the JVM",
        "content": "\n\nGroovy is a scripting language that compiles to the Java Virtual Machine.  It would be more-aptly named JavaScript if that name were not already taken, but it has many similarities to Python.  In fact, some of the libraries implemented for Groovy, such as TableSaw, attempt to take it in the same Data Science direction as Python.\n\nThis post will provide an introduction to the Groovy language using Jupyter notebook with BeakerX, and provides specific applications to Data Science.  It begins with a tour of the Groovy language, then describes some of the most interesting features that the language provides.  We give a comparison to Java with some notes for making integration with Java environments easier.  We finish-off with applications and examples in Data Science. \n\nThis notebook takes code and examples from this github repo: https://github.com/twosigma/beakerx\n\nGetting Started\n\nYou can get started with Groovy in a few different ways.  After installing Groovy, the console (comes with Groovy distribution) is a Java Swing application where we can write and run code, interactively.\n\\\\( groovyconsole\n\nOr you can run a script, directly.\n\\\\) groovy your-script.groovy\n\nIn this post we will use Jupyter with the BeakerX JVM kernel.  BeakerX provides a variety of languages and support transforming data structures among them.  This makes it ideal for learning and prototyping.  You can get started with BeakerX using Docker.\n$ docker run -p 8888:8888 beakerx/beakerx\n\n Introduction\n\nBasic syntax\n\nWe provide the obligatory hello world example using a simple println statement to print output to the console.\n\nclass Example {\n   static void main(String[] args) {\n      println('Hello World');\n   }\n}\nExample.main()\n\n{{ output }}\nHello World\n{{ /output }}\n\n{{ output }}\nnull\n{{ /output }}\n\nBy default, Groovy includes the following libraries in your code, so you dont need to explicitly import them.\n\nimport java.lang.* \nimport java.util.* \nimport java.io.* \nimport java.net.* \n\nimport groovy.lang.* \nimport groovy.util.* \n\nimport java.math.BigInteger \nimport java.math.BigDecimal\n\n{{ output }}\nnull\n{{ /output }}\n\nGroovy supports all Java types (primitive and reference types).\n\nAll primitive types are auto-converted to their wrapper types. So int a = 2 will become Integer a = 2\n\nWhen declaring variables we can do one of the followings:\n\nDo not use any type (that will create a global variable): a = 2\nUse keyword def (that will create a local variable): def a = 2\nUse the actual type (that will create a local variable of strict type Integer): int a = 3\n\nWhen no type is used, variables act like they are of type Object, so they can be reassigned to different types.\n\na = 2\nprintf \"%s - %s%n\", a.getClass().getName(), a\na = \"apple\"\nprintf \"%s - %s%n\", a.getClass().getName(), a\n\n{{ output }}\njava.lang.Integer - 2\njava.lang.String - apple\n{{ /output }}\n\n{{ output }}\nnull\n{{ /output }}\n\n Running the code\n\nThe code outside methods but still in a script is copied to at run to an object method.  So during runtime everything is inside methods. In that sense, this feature allows the variables declared in a method to be accessible to other methods.\n\nGroovy keeps these global variables in a map like object (groovy.lang.Binding).\n\nWhen def is used, variables act like they are of type Object, so they can be reassigned to different types (same as when no type is used): \n\n//';' should be used after each statement, but is not necessary in beakerx cells\n//def is a keyword used in Groovy to define an identifier\ndef c = 1;    //local variable\nd = 2;        //global variable - var with no type are global so they can be accessed across methods\n\n{{ output }}\n2\n{{ /output }}\n\nc //error - var declared with def are local, so they cannot be accessed across methods\n\n{{ output }}\ngroovy.lang.MissingPropertyException: No such property: c for class: script1561051888331\n{{ /output }}\n\n{{ output }}\n\tat this cell line 1\n{{ /output }}\n\n{{ output }}\n\tat com.twosigma.beakerx.groovy.evaluator.GroovyCodeRunner.runScript(GroovyCodeRunner.java:94)\n{{ /output }}\n\n{{ output }}\n\tat com.twosigma.beakerx.groovy.evaluator.GroovyCodeRunner.call(GroovyCodeRunner.java:59)\n{{ /output }}\n\n{{ output }}\n\tat com.twosigma.beakerx.groovy.evaluator.GroovyCodeRunner.call(GroovyCodeRunner.java:32)\n{{ /output }}\n\nd //this works\n\n{{ output }}\n2\n{{ /output }}\n\nData types\n\nUsing actual types (same as Java types).  They follow strict typing rules (just like Java). So they cannot be reassigned to different types:\n\nint a = 2\nprintln a\na = \"apple\"\nprintln a\n\n{{ output }}\n2\n{{ /output }}\n\n{{ output }}\norg.codehaus.groovy.runtime.typehandling.GroovyCastException: Cannot cast object 'apple' with class 'java.lang.String' to class 'int'\n{{ /output }}\n\n{{ output }}\n\tat this cell line 3\n{{ /output }}\n\n{{ output }}\n\tat com.twosigma.beakerx.groovy.evaluator.GroovyCodeRunner.runScript(GroovyCodeRunner.java:94)\n{{ /output }}\n\n{{ output }}\n\tat com.twosigma.beakerx.groovy.evaluator.GroovyCodeRunner.call(GroovyCodeRunner.java:59)\n{{ /output }}\n\n{{ output }}\n\tat com.twosigma.beakerx.groovy.evaluator.GroovyCodeRunner.call(GroovyCodeRunner.java:32)\n{{ /output }}\n\nLike def variables they are also local, so they cannot be accessed across methods.\n\nint e = 2\nvoid printVars() {\n    println e;\n}\nprintVars();\n\n{{ output }}\ngroovy.lang.MissingPropertyException: No such property: e for class: script1561051968611\n{{ /output }}\n\n{{ output }}\n\tat script1561051968611.printVars(script1561051968611:4)\n{{ /output }}\n\n{{ output }}\n\tat this cell line 7\n{{ /output }}\n\n{{ output }}\n\tat com.twosigma.beakerx.groovy.evaluator.GroovyCodeRunner.runScript(GroovyCodeRunner.java:94)\n{{ /output }}\n\n{{ output }}\n\tat com.twosigma.beakerx.groovy.evaluator.GroovyCodeRunner.call(GroovyCodeRunner.java:59)\n{{ /output }}\n\n{{ output }}\n\tat com.twosigma.beakerx.groovy.evaluator.GroovyCodeRunner.call(GroovyCodeRunner.java:32)\n{{ /output }}\n\n//remove variables\nbinding.variables.remove 'a'\nbinding.variables.remove 'b' \nbinding.variables.remove 'c' \nbinding.variables.remove 'd' \nbinding.variables.remove 'e'\n\n{{ output }}\nnull\n{{ /output }}\n\nAs seen above, Groovy uses Objects for everything (int is printed as java.lang.Integer). Primitives are auto-converted to their wrapper type.\n\nint a = 2\nprintf(\"%s - %s%n\", a.getClass(), a.getClass().isPrimitive())\n\ndef b = 2\nprintf \"%s - %s%n\", b.getClass(), b.getClass().isPrimitive()\n\nc = 2\nprintf \"%s - %s%n\", c.getClass(), c.getClass().isPrimitive()\n\ndouble d = 2.2\nprintf \"%s - %s%n\", d.getClass(), d.getClass().isPrimitive()\n\ne = 2.3//no type\nprintf \"%s - %s%n\", e.getClass(), e.getClass().isPrimitive()\n\n{{ output }}\nclass java.lang.Integer - false\nclass java.lang.Integer - false\nclass java.lang.Integer - false\nclass java.lang.Double - false\nclass java.math.BigDecimal - false\n{{ /output }}\n\n{{ output }}\nnull\n{{ /output }}\n\nAll of the variables are initialized (even local) with their default values (just like instance variable).\n\ndef a //initialized with null\nprintln a\n\nString s //initialized with null\nprintln s\n\nint b//initialized with 0\nprintln b\nprintln b + 3\n\nboolean bool//initialized with false\nprintln bool\n\n{{ output }}\nnull\nnull\n0\n3\nfalse\n{{ /output }}\n\n{{ output }}\nnull\n{{ /output }}\n\nUsing actual types.\n\nint sum(int x, int y) {\n    x + y;\n}\nprintln sum(1, 3)\n\n{{ output }}\n4\n{{ /output }}\n\n{{ output }}\nnull\n{{ /output }}\n\nUsing def.\n\ndef sum(def x, def y) {\n    x + y;\n}\nprintln sum(1, 3)\n\n{{ output }}\n4\n{{ /output }}\n\n{{ output }}\nnull\n{{ /output }}\n\nUsing no types with parameters.\n\ndef sum(x, y) {\n    x + y;\n}\nprintln sum(1, 3)\n\n{{ output }}\n4\n{{ /output }}\n\n{{ output }}\nnull\n{{ /output }}\n\nMethods must return def or actual type.\n\nsum(x, y) {\n    x + y;\n}\nprintln sum(1, 3)\n\n{{ output }}\ngroovy.lang.MissingPropertyException: No such property: x for class: script1561052241554\n{{ /output }}\n\n{{ output }}\n\tat this cell line 1\n{{ /output }}\n\n{{ output }}\n\tat com.twosigma.beakerx.groovy.evaluator.GroovyCodeRunner.runScript(GroovyCodeRunner.java:94)\n{{ /output }}\n\n{{ output }}\n\tat com.twosigma.beakerx.groovy.evaluator.GroovyCodeRunner.call(GroovyCodeRunner.java:59)\n{{ /output }}\n\n{{ output }}\n\tat com.twosigma.beakerx.groovy.evaluator.GroovyCodeRunner.call(GroovyCodeRunner.java:32)\n{{ /output }}\n\nclass Example { \n   static void main(String[] args) { \n      //Example of a int datatype \n      int x = 5; \n\t\t\n      //Example of a long datatype \n      long y = 100L; \n\t\t\n      //Example of a floating point datatype \n      float a = 10.56f; \n\t\t\n      //Example of a double datatype \n      double b = 10.5e40; \n\t\t\n      //Example of a BigInteger datatype \n      BigInteger bi = 30g; \n\t\t\n      //Example of a BigDecimal datatype \n      BigDecimal bd = 3.5g; \n\t\t\n      println(x); \n      println(y); \n      println(a); \n      println(b); \n      println(bi); \n      println(bd); \n   } \n}\nExample.main()\n\n{{ output }}\n5\n100\n10.56\n1.05E41\n30\n3.5\n{{ /output }}\n\n{{ output }}\nnull\n{{ /output }}\n\n Features\n\nGroovy has many different features.  We have seen a few of these, earlier, but the others are mentioned, here.\n\nSupport for both static and dynamic typing\nSupport for operator overloading\nNative syntax for lists and associative arrays\nNative support for regular expressions\nNative support for various markup languages such as XML and HTML.\nSimilar syntax to Java\nUse of existing Java libraries\nExtends the java.lang.Object\n\nSupport for regular expressions\n\ndef m = \"Groovy is groovy\" =~ /(G|g)roovy/\nprintln m0 // The first whole match (i.e. the first word Groovy)\nprintln m0 // The first group in the first match (i.e. G)\nprintln m1 // The second whole match (i.e. the word groovy)\nprintln m1 // The first group in the second match (i.e. g)\n\n{{ output }}\nGroovy\nG\ngroovy\ng\n{{ /output }}\n\n{{ output }}\nnull\n{{ /output }}\n\n Support for markup languages\n\nOne of the most used classes for creating HTML or XML markup.\n\nimport groovy.xml.MarkupBuilder \ndef xml = new MarkupBuilder() \n\n{{ output }}\ngroovy.xml.MarkupBuilder@7500ce0e\n{{ /output }}\n\nLiberal use of closures\n\n//closure example\ntimesTwo = {x - x*2}\n\n{{ output }}\nscript1556559307332$runclosure1@cad3663\n{{ /output }}\n\ntimesTwo(4)\n\n{{ output }}\n8\n{{ /output }}\n\ntimesTwo(\"Multiplying Strings!\")\n\n{{ output }}\nMultiplying Strings!Multiplying Strings!\n{{ /output }}\n\nsin(3.1415)\n\n{{ output }}\n9.265358966049026E-5\n{{ /output }}\n\n Comparison of Groovy with Java\n\nBasic differences\n\nautomatically a wrapping a class called Script for every program\ndefault access specifier is public\ngetters and setters are automatically generated for class members \nabbreviated commands, such as println\nsemicolons ; and paraentheses () are optional\ndynamic typing with the def var keyword (locar var), or with no prefix var (global var)\nstring interpolation (GString) is performed with \\\\( operator, such as \"Hello, \\\\){firstName[0]}. $name\"\n\"\"\"multi-line strings are also allowed\"\"\"\nimplicit truthy if(100) because 100 exists\n\n New operators\n\nconditional operators\n  safe navigation? operator checks for properties, such as if(company.getContact()?.getAddress()?.getCountry() == Country.NEW_ZEALAND) { ... } means If the contact or the address are null, the result of the left side will just be null, but no exception will be thrown.\n  ternary / elvis ? operator def name = client.getName() ?: \"\" will assign client.getName() if it isnt false and the empty string, otherwise\n\ntype operators\n  spaceship = delegates to the compareTo() method: def x = 1 = 2; println x; // calls Integer.compareTo\n  identity is() tests object reference equality, while == checks equality with .equals()\n  coercion as converts an object from one type to another (using .asType()), without assignment compatibility, which is different from casting: String s = \"1.1\"; BigDecimal bd = s as BigDecimal; println bd.class.name\n\nUsing methods\n\na function used in a script will be compiled to a method within an object\nreturn keyword is optional\nmethod operators\n  method pointer .& stores a reference to a method in a variable: def power = Math.&pow; def result = power(2, 4);\n  call operator () an object with a call method can be called directly: class A{def call(println(\"hi\"){}}; def a = new A(); a();\nclosures \n  like Java8 lambdas\n  anonymous first-class functions are often called lambda functions\n  def power = { int x, int y - return Math.pow(x, y) }; println power(2, 3)\ncurrying \nmemoization\n\n Collections: list and map\n\nlist and map operators\n  subscript [] allows to read/write to collections and maps: def list = [2, 4]; println list[0]; def map = [x: 2, y: 4]; println map['x']\n  membership in test whether value is in the target collection: def numbers = [2,4,6,8]; println 2 in numbers\n  spread-dot . invokes an action on all items of an aggregate object: def lists = [[1], [10, 20, 30], [6, 8]]; def sizes = lists.size(); //[1, 3, 2]\n  range .. to create ranges of objects: def numbers = 1..5; println numbers\ncreate an ArrayList with the given numbers: def list = [1,1,2,3,5]\nclosures make it easy to iterate, filter and transform lists\n  iterate a list using a passed closure executed once for each element, implicitly passed, as a parameter to the closure: list.each { println it }\n  filter a list: list.findAll { it % 2 == 0 }\n  transform a list: list.collect { it * it }\n  improve: [\"Hello\", \"World\"].collect { it.toUpperCase() } using the spread-dot: [\"Hello\", \"World\"]*.toUpperCase()\n  Collection (and Iterable) interfaces provide some more methods, like any or every\nmaps act similar to lists\n    def key = 'Key3'\n  def aMap = [\n    'Key1': 'Value 1', // Put key1 - Value 1 to the map\n    Key2: 'Value 2', // You can also skip the quotes, the key will automatically be a String\n    (key): 'Another value' // If you want the key to be the value of a variable, you need to put it in parantheses\n  ]\n  \nApplications in Data Science\n\n Dataframes with Tablesaw\n\nTablesaw is easy to add to the BeakerX Groovy kernel.\nTablesaw provides the ability to easily transform, summarize, and filter data, as well as computing descriptive statistics and fundamental machine learning algorithms.\n\nTwo helpful demo notebooks (scala) include:\nRecommnder System\nEvolution to a Data-Driven System\n\nAdd using mvn.\n\n%%classpath add mvn\ntech.tablesaw tablesaw-plot 0.11.4\ntech.tablesaw tablesaw-smile 0.11.4\ntech.tablesaw tablesaw-beakerx 0.11.4\n\n%import tech.tablesaw.aggregate.*\n%import tech.tablesaw.api.*\n%import tech.tablesaw.api.ml.clustering.*\n%import tech.tablesaw.api.ml.regression.*\n%import tech.tablesaw.columns.*\n\n// display Tablesaw tables with BeakerX table display widget\ntech.tablesaw.beakerx.TablesawDisplayer.register()\n\n{{ output }}\nnull\n{{ /output }}\n\nRead .csv data.\n\ntornadoes = Table.read().csv(\"../doc/resources/data/tornadoes_2014.csv\")\n\nPrint the dataset structure.\n\ntornadoes.structure()\n\nGet header names.\n\ntornadoes.columnNames()\n\n{{ output }}\n[Date, Time, State, State No, Scale, Injuries, Fatalities, Start Lat, Start Lon, Length, Width]\n{{ /output }}\n\nDisplays the row and column counts.\n\ntornadoes.shape()\n\n{{ output }}\n908 rows X 11 cols\n{{ /output }}\n\nDisplays the first n rows.\n\ntornadoes.first(3)\n\nimport static tech.tablesaw.api.QueryHelper.column\ntornadoes.structure().selectWhere(column(\"Column Type\").isEqualTo(\"FLOAT\"))\n\nSummarize the data in each column.\n\ntornadoes.summary()\n\n{{ output }}\n\nTable summary for: tornadoes_2014.csv\n       Column: Date        \n Measure   |    Value     |\n---------------------------\n    Count  |         908  |\n  Missing  |           0  |\n Earliest  |  2014-01-11  |\n   Latest  |  2014-12-29  |\n     Column: Time     \n Measure   |  Value  |\n----------------------\n    Count  |    908  |\n  Missing  |      0  |\n Earliest  |  00:01  |\n   Latest  |  23:59  |\n    Column: State     \n Category  |  Count  |\n----------------------\n       GA  |     32  |\n       NM  |     15  |\n       MT  |      8  |\n       CO  |     49  |\n       WV  |      9  |\n       IN  |     28  |\n       MD  |      2  |\n       CA  |      9  |\n       AL  |     55  |\n       TN  |     18  |\n      ...  |    ...  |\n       MO  |     47  |\n       ME  |      4  |\n       LA  |     15  |\n       MI  |     13  |\n       SC  |      7  |\n       KY  |     28  |\n       MA  |      3  |\n       CT  |      1  |\n       NH  |      2  |\n   Column: State No   \n Measure   |  Value  |\n----------------------\n        n  |  908.0  |\n      sum  |    0.0  |\n     Mean  |    0.0  |\n      Min  |    0.0  |\n      Max  |    0.0  |\n    Range  |    0.0  |\n Variance  |    0.0  |\n Std. Dev  |    0.0  |\n       Column: Scale       \n Measure   |    Value     |\n---------------------------\n        n  |       908.0  |\n      sum  |       567.0  |\n     Mean  |   0.6244493  |\n      Min  |         0.0  |\n      Max  |         4.0  |\n    Range  |         4.0  |\n Variance  |   0.6272737  |\n Std. Dev  |  0.79200613  |\n     Column: Injuries      \n Measure   |    Value     |\n---------------------------\n        n  |       908.0  |\n      sum  |       684.0  |\n     Mean  |  0.75330395  |\n      Min  |         0.0  |\n      Max  |       193.0  |\n    Range  |       193.0  |\n Variance  |    57.68108  |\n Std. Dev  |    7.594806  |\n     Column: Fatalities     \n Measure   |     Value     |\n----------------------------\n        n  |        908.0  |\n      sum  |         48.0  |\n     Mean  |  0.052863438  |\n      Min  |          0.0  |\n      Max  |         16.0  |\n    Range  |         16.0  |\n Variance  |   0.44262686  |\n Std. Dev  |    0.6653021  |\n    Column: Start Lat     \n Measure   |    Value    |\n--------------------------\n        n  |      908.0  |\n      sum  |  34690.984  |\n     Mean  |   38.20593  |\n      Min  |        0.0  |\n      Max  |      48.86  |\n    Range  |      48.86  |\n Variance  |  22.448586  |\n Std. Dev  |  4.7379937  |\n    Column: Start Lon     \n Measure   |    Value    |\n--------------------------\n        n  |      908.0  |\n      sum  |  -83613.02  |\n     Mean  |  -92.08483  |\n      Min  |   -122.946  |\n      Max  |        0.0  |\n    Range  |    122.946  |\n Variance  |   91.84773  |\n Std. Dev  |   9.583722  |\n      Column: Length      \n Measure   |    Value    |\n--------------------------\n        n  |      908.0  |\n      sum  |    3014.49  |\n     Mean  |   3.319923  |\n      Min  |        0.0  |\n      Max  |      45.68  |\n    Range  |      45.68  |\n Variance  |  28.736567  |\n Std. Dev  |  5.3606496  |\n      Column: Width       \n Measure   |    Value    |\n--------------------------\n        n  |      908.0  |\n      sum  |   149778.0  |\n     Mean  |  164.95375  |\n      Min  |        0.0  |\n      Max  |     2640.0  |\n    Range  |     2640.0  |\n Variance  |  57764.465  |\n Std. Dev  |  240.34239  |\n\n{{ /output }}\n\nMapping operations.\n\ndef month = tornadoes.dateColumn(\"Date\").month()\ntornadoes.addColumn(month);\ntornadoes.columnNames()\n\n{{ output }}\n[Date, Time, State, State No, Scale, Injuries, Fatalities, Start Lat, Start Lon, Length, Width, Date month]\n{{ /output }}\n\nSorting by column.\n\ntornadoes.sortOn(\"-Fatalities\")\n\nDescriptive statistics.\n\ntornadoes.column(\"Fatalities\").summary()\n\nPerforming totals and sub-totals.\n\ndef injuriesByScale = tornadoes.median(\"Injuries\").by(\"Scale\")\ninjuriesByScale.setName(\"Median injuries by Tornado Scale\")\ninjuriesByScale\n\nCross tabulation.\n\nCrossTab.xCount(tornadoes, tornadoes.categoryColumn(\"State\"), tornadoes.shortColumn(\"Scale\"))\n\nExample with Tablesaw\n\nYou can fetch data from Quandl and load it directly into Tablesaw\n\n%classpath add mvn com.jimmoores quandl-tablesaw 2.0.0\n%import com.jimmoores.quandl.*\n%import com.jimmoores.quandl.tablesaw.*\n\nTableSawQuandlSession session = TableSawQuandlSession.create();\nTable table = session.getDataSet(DataSetRequest.Builder.of(\"WIKI/AAPL\").build());\n\n// Create a new column containing the year\nShortColumn yearColumn = table.dateColumn(\"Date\").year();\nyearColumn.setName(\"Year\");\ntable.addColumn(yearColumn);\n// Create max, min and total volume tables aggregated by year\nTable summaryMax = table.groupBy(\"year\").max(\"Adj. Close\");\nTable summaryMin = table.groupBy(\"year\").min(\"Adj. Close\");\nTable summaryVolume = table.groupBy(\"year\")sum(\"Volume\");\n// Create a new table from each of these\nsummary = Table.create(\"Summary\", summaryMax.column(0), summaryMax.column(1), \n                       summaryMin.column(1), summaryVolume.column(1));\n// Add back a DateColumn to the summary...will be used for plotting\nDateColumn yearDates = new DateColumn(\"YearDate\");\nfor(year in summary.column('Year')){\n    yearDates.append(java.time.LocalDate.of(year,1,1));\n}\nsummary.addColumn(yearDates)\n\nsummary\n\nyears = summary.column('YearDate').collect()\n\nplot = new TimePlot(title: 'Price Chart for AAPL', xLabel: 'Time', yLabel: 'Max [Adj. Close]')\nplot << new YAxis(label: 'Volume')\nplot << new Points(x: years, y: summary.column('Max [Adj. Close]').collect())\nplot << new Line(x: years, y: summary.column('Max [Adj. Close]').collect(), color: Color.blue)\nplot << new Stems(x: years, y: summary.column('Sum [Volume]').collect(), yAxis: 'Volume')\n\n Auto-Translation in BeakerX\n\nAuto-Translation is the act of converting a data structure in one language to another.  In the context of data science, the obvious data structures are lists and data frames.\n\n//start with groovy\nbeakerx.foo = \"a groovy value\"\n\n{{ output }}\na groovy value\n{{ /output }}\n\n//to javascript\n%%javascript\nbeakerx.bar = [23, 48, 7, \"from JS\"];\nbeakerx.foo\n\n//back to groovy\nbeakerx.bar \n\n//to python\n%%python\nfrom beakerx import beakerx\nbeakerx.foo\n\n{{ output }}\n'a groovy value'\n{{ /output }}\n\n//to scala\n%%scala\nbeakerx.foo\n\n{{ output }}\na groovy value\n{{ /output }}\n\nGraphing with BeakerX\n\nBoth BeakerX and Tablesaw do a good job of addressing the need to visualize data. \n\nrates = new CSV().read(\"../doc/resources/data/interest-rates.csv\")\ndef f = new java.text.SimpleDateFormat(\"yyyy MM dd\")\nlehmanDate = f.parse(\"2008 09 15\")\nbubbleBottomDate = f.parse(\"2002 10 09\")\ninversion1 = [f.parse(\"2000 07 22\"), f.parse(\"2001 02 16\")]\ninversion2 = [f.parse(\"2006 08 01\"), f.parse(\"2007 06 07\")]\ndef size = rates.size()\n(0 ..< size).each{row = rates[it]; row.spread = row.y10 - row.m3}\n\nOutputCell.HIDDEN\n\n// The simplest chart function with all defaults:\nnew SimpleTimePlot(rates, [\"y1\", \"y10\"])\n\n//scatter plot\ndef c = new Color(120, 120, 120, 100)\nnew Plot() << new Points(x: rates.y1, y: rates.y30, displayName: \"y1 vs y30\") \\\n           << new Points(x: rates.m3, y: rates.y5, displayName: \"m3 vs y5\") \\\n           << new Line(x: rates.m3, y: rates.y5, color: c) \\\n           << new Line(x: rates.y1, y: rates.y30, color: c)\n\ndef ch = new Crosshair(color: Color.gray, width: 2, style: StrokeType.DOT)\n\n// The top plot has 2 lines.\np1 = new TimePlot(yLabel: \"Interest Rate\", crosshair: ch)\np1 << new Line(x: rates.time, y: rates.m3, displayName: \"3 month\")\np1 << new Line(x: rates.time, y: rates.y10, displayName: \"10 year\")\n\n// The bottom plot has an area filled in.\np2 = new TimePlot(yLabel: \"Spread\", crosshair: ch)\np2 << new Area(x: rates.time, y: rates.spread, color: new Color(120, 60, 0))\n\n// Highlight the inversion intervals\ndef b1 = new ConstantBand(x: inversion1, color: new Color(240, 100, 100, 55))\ndef b2 = new ConstantBand(x: inversion2, color: new Color(240, 100, 100, 55))\n\n// Add notation and line for Lehman Bankruptcy.\np1 << new Text(x: lehmanDate, y: 7.5, text: \"Lehman Brothers Bankruptcy\")\ndef l1 = new ConstantLine(x: lehmanDate, style: StrokeType.DOT, color: Color.gray)\n\n// Add notation and line for Stocks Nadir.\np1 << new Text(x: bubbleBottomDate, y: 5.75, text: \"Stocks Hit Bottom\")\ndef l2 = new ConstantLine(x: bubbleBottomDate, style: StrokeType.DOT, color: Color.gray)\n\n// add the notations and highlight bands to both plots\np1 << l1 << l2 << b1 << b2\np2 << l1 << l2 << b1 << b2\n\nOutputCell.HIDDEN\n\n// Then use a CombinedPlot to get stacked plots with linked X axis.\ndef c = new CombinedPlot(title: \"US Treasuries\", initWidth: 1000)\n\n// add both plots to the combined plot, and including their relative heights.\nc.add(p1, 3)\nc.add(p2, 1)\n\n Integration with D3js\n\nBeing able to prototype for the frontend is key for deliverying quickly.  The BeakerX integration with D3js is great for this.\n\ndef r = new Random()\ndef nnodes = 100\ndef nodes = []\ndef links = []\n\nfor (x in (0..nnodes)){\n  nodes.add(name:\"\" + x, group:((int) x*7/nnodes))\n}\n\nfor (x in (0..(int) nnodes*1.15)) { \n  source = x % nnodes\n  target = ((int) log(1 + r.nextInt(nnodes))/log(1.3))\n  value = 10.0 / (1 + abs(source - target))\n  links.add(source: source, target: target, value: value*value)\n}\n\nbeakerx.graph = [nodes: nodes, links: links]\nOutputCell.HIDDEN\n\n%%javascript\nrequire.config({\n  paths: {\n      d3: '//cdnjs.cloudflare.com/ajax/libs/d3/4.9.1/d3.min'\n  }});\n\n%%html\nstyle\n.node {\n  stroke: #fff;\n  stroke-width: 1.5px;\n}\n\n.link {\n  stroke: #999;\n  stroke-opacity: .6;\n}\n/style\n\nhtmlstyle\n.node {\n  stroke: #fff;\n  stroke-width: 1.5px;\n}\n\n.link {\n  stroke: #999;\n  stroke-opacity: .6;\n}\n/style/html\n\n%%javascript\n\nbeakerx.displayHTML(this, 'div id=\"fdg\"/div');\n\nvar graph = beakerx.graph\n\nvar d3 = require(['d3'], function (d3) {\n    \n    var width = 600,\n        height = 500;\n\n    var color = d3.scaleOrdinal(d3.schemeCategory20);\n\n    var simulation = d3.forceSimulation()\n        .force(\"link\", d3.forceLink().distance(30))\n        .force(\"charge\", d3.forceManyBody().strength(-200))\n        .force(\"center\", d3.forceCenter(width / 2, height / 2))\n        .force(\"y\", d3.forceY(width / 2).strength(0.3))\n        .force(\"x\", d3.forceX(height / 2).strength(0.3));\n\n    var svg = d3.select(\"#fdg\")\n                .append(\"svg\")\n                .attr(\"width\", width)\n                .attr(\"height\", height)\n                .attr(\"transform\", \"translate(\"+[100, 0]+\")\");\n\n    simulation\n          .nodes(graph.nodes)\n          .force(\"link\")\n          .links(graph.links);\n\n    var link = svg.selectAll(\".link\")\n          .data(graph.links)\n          .enter().append(\"line\")\n          .attr(\"class\", \"link\")\n          .style(\"stroke-width\", function(d) { return Math.sqrt(d.value); });\n\n    var node = svg.selectAll(\".node\")\n          .data(graph.nodes)\n          .enter().append(\"circle\")\n          .attr(\"class\", \"node\")\n          .attr(\"r\", 10)\n          .style(\"fill\", function(d) { return color(d.group); });\n\n    node.append(\"title\")\n          .text(function(d) { return d.name; });\n\n    simulation.on(\"tick\", function() {\n        link.attr(\"x1\", function(d) { return d.source.x; })\n            .attr(\"y1\", function(d) { return d.source.y; })\n            .attr(\"x2\", function(d) { return d.target.x; })\n            .attr(\"y2\", function(d) { return d.target.y; });\n\n        node.attr(\"cx\", function(d) { return d.x; })\n            .attr(\"cy\", function(d) { return d.y; });\n    });\n    \n    node.call(d3.drag()\n        .on(\"start\", dragstarted)\n        .on(\"drag\", dragged)\n        .on(\"end\", dragended)\n    );\n    \n    function dragstarted(d) {\n        if (!d3.event.active) simulation.alphaTarget(0.3).restart();\n        d.fx = d.x;\n        d.fy = d.y;\n    }\n\n    function dragged(d) {\n        d.fx = d3.event.x;\n        d.fy = d3.event.y;\n    }\n\n    function dragended(d) {\n        if (!d3.event.active) simulation.alphaTarget(0);\n        d.fx = null;\n        d.fy = null;\n    }\n});\n\nReferences\n\n Table of keywords\n\nThe following table lists the keywords which are defined in Groovy\n\n|   |   |   |   |   |\n|---|---|---|---|---|\n| as |      assert |      break |        case |\n| catch |\tclass  |     const \t|   continue |\n| def | \tdefault |\tdo \t   |      else |\n| enum |\textends |\tfalse \t|     Finally |\n| for |\tgoto \t|    if \t  |       implements |\n| import |\tin \t  |      instanceof |\t interface |\n| new |\tpull \t|    package |\t return |\n| super |\tswitch \t  |  this \t  |   throw |\n| throws |\ttrait \t|    true \t |    try |\n| while |\t\t\t\n\nGroovy but not Java:\n\n|   |   |   |   |   |\n|---|---|---|---|---|\n| as  |  def  |  in  |  trait |\n\nData types\n\nPrimitive data types\n    byte  represent a byte value. An example is 2\n    short  represent a short number. An example is 10\n    int  represent whole numbers. An example is 1234\n    long  represent a long number. An example is 10000090\n    float  represent 32-bit floating point numbers. An example is 12.34\n    double  represent 64-bit floating point numbers which are longer decimal numbers which may be required at times. An example is 12.3456565\n    char  defines a single character literal. An example is a\n    Boolean  represents a Boolean value which can either be true or false\n    String  text literals which are represented in the form of chain of characters. For example Hello World.\n\nIn addition to the primitive types, the following object types (sometimes referred to as wrapper types) are allowed \n    java.lang.Byte\n    java.lang.Short\n    java.lang.Integer\n    java.lang.Long\n    java.lang.Float\n    java.lang.Double\nFor arbitrary precision artithemetic\njava.math.BigInteger\njava.math.BigDecimal\n\n Online\n\nofficial website and documentation\ngetting started with groovy in IntelliJ\ngroovy for java developers\ngroovy tutorial\ndetailed groovy tutorials\n",
        "tags": [
            "groovy",
            "jvm",
            "data_visualization"
        ]
    },
    {
        "uri": "/posts/blog_programming_java-modern_java",
        "title": "A Data Scientist's Guide to Modern Java(8+) and the JVM",
        "content": "\n\nMost data scientists avoid the Java Virtual Machine (JVM) like the plague.  The features that make developers and data engineers so productive as a team, such as access modifiers and powerful IDEs, feel slow, old, and cumbersome to individuals interacting with data and prototyping new algorithms.  However, the JVM and its supporting system matured to an indominatble force since its inception.  It is ubiquitous in the most popular open-source projects; espectially in Big Data and distributed systems, such as Hadoop and Kafka.  The only competitors to Java in this domain are supporting languages that compile to the JVM, such as Scala, Groovy, and Kotlin.  Because of these factors the JVM culture sets precedence in a manner similar to Linux.  \n\nData scientists need to understand the perspective of other engineers and the tools they use in order to progress in their careers, and knowing Java is the backbone to this.  Another advantage to knowing java is that it exposes users to many fundamental computer science concepts.  This guide will provide the basics for getting familiar with Java, fast, as well as displaying different programming abstractions, such as testing, team integration and design patterns, not readily available to most consulting data scientists.  It will also provide support for a multitude of JVM languages that, while not necessary to know Java, will make life much easier.\n\nCulture and Precendence\n\nBecause Java is such an old and popular language it has quite alot of culture and history (some might say baggage) built around it.  This culture also creates precedence which might not be enforced by a compiler, but is so sacrosanct that anyone breaking the rules will quickly become a target.  Most of this is created around how Java found its niche: as a portable language for large organizations of development teams to deliver code.  For individual programmers much of Java functionality will not seem necessary, and even tiresome.  It grew-up before the age serverless technology or microservices.  But all of that changes once it is used by teams who have to work together, and, in turn, deliver components for a large, monolith system.\n\nSome general knowledge and basic conventions that help beginners:\n\nmodern Java begins with version Java 1.8, but is called Java8\nthe Java platform includes packages of functions, such as java, javax, org.omg; and the most fundamental: java.lang\npackage namespaces are the url of the company, backwards, such as com.firmname.classify.functions\ndirectory structures are implemented from the package name, so there can be alot of empty folders depending on how many suffixes you used\nthe directory path is for src the other is for test\neach Java class must be in an individual file, so you may have to have many files open in order to find something\ndependency management is performed by maven (traditional xml-based) or gradle (groovy-based)\n\nNaming conventions:\n\nClass and Inteface names should be nouns, in mixed case, such as class ImageSprite\nMethods should be verbs and Variables should be nouns, both in mixed camel case, such as getBackground() and float myWidth, respectivly\nconstants should be all upper-case, such as static final int MIN_WIDTH = 4\n\n Basics\n\nConfiguation and envrironment\n\nProper development in Java demands an Integrated Development Environment IDE.  JetBrain's Intellij IDEA is one of the best.  However, some time must be taken to become acquainted with it.\n\nGotchas:\n\nIntellij creates a project folder within its own directory for each project you create.  You must delete a project in both places.\nAlways Import a project, instead of just Opening one.\n???\n\nTo get started with Intellij, Import a new project.  Then move to the tests directory, open a file, and run tests by clicking on the green arrows that appear on the left side.\n\nThis tutorial will be created using Two Sigma's BeakerX JVM kernel for the Jupyter notebook.  So we will focus on package-level code snippets before looking at a larger project.  BeakerX allows you to reference work among cells by creating assigning the cell to a package just as you do within a project.\n\nThe following code cell creates a class BeakerTest, the class is then instantated, in the next cell.\n\npackage test.beaker;\n\nimport java.util.Date;\nimport java.text.SimpleDateFormat;\n\npublic class BeakerTest {\n  private Date _date;\n  private SimpleDateFormat sdf = new SimpleDateFormat(\"yyyy-MM-dd'T'HH:mmZ\");\n  \n  public BeakerTest() {\n    _date = new Date();\n  }\n\n  public String getDateTxt() {\n    return \"Today:\" + sdf.format(_date);\n  }\n\n  public String getDateUpperCaseTxt() {\n    return getDateTxt().toUpperCase();\n  }\n\n}\n\n{{ output }}\ntest.beaker.BeakerTest\n{{ /output }}\n\npackage test.beaker;\n\nBeakerTest bt = new BeakerTest();\nreturn bt.getDateTxt();\n\n{{ output }}\nToday:2019-06-27T13:20+0000\n{{ /output }}\n\nBecause BeakerX is designed for data science, graphs can be created by importing their Plot package.\n\nimport java.util.List;\nimport java.util.ArrayList;\nimport com.twosigma.beakerx.chart.xychart.Plot;\nimport com.twosigma.beakerx.chart.xychart.plotitem.*;\nimport com.twosigma.beakerx.chart.Color;\n\nPlot p = new Plot();\n\np.setTitle(\"this is a Java plot\");\n\nBars b = new Bars();\n\nListNumber yList = new ArrayListNumber();\nyList.add(2);\nyList.add(5);\nyList.add(4);\nyList.add(8);\n\nb.setY(yList);\nb.setColor(Color.blue);\nb.setWidth(0.5);\n\np.add(b);\n  \nreturn p;\n\npackage test.beaker;\ninterface DateGetter {\n   public String getDateTxt();\n}\n\n{{ output }}\ntest.beaker.DateGetter\n{{ /output }}\n\npackage test.beaker;\npublic class DG2 extends BeakerTest implements DateGetter {\n}\n\n{{ output }}\ntest.beaker.DG2\n{{ /output }}\n\n Core packages\n\nThe following are core packages that do not require dependency tracking, such as maven.\n\njava.lang  basic language functionality and fundamental types\njava.util  collection data structure classes\njava.io \t file operations\njava.math  multiprecision arithmetics\njava.nio \t the Non-blocking I/O framework for Java\njava.net \t networking operations, sockets, DNS lookups, ...\njava.security  key generation, encryption and decryption\njava.sql \t Java Database Connectivity (JDBC) to access databases\njava.awt \t basic hierarchy of packages for native GUI components\njava.text  Provides classes and interfaces for handling text, dates, numbers, and messages in a manner independent of natural languages.\njava.rmi \t Provides the RMI package.\njava.time  The main API for dates, times, instants, and durations.\njava.beans  The java.beans package contains classes and interfaces related to JavaBeans components.\njava.Applet  This package provides classes and methods to create and communicate with the applets.\n\nThe java.lang package is available without the use of an import statement. \n\nPopular libraries\n\nstandard\n  lang\n  util\n  io, nio\n  math\n  net\n\nproductivity\n  apache commons\n    math\n    cli\n    csv\n    io\n  guava, google commons\n  google-gson\n\ntesting \n  junit\n  mockito\n\nlogging\n  log4j\n  slf4j\n\napplication development\n  http\n  h2\n  jhipster\n  spring\n  hibernate orm\n\n Syntax\n\nBasic operations\n\ndouble result = 2.3 + 4.5;\nSystem.out.println(result);\nString result1 = \"Hello, \" + \"World\";\nSystem.out.println(result1);\n\n{{ output }}\n6.8\nHello, World\n{{ /output }}\n\n{{ output }}\nnull\n{{ /output }}\n\nBasic arrays\n\nint[] nums = {2, 5, 4, 9};\nSystem.out.println(nums[0]);\nString[] strings = {\"alsdj\", \"asldfj\", \"owiure\"};\nSystem.out.println(strings.length);\n\n{{ output }}\n2\n3\n{{ /output }}\n\n{{ output }}\nnull\n{{ /output }}\n\nTypical main within class\n\nclass Programm {\n  public static void main(String[] args){\n    Programm programm = new Programm();\n    programm.start();\n  }\n  public void start(){\n    String[] test = {\"This\", \"is\", \"a\", \"test\"};\n    for(String t:test){\n        System.out.println(t);\n    }\n  }\n}\n\n{{ output }}\ncom.twosigma.beaker.javash.bkr9f024aeb.Programm\n{{ /output }}\n\nExample using strings and conditionals\n\npackage test.beaker;\n\nimport java.lang.String;\n\npublic class Input1 {\n    \n  public String mIfElse(String[] args) {\n      String testr;\n    if(args.length  3){\n      String sArgs =  String.join(\",\", args);\n      testr =  \"Your argument is: \" + sArgs;\n        for(String arg: args){\n            System.out.println(arg);\n        }\n    } else {\n      testr = \"Not many arguments\";\n        for(int i=0; i<args.length; i++){\n            System.out.println(args[i]);\n        }\n    }\n      return testr;\n  }\n}\n\n{{ output }}\ntest.beaker.Input1\n{{ /output }}\n\npackage test.beaker;\n\nInput1 x = new Input1();\nString[] test = {\"This\", \"is\", \"a\", \"test\"}; \nSystem.out.println(x.mIfElse( test ));\n\nString[] y = {\"a\",\"test\"};\nSystem.out.println( x.mIfElse(y) );\n\n{{ output }}\nThis\nis\na\ntest\nYour argument is: This,is,a,test\na\ntest\nNot many arguments\n{{ /output }}\n\n{{ output }}\nnull\n{{ /output }}\n\nArray actions\n\npackage test.beaker;\n\nimport java.lang.String;\n\npublic class ArraySum {\n    public void sum() {\n        double[] numbers = { 1.1, 2.2, 3.3 };\n        System.out.println(\"[v1] Sum1 of {1.1,2.2,3.3}=\" + arraySum1(numbers));\n        System.out.println(\"[v2] Sum2 of {1.1,2.2,3.3}=\" + arraySum2(numbers));\n        System.out.println(\"[v3] Sum3 of {1.1,2.2,3.3}=\" + arraySum3(numbers));\n    }\n\n    public static double arraySum1(double[] nums) {\n        double sum = 0;\n        for(double num: nums) {\n            sum = sum + num;    // Or sum += num\n            }\n        return(sum);\n    }\n    \n    public static double arraySum2(double[] nums) {\n        double sum = 0;\n        for(int i=0; i<nums.length; i++) {\n            sum = sum + nums[i]; \n        }\n        return(sum);\n    }\n    public static double arraySum3(double[] nums) {\n        double sum = 0;\n        int i=0;\n        while(i<nums.length) {\n            sum = sum + nums[i]; \n            i++;            // Or i = i + 1, or i += 1\n        }\n        return(sum);\n    }\n}\n\n{{ output }}\ntest.beaker.ArraySum\n{{ /output }}\n\npackage test.beaker;\n\nArraySum x = new ArraySum();\nx.sum();\n\n{{ output }}\n[v1] Sum1 of {1.1,2.2,3.3}=6.6\n[v2] Sum2 of {1.1,2.2,3.3}=6.6\n[v3] Sum3 of {1.1,2.2,3.3}=6.6\n{{ /output }}\n\n{{ output }}\nnull\n{{ /output }}\n\nDeclare and allocate arrays\n\npackage test.beaker;\n\npublic class Allocate{\n    \n    public static void run(){\n        // one-step\n        int[] val1 = {1,2,3};\n        // two-step\n        int[] val2 = new int[3];\n        val2[0] = 1;\n        val2[1] = 2;\n        val2[2] = 3;\n        \n        System.out.println(val1[0]);\n        System.out.println(val2[0]);\n    }\n}\n\n{{ output }}\ntest.beaker.Allocate\n{{ /output }}\n\npackage test.beaker;\nAllocate x = new Allocate();\nx.run();\n\n{{ output }}\n1\n1\n{{ /output }}\n\n{{ output }}\nnull\n{{ /output }}\n\nTypical class\n\npackage test.beaker;\n\npublic class Circle {\n  private double radius;\n\n  public Circle(double radius) {\n    this.radius = radius;\n  }\n\n  public double getRadius() {\n    return(radius);\n  }\n\n  public void setRadius(double radius) {\n    this.radius = radius;\n  }\n\n  public double getArea() {\n    return(Math.PI * radius * radius);\n  }\n}\n\n{{ output }}\ntest.beaker.Circle\n{{ /output }}\n\nAllocating arrays\n\npackage test.beaker;\n\npublic class CircleArray {\n  public static void main(String[] args) {\n    // Do something with arrays\n  }\n  \n  /** Builds an array of Circles and returns the array. After allocating space for the Circles, \n   it loops down, builds a Circle, and puts it into the appropriate place in the array.\n   This is the correct approach. \n   */\n  public static Circle[] makeCircles1(int numCircles) {\n    Circle[] circles = new Circle[numCircles];      // Allocate space\n    for(int i=0; i<circles.length; i++) {\n      circles[i] = new Circle(Math.random() * 10);  // Put circles in the array\n    }\n    return(circles);\n  }\n  \n  /** Attempts to build an array of Circles. Crashes with NullPointerException since after\n   first line there are no Circle objects, just null pointers. So, trying to call setRadius\n   on null crashes. \n   */\n  public static Circle[] makeCircles2(int numCircles) {\n    Circle[] circles = new Circle[numCircles];\n    for(int i=0; i<circles.length; i++) {\n      circles[i].setRadius(Math.random() * 10); // Crashes with NullPointerException\n    }\n    return(circles);\n  }\n  \n  /** Attempts to build an array of Circles. Fails because it never puts any Circles\n   into the array. To put something into an array, you must have the index.\n   *  The funny @SuppressWarnings entry below is something we have not yet\n   covered. It just tells Eclipse not to warn that the variable c in the loop\n   below is never used, since I already know that the code is wrong. It is a bad habit\n   to leave code in your projects that has warnings, because then you get in the habit\n   of ignoring the warnings, and the vast majority of the warnings are useful.\n   If you are deliberately doing something that will result in a warning from Eclipse, \n   suppress the warnings using \n   http://help.eclipse.org/mars/index.jsp?topic=%2Forg.eclipse.jdt.doc.user%2Ftasks%2Ftask-suppress_warnings.htm\n   and, preferably document why you are doing things a knowingly bad way.\n   */\n  @SuppressWarnings(\"unused\")\n  public static Circle[] makeCircles3(int numCircles) {\n    Circle[] circles = new Circle[numCircles];\n    for(Circle c: circles) {\n      c = new Circle(Math.random() * 10);; // Fails to store c in array\n    }\n    return(circles); // Array still contains only null pointers\n  }\n}\n\n{{ output }}\ntest.beaker.CircleArray\n{{ /output }}\n\npackage test.beaker;\n\nCircleArray x = new CircleArray();\nCircle[] y = x.makeCircles1(3);\nSystem.out.println(y[0].getRadius() );\n\n{{ output }}\n3.716013423654272\n{{ /output }}\n\n{{ output }}\nnull\n{{ /output }}\n\nStatic methods (math operations) these are essentially global functions\n\ndouble rand = Math.random();\nSystem.out.println(rand);\nSystem.out.println(Math.pow(2,3));\n\nSystem.out.println(Math.exp(2.30));\nSystem.out.println(Math.log(10));\n\n{{ output }}\n0.03994823989553764\n8.0\n9.974182454814718\n2.302585092994046\n{{ /output }}\n\n{{ output }}\nnull\n{{ /output }}\n\nUse of static import\n\nimport static java.lang.Math.*;\n...\ndouble d1 = cos(...);   // Instead of Math.cos(...)\ndouble d2 = sin(...);   // Instead of Math.sin(...)\ndouble d3 = random(); // Instead of Math.random()\n\nKeywords\n\nThe following is a table of all keywords.  Some noteworthy points regarding Java keywords:\n\nconst and goto are resevered words but not used\ntrue, false and null are literals, not keywords\nsince Java 8, the default keyword is also used to declare default methods in interfaces\nsince Java 10, the word var is used to declare local variables (local variables type inference). For backward compatibility, you can still use var as variable names. So var is a reserved word, not keyword\nall keywords are in lower-case\nall keywords are reserved words but all reserved words are not keywords. Specifically, Java has two reserved words (goto and const) which are not keywords\n  Reserved words are those that cannot be used as identifiers (class names, method names, varaible names etc).  For example, class, public, int, etc are reserved words\n  Keywords are those words which convey some special meaning to the compiler. For example, the kewyord break indicates some form of branching, class is used to specify  a class definition\n\nAccess modifiers: private, protected, public\n    \nFlow control: break, case, continue, default, do, else, for, if, instanceof, return, switch, while\n\nPackage control: import, package\n\nPrimitive types: boolean, byte, char, double, float, int, long, short\n\nError handling: assert, catch, finally, throw, throws, try\n\nEnumeration: enum\n    \nOthers:  super, this, void\n\nUnused (reserved): const, goto \n\nClass, method, variable modifiers:\n\nabstract, class, default, extends, final, \n\nimplements, interface, native, new, \n\nstatic, strictfp, synchronized, transient, \n\nvar, volatile\n\n Annotations\n\nStandard\n  @Override\n  @Deprecated\n  @SuppressWarnings\n  \nSpring\n  ???\n  ???\n\nGenerics\n\nIntermediate Java developers should also to be able to define classes or methods that support generics.\n\nUsing TypeVariable\n    \nIf you put variables in angle brackets in the class or method definition, it tells Java that uses of those variables refer to types, not to values\nIt is conventional to use short names in upper case, such as T, R (input type, result type) or T1, T2 (type1, type2), or E (element type)\n\nUsing Generic Types in Existing Classes\n\nFind a data structure that accepts Object(s)\n\nArrayList, LinkedList, HashMap, HashSet, Stack\n\nDeclare the data structure with the type(s) in angle brackets \nimmediately after type name\n\nListString names = new ArrayList();\nMapString,Person employees = new HashMap();\n\nInsert objects of the appropriate type\n\nnames.add(\"Some String\");\nemployees.put(person.getEmployeeId(), person);\n\nNo typecast required on removal\n\nString firstName = names.get(0);\nPerson p1 = employees.get(\"a1234\");\n\n----------------------------------------------------------\n`` diamond operator \n\nAutoboxing\n\nSo you cannot actually store int, double, and other primitives. You cannot declare the List to take primitives (e.g., Listint is illegal)\nThese data structures can only store wrapper types (Integer, Double, etc.)\n\nimport java.util.*;\n\npublic class RandomList {\n    public static void main(String[] args) {\n        ListString entries = new ArrayList();\n        double d;\n        while((d = Math.random())  0.1) {\n            entries.add(\"Value: \" + d);\n        }\n        for(String entry: entries) {System.out.println(entry);}\n    }\n}\n\n{{ output }}\ncom.twosigma.beaker.javash.bkr9f024aeb.RandomList\n{{ /output }}\n\n/*\nThis says that the best method takes a List of Ts and returns a T.\nThe 'T' at the beginning means T is not a real type, but a type \nthat Java will figure out from the method call\n*/\n    \npublic static T T methodname(ListT entries, ...) { ... }\n\npackage generics.beaker;\n\nimport java.util.Random;\n\npublic class RandomUtils {\n  private static Random r = new Random();\n\n  /** Return a random int from 0 to range-1. So, randomInt(4)\n   returns any of 0, 1, 2, or 3.\n   */\n  public static int randomInt(int range) {\n    return(r.nextInt(range));\n  }\n\n  /** Return a random index of an array. */\n  public static int randomIndex(Object[] array) {\n    return(randomInt(array.length));\n  }\n\n  /** Return a random element from an array.\n   Uses generics, so no typecast is required\n   for the return value.\n   */\n  public static T T randomElement(T[] array) {\n    return(array[randomIndex(array)]);\n  }\n  /* T\n     In rest of method, T refers to a type.\n     Java will figure out what type T is by looking at the parameters of the method call.\n     Even if there is an existing class actually called T, it is irrelevant here.\n  */\n  /* T and T[]\n    This says that the method takes in an array of Ts and returns a T.\n    For example, if you pass in an array of Strings, you get out a String;\n    if you pass in an array of Employees, you get out an Employee.\n    No typecasts required in any of the cases.\n  */\n}\n\n{{ output }}\ngenerics.beaker.RandomUtils\n{{ /output }}\n\npackage generics.beaker;\n\nimport java.util.Random;\nimport java.util.*;\n\nRandomUtils r = new RandomUtils();\nString[] arr = new String[3]; \narr[0] = \"one\";\narr[1] = \"two\";\narr[2] = \"three\";\nSystem.out.println( r.randomElement(arr) );\nString[] names = { \"Joe\", \"John\", \"Jane\" };\nString name = r.randomElement(names);\nSystem.out.println(name);\nInteger[] nums = { 1, 2, 3, 4 };    \nint num = r.randomElement(nums);\nSystem.out.println(num);\n\n{{ output }}\none\nJohn\n3\n{{ /output }}\n\n{{ output }}\nnull\n{{ /output }}\n\npackage generics.beaker;\n\nimport java.util.*;\n\npublic class Cprint {\n    \n    public static T T mPrint(ListT lArg ){\n        for(T item: lArg){\n            System.out.println(item);\n        }\n        //return(lArg.get(0));    <-- wierd, seems like it should have to return something\n    }\n    static T void mDisplay(ListT lArg){\n        for(T item: lArg){\n            System.out.println(item);\n        }\n    }\n}\n\n{{ output }}\ngenerics.beaker.Cprint\n{{ /output }}\n\n// WTF???\npackage generics.beaker;\n\nimport java.util.*;\n\nCprint inst = new Cprint();\nListString lArg = new ArrayList(); \nlArg.add(\"one\");\nlArg.add(\"two\");\nlArg.add(\"three\");\ninst.mPrint(lArg);\nSystem.out.println(\"\");\ninst.mDisplay(lArg);\n\n{{ output }}\ncannot find symbol\n{{ /output }}\n\n{{ output }}\n  symbol:   class Cprint\n{{ /output }}\n\n{{ output }}\n  location: class generics.beaker.BeakerWrapperClass1261714175Id08595fc76c1a46ebbef0e11cd0c086e8\n{{ /output }}\n\n{{ output }}\n Cprint inst = new Cprint()\n{{ /output }}\n\n{{ output }}\n ^     ^                     \n{{ /output }}\n\n{{ output }}\n{{ /output }}\n\n{{ output }}\ncannot find symbol\n{{ /output }}\n\n{{ output }}\n  symbol:   class Cprint\n{{ /output }}\n\n{{ output }}\n  location: class generics.beaker.BeakerWrapperClass1261714175Id08595fc76c1a46ebbef0e11cd0c086e8\n{{ /output }}\n\n{{ output }}\n Cprint inst = new Cprint()\n{{ /output }}\n\n{{ output }}\n                   ^     ^   \n{{ /output }}\n\n// Class\n// We use   to specify Parameter type\nclass TestT{\n    // An object of type T is declared\n    T obj;\n    Test(T obj) {  this.obj = obj;  }  // constructor\n    public T getObject()  { return this.obj; }\n}\n  \n// Driver class to test above\nclass Main{\n    public static void main (String[] args)\n    {\n        // instance of Integer type\n        Test Integer iObj = new TestInteger(15);\n        System.out.println(iObj.getObject());\n        // instance of String type\n        Test String sObj = new TestString(\"GeeksForGeeks\");\n        System.out.println(sObj.getObject());\n    }\n}\n\n{{ output }}\ncom.twosigma.beaker.javash.bkr9f024aeb.Test\n{{ /output }}\n\n// yeah, I could spend some time one this\n\n Methods\n\nMethods (pass by value)\n\nref\ndiscussion\n\nPass-by-value\n    The actual parameter (or argument expression) is fully evaluated and the resulting value is copied into a location being used to hold the formal parameter's value during method/function execution. That location is typically a chunk of memory on the runtime stack for the application (which is how Java handles it), but other languages could choose parameter storage differently.\n\nPass-by-reference\n    The formal parameter merely acts as an alias for the actual parameter. Anytime the method/function uses the formal parameter (for reading or writing), it is actually using the actual parameter. \n\nAutoboxing\n\nimport java.util.*;\n\npublic class Autoboxing {\n    public static void main(String[] args) {\n        ListInteger nums = new ArrayList();\n        int[] values = { 2, 4, 6 };\n        for(int value: values) {\n            nums.add(value);\n        }\n        System.out.println(\"List: \" + nums);\n        int secondNum = nums.get(1);\n        System.out.println(\"Second number: \" + secondNum);\n    }\n}\n\n{{ output }}\ncom.twosigma.beaker.javash.bkr9f024aeb.Autoboxing\n{{ /output }}\n\n/* Java program to illustrate autoboxing */\nimport java.io.*;\nimport java.util.*;\n \nclass GFG\n{\n    public static void main (String[] args)\n    {\n        /* Here we are creating a list\n          of elements of Integer type.\n          adding the int primitives type values */\n        ListInteger list = new ArrayListInteger();\n        for (int i = 0; i < 10; i++)\n            list.add(i);\n    }\n}\n\n{{ output }}\ncom.twosigma.beaker.javash.bkr9f024aeb.GFG\n{{ /output }}\n\n/* Java program to illustrate autoboxing */\nimport java.io.*;\nimport java.util.*;\n \nclass GFG\n{\n    public static void main (String[] args)\n    {\n        /* Here we are creating a list of elements\n          of Integer type. Adding the int primitives\n          type values by converting them into Integer\n          wrapper Object*/\n        ListInteger list = new ArrayListInteger();\n        for (int i = 0; i < 10; i++)\n            list.add(Integer.valueOf(i));\n \n    }\n}\n\n{{ output }}\ncom.twosigma.beaker.javash.bkr9f024aeb.GFG\n{{ /output }}\n\n/*Another example of auto and unboxing is to find sum of odd numbers in a list. \nImportant point in the program is that the operators remainder (%) and unary \nplus (+=) operators do not apply to Integer objects. But still code compiles\nsuccessfully because the unboxing of Integer Object to primitive int value is\ntaking place by invoking intValue() method at runtime.\n*/\n// Java program to illustrate  find sum\n// of odd numbers using autobxing and unboxing\nimport java.io.*;\nimport java.util.*;\n \nclass GFG\n{\n    public static int sumOfOddNumber(ListInteger list)\n    {\n        int sum = 0;\n        for (Integer i : list)\n        {\n            // unboxing of i automatically\n            if(i % 2 != 0)\n                sum += i;\n            /* unboxing of i is done automatically\n               using intvalue implicitly\n            if(i.intValue() % 2 != 0)\n                sum += i.intValue();*/\n        }\n        return sum;\n    }\n \n    public static void main (String[] args)\n    {\n        /* Here we are creating a list of elements\n           of Integer type and adding the int primitives\n           type values to the list*/\n        ListInteger list = new ArrayListInteger();\n        for (int i = 0; i < 10; i++)\n            list.add(i);\n \n        // getting sum of all odd no. in the list.\n        int sumOdd = sumOfOddNumber(list);\n        System.out.println(\"Sum of odd numbers = \" + sumOdd);\n    }\n}\n\n{{ output }}\ncom.twosigma.beaker.javash.bkr9f024aeb.GFG\n{{ /output }}\n\n Collections\n\npackage test.beaker;\n/*\nYou say List (the interface type) instead of ArrayList (the concrete class) here so that you do not \naccidentally use one of the few methods that is specific to ArrayList. That way, if you decide to \nchange to LinkedList for performance reasons, all the rest of your code stays the same, and the \noutput is unchanged. And of course if you make a method that accepts a list, it is doubly \nimportant that you declare the parameter as ListBlah, not ArrayListBlah, so that the same \nmethod can also be used for another type of List.\n*/\nimport java.util.*;\n\nListString myArr = new ArrayList();\nListString myLink = new LinkedList();\n\nmyArr.add(\"new item\");\nmyArr.add(0,\"first new item\");\nmyArr.add(\"another item\");\nmyArr.add(\"last item\");\n/*\n builtin toString method that shows the \nList values separated by commas. \n*/\nSystem.out.println(myArr);\nSystem.out.println(myArr.get(1));\n\n{{ output }}\n[first new item, new item, another item, last item]\nnew item\n{{ /output }}\n\n{{ output }}\nnull\n{{ /output }}\n\npackage test.beaker;\n\nimport java.util.*;\nimport java.util.List;\nimport java.util.stream.Collectors;\n\nListString myArr = new ArrayList();\nmyArr.add(\"new item\");\nmyArr.add(0,\"first new item\");\nmyArr.add(\"another item\");\nmyArr.add(\"last item\");\n\nfor(String item: myArr){\n    System.out.println(item);\n}\nSystem.out.println(\"\\n\");\nmyArr.forEach(System.out::println);\n\nSystem.out.println(\"\\n\");\nListString result = myArr.stream()                        // convert list to stream\n                .filter(line - !\"last item\".equals(line))  // we dont like mkyong\n                .collect(Collectors.toList());              // collect the output and convert streams to a List\nSystem.out.println(result);\n\n{{ output }}\nfirst new item\nnew item\nanother item\nlast item\n\nfirst new item\nnew item\nanother item\nlast item\n\n[first new item, new item, another item]\n{{ /output }}\n\n{{ output }}\nnull\n{{ /output }}\n\nList methods\n\nimport java.util.*;\n\nListString words = new ArrayList();\n// ListString words = new LinkedList();\n// ListString wordList1 = Arrays.asList(\"word1\", \"word2\", ...);      <<< asList() not used in production\nwords.add(\"hi\");\nwords.add(\"hello\");\nwords.add(\"hola\");\nSystem.out.println(\"List: \" + words);\nSystem.out.println(\"Num words: \" + words.size());\nString secondWord = words.get(1);\nSystem.out.println(\"2nd word: \" + secondWord);\nSystem.out.println(\"Contains 'hi'? \" + words.contains(\"hi\"));\nSystem.out.println(\"Contains 'bye'? \" + words.contains(\"bye\"));\nwords.remove(\"hello\");\nSystem.out.println(\"List: \" + words);\nSystem.out.println(\"Num words: \" + words.size());\n\n{{ output }}\nList: [hi, hello, hola]\nNum words: 3\n2nd word: hello\nContains 'hi'? true\nContains 'bye'? false\nList: [hi, hola]\nNum words: 2\n{{ /output }}\n\n{{ output }}\nnull\n{{ /output }}\n\n// lambda\nimport java.util.*;\n\nListString words = new ArrayList(); \n// or,  = new LinkedList();\nwords.add(\"hi\");\nwords.add(\"hello\");\nwords.add(\"hola\");\nSystem.out.println(\"List: \" + words);\nwords.sort((word1,word2) - word1.length()-word2.length());\nSystem.out.println(\"List: \" + words);\nwords.replaceAll(word - word.toUpperCase() + \"!\");\nSystem.out.println(\"List: \" + words);\nwords.removeIf(word - word.contains(\"E\"));\nSystem.out.println(\"List: \" + words);\nwords.forEach(word - System.out.println(\"Word: \" + word));\nString[] wordArray = words.toArray(new String[0]);\nfor(String word: wordArray) {\n    System.out.println(\"Word: \" + word);\n}\n\n{{ output }}\nList: [hi, hello, hola]\nList: [hi, hola, hello]\nList: [HI!, HOLA!, HELLO!]\nList: [HI!, HOLA!]\nWord: HI!\nWord: HOLA!\nWord: HI!\nWord: HOLA!\n{{ /output }}\n\n{{ output }}\nnull\n{{ /output }}\n\n// maps / hashmaps (lookup tables or associative arrays)\nimport java.util.*;\n\nMapString, Double map = new HashMap();\nmap.put(\"one\",1.0);\nDouble result = map.get(\"one\");\nSystem.out.println(result);\n\n{{ output }}\n1.0\n{{ /output }}\n\n{{ output }}\nnull\n{{ /output }}\n\nhashmap performance\n\nInserting a value associated with a key\n    Independent of the number of entries in the table, i.e., O(1)  \nFinding the value associated with a key\n    Independent of the number of entries in the table, i.e., O(1)\nFinding the key associated with a value\n    Requires you to look at every entry, i.e., O(N)\n\npackage map.beaker;\n\nimport java.util.*;\n\npublic class StateMap {\n    \n    private static String stateArray = {{\"AK\",\"Alaska\"},{\"AL\",\"Arizona\"},{\"AR\",\"Arkansas\"}};\n    \n    private static MapString, String stateMap = new HashMap();\n    \n    static{\n        for(String[] state: stateArray ){\n            stateMap.put(state[0],state[1]);\n        }\n    }\n    \n    public static String statename(String stateCode){\n        return( stateMap.getOrDefault(stateCode, \"[None]\") );\n    }\n}\n\n{{ output }}\nmap.beaker.StateMap\n{{ /output }}\n\npackage map.beaker;\n\nimport java.util.*;\n\nStateMap x = new StateMap();\nString result = x.statename(\"AK\");\nSystem.out.println(result);\n\n// new hashmap\nMapString, Integer stateMap = new HashMap();\nstateMap.put(\"one\",1);\nstateMap.put(\"two\",2);\nstateMap.put(\"three\",3);\n\nSystem.out.println(stateMap.keySet());\nSystem.out.println(stateMap.values());\nSystem.out.println(stateMap.size());\nstateMap.forEach((k,v) - System.out.printf(\"(%s,%s)%n\", k, v));\n//stateMap.computeIfAbsent('four', f());\n//map.merge(key, message, String::concat)\n\n{{ output }}\nAlaska\n[one, two, three]\n[1, 2, 3]\n3\n(one,1)\n(two,2)\n(three,3)\n{{ /output }}\n\n{{ output }}\nnull\n{{ /output }}\n\n// set\n// Similar to a Map where the values corresponding to each key are just boolean true\nimport java.util.*;\n\nSetString set = new HashSet();\nset.add(\"one\");\nset.add(\"two\");\nset.add(\"two\");\n\nSystem.out.println( set.contains(\"two\") );\nSystem.out.println( set.contains(\"three\") );\n\n{{ output }}\ntrue\nfalse\n{{ /output }}\n\n{{ output }}\nnull\n{{ /output }}\n\n// printf\n\nSystem.out.printf(\"%s, %s, and %s.%n\", v1, v2, v3);\n\n// variable arguments (Type... argument)\npublic class MathUtils {\n    public static int min(int... numbers){\n        int minimum = Integer.MAX_VALUE;\n        for(int number: numbers) {\n            if (number < minimum) {\n                minimum = number;\n            }\n        }\n        return(minimum);\n    }\n    public static void main(String[] args) {\n        System.out.printf(\"Min of 2 nums: %d.%n\", min(2,1));\n        System.out.printf(\"Min of 7 nums: %d.%n\", min(2,4,6,8,1,2,3));\n    }\n}\n\n{{ output }}\ncom.twosigma.beaker.javash.bkr9f024aeb.MathUtils\n{{ /output }}\n\n// String - immutable\n// performance: O(N^2)\n// i)copied result, ii)allocate a new String object, iii)assign that new object to result\npublic static String padChars1(int n, String orig) {\n    String result = \"\";\n    for(int i=0; i<n; i++) {\n        result = result + orig;\n    }\n    return(result);\n}\n\n// StringBuilder - mutable\n// performance: O(N)\npublic static String padChars2(int n, String orig) {\n    StringBuilder result = new StringBuilder(\"\");\n    for(int i=0; i<n; i++) {\n        result = result.append(orig);\n    }\n    return(result.toString());\n}\n\nObject Oriented Programming\n\n Thinking like a developer\n\nOOP for modeling the world\n\nDifficulties when working in a team\n\nGetters and setters\n\nAccess modifiers\n\naccess modifiers\ngeneral modifiers\n\nOnce you learn about private, your strategy is this:\n\nIf you want code that uses your class to access the method, make it public. \nIf your method is called only by other met hods in the same class,  make it private. \nMake it private unless you have a specific reason to do otherwise.\n\nDefault\n\n//Java program to illustrate default modifier\npackage p1.beaker;\n \n//Class Geeks is having Default access modifier\nclass Geek\n{\n    void display()\n       {\n           System.out.println(\"Hello World!\");\n       }\n}\n\n{{ output }}\np1.beaker.Geek\n{{ /output }}\n\n//Java program to illustrate error while \n//using class from different package with\n//default modifier\npackage p2.beaker;\nimport p1.*;\n \n//This class is having default access modifier\nclass GeekNew\n{\n    public static void main(String args[])\n       {  \n          //accessing class Geek from package p1\n          Geeks obj = new Geek();\n          obj.display();\n       }\n}\n\n{{ output }}\nERROR: java.lang.IllegalStateException: package p1 does not exist\n{{ /output }}\n\n{{ output }}\n import p1.*\n{{ /output }}\n\n{{ output }}\n ^           \n{{ /output }}\n\n{{ output }}\n{{ /output }}\n\n{{ output }}\ncannot find symbol\n{{ /output }}\n\n{{ output }}\n  symbol:   class Geeks\n{{ /output }}\n\n{{ output }}\n  location: class p2.beaker.GeekNew\n{{ /output }}\n\n{{ output }}\n Geeks obj = new Geek()\n{{ /output }}\n\n{{ output }}\n ^    ^                  \n{{ /output }}\n\n{{ output }}\n{{ /output }}\n\n{{ output }}\ncannot find symbol\n{{ /output }}\n\n{{ output }}\n  symbol:   class Geek\n{{ /output }}\n\n{{ output }}\n  location: class p2.beaker.GeekNew\n{{ /output }}\n\n{{ output }}\n Geeks obj = new Geek()\n{{ /output }}\n\n{{ output }}\n                 ^   ^   \n{{ /output }}\n\nPrivate\n\n//Java program to illustrate error while \n//using class from different package with\n//private modifier\npackage p1.beaker;\n \nclass A\n{\n   private void display()\n    {\n        System.out.println(\"GeeksforGeeks\");\n    }\n}\n \nclass B\n{\n   public static void main(String args[])\n      {\n          A obj = new A();\n          //trying to access private method of another class\n          obj.display();\n      }\n}\n\n{{ output }}\nERROR: java.lang.IllegalStateException: display() has private access in p1.beaker.A\n{{ /output }}\n\n{{ output }}\n obj.display()\n{{ /output }}\n\n{{ output }}\n ^          ^   \n{{ /output }}\n\nProtected\n\n//Java program to illustrate\n//protected modifier\npackage p1.beaker;\n \n//Class A\npublic class A\n{\n   protected void display()\n    {\n        System.out.println(\"GeeksforGeeks\");\n    }\n}\n\n{{ output }}\np1.beaker.A\n{{ /output }}\n\n//Java program to illustrate\n//protected modifier\npackage p2.beaker;\nimport p1.*; //importing all classes in package p1\n \n//Class B is subclass of A\nclass B extends A\n{\n   public static void main(String args[])\n   {  \n       B obj = new B();  \n       obj.display();  \n   }  \n     \n}\n\n{{ output }}\nERROR: java.lang.IllegalStateException: package p1 does not exist\n{{ /output }}\n\n{{ output }}\n import p1.*\n{{ /output }}\n\n{{ output }}\n ^           \n{{ /output }}\n\n{{ output }}\n{{ /output }}\n\n{{ output }}\ncannot find symbol\n{{ /output }}\n\n{{ output }}\n  symbol: class A\n{{ /output }}\n\n{{ output }}\n class B extends A\n{{ /output }}\n\n{{ output }}\n                 ^^ \n{{ /output }}\n\n{{ output }}\n{{ /output }}\n\n{{ output }}\ncannot find symbol\n{{ /output }}\n\n{{ output }}\n  symbol:   method display()\n{{ /output }}\n\n{{ output }}\n  location: variable obj of type p2.beaker.B\n{{ /output }}\n\n{{ output }}\n obj.display()\n{{ /output }}\n\n{{ output }}\n ^          ^   \n{{ /output }}\n\nPublic\n\n//Java program to illustrate\n//public modifier\npackage p1.beaker;\npublic class A\n{\n   public void display()\n      {\n          System.out.println(\"GeeksforGeeks\");\n      }\n}\n\n{{ output }}\np1.beaker.A\n{{ /output }}\n\npackage p1.beaker;\n// should work with the below\n//package p2.beaker;\n//import p1.beaker;\nclass B\n{\n    public static void main(String args[])\n      {\n          A obj = new A();\n          obj.display();\n      }\n}\n\n{{ output }}\np1.beaker.B\n{{ /output }}\n\n// Static Blocks\n//  Code that runs when class is loaded, not when instance is built (as with constructor).  Used to initialize static variables that require multiple steps to build their values.\nimport java.util.*;\n\npublic class Blah{\n    private static MapString,String map = new HashMap();\n    static {\n        map.put(\"key1\", \"value1\");\n        map.put(\"key2\", \"value2\");\n    }\n}\n\n{{ output }}\ncom.twosigma.beaker.javash.bkr9f024aeb.Blah\n{{ /output }}\n\n Abstract and Interface\n\nInterfaces are more flexible, because a class can implement multiple interfaces.  Since Java does not have multiple inheritance, using abstract classes prevents your users from using any other class hierarchy. In general, prefer interfaces when there are no default implementations or state. Java collections offer good examples of this (Map, Set, etc.).\nAbstract classes have the advantage of allowing better forward compatibility.  Once clients use an interface, you cannot change it; if they use an abstract class, you can still add behavior without breaking existing code. If compatibility is a concern, consider using abstract classes.\nEven if you do have default implementations or internal state, consider offering an interface and an abstract implementation of it. This will assist clients, but still allow them greater freedom if desired\n\nInterfaces\n\nEnforces behavior - Like abstract classes, guarantees classes have certain methods\nMore flexibility that abstract classes  Classes can implement multiple interfaces\nYou cannot directly extend multiple abstract classes\nNew features in Java 8 interfaces  Interfaces can have static methods\nExample shown on upcoming slides in this section  Interfaces can have concrete (default) methods\nExample and more details in later section on Java 8 interfaces\nRestriction  Even in Java 8, interfaces cannot have mutable (modifiable) instance variables\n\npackage shape3.beaker;\n\n/** Represents the parent of all shapes that have a getArea method.\n This (using an interface) is the third attempt at a design that will support \n making a static method to sum the areas of a mixed set of shapes. This approach is \n better than the second approach (using an abstract class) in two ways: because classes\n can implement more than one interface, and because with static methods in interfaces\n Java enforces that you call them via InterfaceName.staticMethodName(...), whereas with\n static methods in abstract classes it is possible to call them via instanceName.staticMethodName(...),\n which misleads readers of the code into thinking that they are normal instance methods\n instead of static methods. General rule in Java 8 and later: use interfaces instead of abstract\n classes except for the relatively rare case where you need to define instance variables\n in the abstract class.\n */\n\npublic interface Shape {\n  double getArea(); // All real shapes must define a getArea \n  \n  static double sumAreas(Shape[] shapes) {\n    double sum = 0;\n    for(Shape s: shapes) {\n      sum = sum + s.getArea();\n    }\n    return(sum);\n  }\n}\n\n{{ output }}\nshape3.beaker.Shape\n{{ /output }}\n\npackage shape3.beaker;\n/** Represents a simplistic Circle. Used to illustrate encapsulation (private instance vars),\n JavaDoc (these comments), and inheritance (extending Shape so that we can make an array\n of mixed shapes and sum their areas).\n */\n\npublic class Circle implements Shape {\n  private double radius;\n\n  /** Builds a Circle with the given radius. */\n  \n  public Circle(double radius) {\n    this.radius = radius;\n  }\n\n  /** Returns the current radius. */\n  \n  public double getRadius() {\n    return(radius);\n  }\n\n  /** Sets the current radius. */\n  \n  public void setRadius(double radius) {\n    this.radius = radius;\n  }\n\n  /** Calculates the area from the radius. */\n  @Override\n  public double getArea() {\n    return(Math.PI * radius * radius);\n  }\n\n  /** Indirectly sets the area by working backward to the radius.\n   The resultant area may not be EXACTLY what you set, due to roundoff\n   error when working with doubles.\n    */\n  public void setArea(double area) {\n    radius = Math.sqrt(area / Math.PI);\n  }\n}\n\n{{ output }}\nshape3.beaker.Circle\n{{ /output }}\n\npackage shape3.beaker;\n/** Represents a simplistic Rectangle. Also see the Square subclass.\n p\n From a href=\"http://courses.coreservlets.com/Course-Materials/\"the\n coreservlets.com tutorials on JSF 2, PrimeFaces, Ajax, jQuery, GWT, Android,\n Spring, Hibernate, JPA, RESTful Web Services, Hadoop, \n servlets, JSP, and Java 7 and Java 8 programming/a.\n */\npublic class Rectangle implements Shape {\n  private double width, height;\n\n  public Rectangle(double width, double height) {\n    this.width = width;\n    this.height = height;\n  }\n\n  public double getWidth() {\n    return(width);\n  }\n\n  public void setWidth(double width) {\n    this.width = width;\n  }\n\n  public double getHeight() {\n    return(height);\n  }\n\n  public void setHeight(double height) {\n    this.height = height;\n  }\n\n  @Override\n  public double getArea() {\n    return(width * height);\n  }\n}\n\n{{ output }}\nshape3.beaker.Rectangle\n{{ /output }}\n\npackage shape3.beaker;\n/** Tests using mixed Shape types and the static sumAreas method.\n p\n From a href=\"http://courses.coreservlets.com/Course-Materials/\"the\n coreservlets.com tutorials on JSF 2, PrimeFaces, Ajax, jQuery, GWT, Android,\n Spring, Hibernate, JPA, RESTful Web Services, Hadoop, \n servlets, JSP, and Java 7 and Java 8 programming/a.\n */\n\npublic class ShapeTest {\n  public static void main(String[] args) {\n    Shape[] shapes = { new Circle(10),            // Area is about 314.159\n                       new Rectangle(5, 10)};          // Area is 50\n    System.out.println(\"Sum of areas: \" +\n                       Shape.sumAreas(shapes));   // Area is about 464.159\n  }\n}\n\n{{ output }}\nshape3.beaker.ShapeTest\n{{ /output }}\n\npackage enums1.beaker;\n\npublic class DayTest {\n    \npublic enum Day {\n  SUNDAY, MONDAY, TUESDAY, WEDNESDAY,\n  THURSDAY, FRIDAY, SATURDAY;\n}\n    public static boolean isWeekend(Day d) {\n        return(d == Day.SATURDAY || d == Day.SUNDAY);\n    }\n    public static void main(String[] args) {\n        System.out.println(\"Monday is weekend? \" + \n                           isWeekend(Day.MONDAY));\n        System.out.println(\"Saturday is weekend? \" + \n                           isWeekend(Day.SATURDAY));\n    }\n}\n\n{{ output }}\nenums1.beaker.DayTest\n{{ /output }}\n\npackage enums1.beaker;\n\npublic class DayTest {\n    \npublic enum Day {\n  // typical usage\n  SUNDAY(\"Sun\"), MONDAY(\"Mon\"), TUESDAY(\"Tues\"), \n  WEDNESDAY(\"Wed\"), THURSDAY(\"Thurs\"), \n  FRIDAY(\"Fri\"), SATURDAY(\"Sat\");\n  \n  private String abbreviation;\n  \n  private Day(String abbreviation) {\n    this.abbreviation = abbreviation;\n  }\n  \n  public String getAbbreviation() {\n    return(abbreviation);\n  }\n\n  public boolean isWeekend() {\n    return(this == SATURDAY || this == SUNDAY);\n  }\n  \n  public boolean isWeekday() {\n    return(!isWeekend());\n  }\n}\n   \n  public static void main(String[] args) {\n    Day day1 = Day.MONDAY;\n    System.out.println(day1);  // toString is automatic with enums\n    System.out.println(day1.getAbbreviation() + \n                       \" is weekend? \" + \n                       day1.isWeekend());\n    Day day2 = Day.SATURDAY;\n    System.out.println(day2.getAbbreviation() + \n                       \" is weekend? \" + \n                       day2.isWeekend());\n  }\n}\n\n{{ output }}\nenums1.beaker.DayTest\n{{ /output }}\n\nFinal keyword\n\n Static keyword\n\nAdvanced Concepts\n\n Design patterns\n\nTesting \n\nreference\n\n ?-driven development\n\nConclusion\n\n References\n\nTables\n\n External \n\nsnippet tutorials\nsnippet tutorials\nbaeldong: in-depth explanations\ngeeks-for-geeks: all questions answered\n\njava collections\ncollections: maps\n\ngoogle guava\n",
        "tags": [
            "jvm",
            "tag2",
            "tag3"
        ]
    },
    {
        "uri": "/posts/blog_prototype-creating_frontend",
        "title": "Prototyping an Interactive Frontend with Vue",
        "content": " \n\nAssumes you are comfortable with HTML, CSS, JS.  This will cover creating SPAs with webpack and Vue basics.  This will not cover mobile or advanced Vue.  Improvements will make frontend development a more imperative programming approach as compared to the typical declarative methods found in more basic work.\n\nIntroduction\n\nOnce you understand the basics of browser languages, such as HTML, CSS, and JS, then you quickly desire to have more interactive elements.  The obvious evolution is jQuery, as you can directly perform imperative programming to manipulate elements.  That was a powerful web technology for about a decade, and it is still used today.  But, frontend programmers quickly learned that jQuery code became extremely crowded, untestable, and overly-complex.  There were limits to what could be practically built with jQuery.  The upper limit was Single Page Applications (SPAs).\n\nSPAs allow for much more dynamic and intuitive interfaces for users.  However, to build and maintain them, more powerful technologies needed to perform scoped logic on modular components.  The first two frameworks to support this were Angular and React.  Vue came slightly later and was able to capitalize on some of the mistakes learned from the first two.  This allowed for a powerful system and fast workflow.\n\nThis post will explain how to prototype dynamic user interfaces as well as provide an understanding of more advanced technologies used by frontend programmers. \n\n Webpack and Modular Programming\n\nref: basic concepts\nref: modules\nref: getting started\n\nWebpack builds a dependency graph and uses the graph to generate an optimized bundle where scripts will be executed in the correct order.  In a more opinionated manner, it bundles javascript applications that are built using a modular design.  Modular programming is used so that verification, debugging, and testing can be performed as an independent and isolated unit.  They can then be added to other modules using a simple ES2015 import or CommonJs require statement.  \n\nThere are a variety of different flavors of JS used for frontend development, including Coffescript, TypeScript and ESNext (Babel).  These can be compiled into JS, then used in browsers.  Webpack supports modules written in a variety of languages and preprocessors, via loaders. Loaders describe to webpack how to process non-JavaScript modules and include these dependencies into your bundles. \n\nThere are a few concepts to know about how webpack works\n\nEntry - module to begin dependency graph (default: ./src/index.js)\nOutput - where to emit bundles (default: ./dist/main.js)\nLoaders - default only JavaScript and JSON files. allow webpack to process, convert other files into valid modules\nPlugins - wider range of tasks like bundle optimization, asset management and injection of environment variables\nMode - set to: development, production or none; enables built-in optimizations (default: production)\nBrowser Compatibility - supports all browsers that are ES5-compliant \n\nSimple usage \n\ni. Install\n\nstart project\nnpm init\nfor development only\nnpm install webpack --save-dev\ninstead of using file:/// url\nnpm install webpack-dev-server --save-dev\n\nii. Configure\n\nUsed like: webpack entrypoint outputfile\n\n//package.json\n\"scripts\":{\n\t\"build\": \"webpack-dev-server --entry ./src/js/app.js --output-filename ./dist/bundle.js\"\n\t\"build-prod\": \"webpack /src/js/app.js dist/bundle.js -p\"\t#minify for production\n}\n\niii. Implement\n\nWhat dependencies are determined by these only es6 syntax.\n\n//app.js\nimport {name} from './domloader.js'\n\n//domloader.js\nexport var name = function\n\n//index.html\nscript src=\"dist/bundle.js\"\n\nSimple configuration\n\nref: configuration\n\n//package.json\n\"scripts\": {\n  \"build\": \"webpack --config prod.config.js\"\n}\n\n//webpack.config.js\nconst path = require('path');\n\nmodule.exports = {\n  entry: './src/index.js',\n  output: {\n    filename: 'main.js',\n    path: path.resolve(__dirname, 'dist')\n  }\n};\n\n Development\n\nref: plugins\n\nPlugins can support your workflow.  These are three useful plugins:\n\nHtmlWebpackPlugin - generates new names in output\nclean-webpack-plugin - clean /dist folder before each output\n\nAutomatically update webpage\nnpm start\n\n//package.json\n  {\n    \"name\": \"development\",\n    \"version\": \"1.0.0\",\n    \"description\": \"\",\n    \"private\": true,\n    \"scripts\": {\n      \"test\": \"echo \\\"Error: no test specified\\\" && exit 1\",\n      \"watch\": \"webpack --watch\",\n      \"start\": \"webpack-dev-server --open\",\n      \"build\": \"webpack\"\n    },\n    \"keywords\": [],\n    \"author\": \"\",\n    \"license\": \"ISC\",\n    \"devDependencies\": {\n\n//webpack.config.js\n  const path = require('path');\n  const HtmlWebpackPlugin = require('html-webpack-plugin');\n  const { CleanWebpackPlugin } = require('clean-webpack-plugin');\n\n  module.exports = {\n    mode: 'development',\n    entry: {\n      app: './src/index.js',\n      print: './src/print.js'\n    },\n    devtool: 'inline-source-map',\n    devServer: {\n      contentBase: './dist'\n    },\n    plugins: [\n      // new CleanWebpackPlugin(['dist/*']) for < v2 versions of CleanWebpackPlugin\n      new CleanWebpackPlugin(),\n      new HtmlWebpackPlugin({\n        title: 'Development'\n      })\n    ],\n    output: {\n      filename: '[name].bundle.js',\n      path: path.resolve(__dirname, 'dist')\n    }\n  };\n\nAdvanced Topics\n\ncode splitting and bundle analysis\nenv variables\nprogressive web apps\n\n Vue Ecosystem\n\nTooling\n\nVue CLI - interactive project scaffolding with zero config rapid prototyping, a runtime dependency (@vue/cli-service) and a full graphical user interface to create and manage Vue.js projects\n  vue-cli-service - built on top of webpack that loads other plugins\n  @vue/cli-plugin- (for built-in plugins)\n  vue-cli-plugin- (for community plugins)\nVue (Webpack) Loader - allows you to author Vue components in a format called Single-File Components (SFCs)\nVue (browser) dev-tools Extension - for in-browser development\n\nLibraries\n\nTesting: Vue-Test-Utils\nHTTP Client: Axios - requests for consuming API\nRouter - official router support\nState Management: Vuex - an architecture for Vue applications and allows simple management of the application state.\nPre-Render, Production: NuxtJs - opinionated for spa\n\nComponent Search\n\nBit\ncurated Vue\nVue components\n\nDev Env\n\nStorybook - build UIs like legos\nOverVue - prototype-based dev\n\nref: awesome Vue\n\nVue CLI Scaffolding\n\nref: blog post\nref: guide docs\n\nProjects created by Vue CLI are pre-configured with most of the common development needs working out of the box, including Vue Loader.\n\nsingle component\nnpm install -g @vue/cli-service-global\nvue serve\n(browser)localhost:8080\n\nproject\nnpm install -g @vue/cli\nvue --version\nvue create my-project\nnpm run serve\n(browser)localhost:8080\nor with ui for dependency management\nvue ui\nor directly access the binary\nnpx vue-cli-service serve\n\nProject Structure\n\nnode_modules folder contains the packages that the app and development tools require.\npublic folder contains static project assets, which will not be included in the bundling process.\nsrc folder contains the Vue.js application with all resources.\n  assets folder is used for static resources required by the app, which will be included in the bundling process.\n  components folder is used for the application's components.\n  views folder is used for components which will be displayed using the URL routing feature.\n    App.vue is the root component.\n  main.js is the JavaScript file that creates the Vue instance object.\n  router.js is used to configure the Vue router.\n  store.js is used to configure the data store created with Vuex.\n.gitignore contains a list of files and folders that are excluded from the Git version control.\nbabel.config.js contains the configuration settings for the Babel compiler.\npackage.json contains a list of the packages required for Vue.js development as well as the commands used for the development tools.\npackage-lock.json contains a complete list of the packages required by the project and their dependencies.\nREADME.md contains general information about the project.\n\ninstall plugin\nvue add bootstrap-vue\n\nsrc/plugins/new_plugin\n\nbuild production bundle of: app, library, or component\nnpm run build --modern --target app\n\ndist folder created and two version with the browser-appropriate version selected automatically\n\nanalyze the build\nnpm run inspect\n\nTODO: Guide  Development\n\nVue Basics\n\nVue.js allows you to simply bind your data models to the representation layer. It also allows you to easily reuse components throughout the application.\n\n Useful Frontend Terms\n\nDeclarative Views: These are the Views that provide a way of direct data binding between plain JavaScript data models and the representation.\nDirectives: These are special HTML elements attributes prefixed with v- in Vue.js that allow data binding in different ways.  They apply special reactive behavior to the rendered DOM.\nReactivity: In the Web, this is actually the immediate propagation of any changes of data to the View layer.\n\nVue Foundations\n\ndiv id=\"app\"\n  {{ message }}\n/div\n\nvar app = new Vue({\n  el: 'app',\n  data: {\n    message: 'Hello Vue!'\n  }\n})\n\nDirectives\n\nvue directive syntax: \ndiv v-directive:argument of [dynamic argument].<eventmodifier or keymodifier=\" js expression | filter \"\n\ndata output\n {{}}\n\tdiv{{ interpolated_data }}/div\n v-bind div v-bind:id=\"dynamicId\"/div or ':id'\n    :[attribName / null]=\"var\"\n    :id=\"elemId\"\n    :disabled=\"null\"\n    :href=\"url\"\n v-once\n v-html\n\tpUsing v-html directive: span v-html=\"rawHtml\"/span/p\ndata input\n v-model\nconditionals\n v-if\n v-else-if\n v-else\n v-show\n v-for=\"(item, index) in items\" \n   v-for=\"(value, name, index) in object\"\n   v-for=\"todo in todos\" v-if=\"!todo.isComplete\"\nevent listener\n v-on or '@click'\n    :[eventName] \n    :keyup.enter\n    :keyup.page-down\n    :click\n    :click=\"say('what')\"\n    :click.once \n    :hover\n    :focus\n    :submit\nstyle\n v-bind:class=\"{ active: isActive }\"/div\n v-bind:style=\"[base, { color: activeColor, fontSize: fontSize + 'px' }]\"/div\n\n Data\n\ninstance properties (prefixed by $) are different from user-defined (var data={} ) data\n\nImplementation designs\n\nAll js in HTML\nscript\nvar vm = new Vue({\n  el: 'example',\n  data: {},\n  props: ['item'],\n  methods: {\n    name: function(){\n      return this.msg\n    },\n  computed:\n  hooks:created, mounted, updated, destroyed: function(){} \n}) \n/script\n\nSplit js into a globally-registered component\ndiv id='timer'\nTimer title='my timer'/Timer\n/div\n\nVue.component('Timer',{\n\ttemplate: 'div.../div',\n\tprops: ['title'],\t\t\t//data passed to and maintained by instance\n\tdata: function () {\t\t\t//data must be a function to maintain indep data copy\n\t\treturn {count: 0}\n\t},\n\tmethods:\n})\n\nnew Vue({\n  el: \"#timer\",\n});\n\nUse local registration of sub-component\n//ComponentA.vue\n\n//ComponentB.vue\nimport ComponentA from './ComponentA'\nexport default {\n  components: {\n    ComponentA\n  }\n}\n\n//main.js\nimport Vue from 'vue'\nimport upperFirst from 'lodash/upperFirst'\n\n//index.html\n\nSingle-file component separation-of-layers\n//comp.vue\ntemplate\n  divThis will be pre-compiled/div\n/template\nscript src=\"./my-component.js\"/script\nstyle src=\"./my-component.css\"/style\n\nTypical single-file component\n\ntodo app\n\nThis is advanced javascript and must understand\n\nnpm intro \nnpm, up to uninstalling global packages\nlearn es2015\n\nindex.html\ndiv id=\"app\"/div\n\n//index.js\nimport Vue from 'vue'\nimport App from './App'\n\nVue.config.productionTip = false\n\n/* eslint-disable no-new */\nnew Vue({\n  el: 'app',\n  template: 'App/',\n  components: { App }\n})\n\n//App.vue\ntemplate\n\tdiv id=\"app\"\n\t\th1My Todo App!/h1\n\t\tTodoList/\n\t/div\n</template\nscript\nimport TodoList from './components/TodoList.vue'\n\nexport default {\n\tcomponents: {\n\t\tTodoList\n\t}\n}\n/script\nstyle/style\n\nUnit-testing individual components\n\nref: unit tests\n\n//Component.vue\ntemplate\n  p{{ msg }}/p\n/template\n\nscript\n  export default {\n    props: ['msg']\n  }\n/script\n\n//test.js\nimport Vue from 'vue'\nimport MyComponent from './MyComponent.vue'\n\n// helper function that mounts and returns the rendered text\nfunction getRenderedText (Component, propsData) {\n  const Constructor = Vue.extend(Component)\n  const vm = new Constructor({ propsData: propsData }).$mount()\n  return vm.$el.textContent\n}\n\ndescribe('MyComponent', () = {\n  it('renders correctly with different props', () = {\n    expect(getRenderedText(MyComponent, {\n      msg: 'Hello'\n    })).toBe('Hello')\n\n    expect(getRenderedText(MyComponent, {\n      msg: 'Bye'\n    })).toBe('Bye')\n  })\n})\n\nTODO\nemit\nclient-side storage\nstorage with indexdDb\ndebugging in vscode\n\nEND",
        "tags": [
            "vue",
            "JavaScript",
            "tag3"
        ]
    },
    {
        "uri": "/posts/blog_test-hugo_blog",
        "title": "Formatting for Jupyter (.ipynb) Notebooks",
        "content": "\n\nThis is a test post for formatting Jupyter Notebooks for Hugo.  This workflow makes use of the code at repository nb2hugo, as well as the beakerx jupyter kernel.\n\nThis is will test blog is a complicated workflow.  Begin by running the newest version of JupyterLab.  Run through the basic markdown sections.  Next, try working with the R kernel by using rpy2 library.  Run these cells to ensure functionality.\n\nThen close the notebook and re-open it in Beakerx with the beakerx Groovy kernel.  This will ensure that the beakerx object is available for autotranslation.  Try the autotranslated cells.\n\nFinally, change the kernel back to Python and finish running the notebook.\n\nBasic Section Headers\n\n Subsection header\n\nCupiditate voluptas sunt velit. Accusantium aliquid expedita excepturi quis laborum autem. Quas occaecati et atque est repellat dolores. Laudantium in molestiae consequatur voluptate ipsa. Nulla quia non qui sed. Voluptatem et enim nesciunt sunt pariatur. Libero eius excepturi voluptatibus reprehenderit. Facere enim neque dolorem sed ullam non. Dolor sit molestias repellendus. \n\nExample of one output\n\nprint('goodbye!')\n\n{{ output }}\ngoodbye!\n{{ /output }}\n\nExample of multiple outputs\n\nprint('hello')\nprint('world')\nprint('goodbye!')\n\n{{ output }}\nhello\nworld\ngoodbye!\n{{ /output }}\n\nSubsection header\n\nCupiditate voluptas sunt velit. Accusantium aliquid expedita excepturi quis laborum autem. Quas occaecati et atque est repellat dolores. Laudantium in molestiae consequatur voluptate ipsa. Nulla quia non qui sed. Voluptatem et enim nesciunt sunt pariatur. Libero eius excepturi voluptatibus reprehenderit. Facere enim neque dolorem sed ullam non. Dolor sit molestias repellendus.\n\nThis is a footnote as performed with text:``, which follows as.\n\nThe bottom of the page can be marked with the following:\n\n: the footnote text.\n\nScroll to the bottom to see the result.\n\n Formatting Requirements\n\nMarkdown section\n\nThe post must conform to the following:\n\nnotebook-filenamemustbe_lowercase.ipynb\napply metadata formatting\n Formatting for Jupyter (.ipynb) Notebooks\n\nDate: 2019-05-08  \nAuthor: Jason Beach  \nCategories: Blog, Category  \nTags: jupyter, tag \n\n!--eofm--\n\nnotebook-namemustbe_lowercase.ipynb\n#Title As Above (.ipynb) or part of metadata (.md)\n## All Second Sections (to ensure proper smartToc)\n### All third sections\nuse opening paragraph beneath metadata\nensure either output, or markdown cell, between code cells\nreference other posts with absolute url: my post\nadd external references to documentation ref\n\nLatex section\n\nThis is inline latex \\\\(x\\_i^2\\\\)\n\nThe display mode notation \\\\[c = \\\\sqrt{a^2 + b^2}\\\\] becomes:\n\\\\[c = \\\\sqrt{a^2 + b^2}\\\\]\n\nThis is a latex code block using %%latex cell magic\n\n%%latex\n\\begin{aligned}\n\\nabla \\times \\vec{\\mathbf{B}} -\\, \\frac1c\\, \\frac{\\partial\\vec{\\mathbf{E}}}{\\partial t} & = \\frac{4\\pi}{c}\\vec{\\mathbf{j}} \\\\\n\\nabla \\cdot \\vec{\\mathbf{E}} & = 4 \\pi \\rho \\\\\n\\nabla \\times \\vec{\\mathbf{E}}\\, +\\, \\frac1c\\, \\frac{\\partial\\vec{\\mathbf{B}}}{\\partial t} & = \\vec{\\mathbf{0}} \\\\\n\\nabla \\cdot \\vec{\\mathbf{B}} & = 0\n\\end{aligned}\n\n Graphic section\n\nimport matplotlib.pyplot as plt\nimport numpy as np\n\na=[x for x in range(10)]\nb=np.square(a)\nplt.plot(a,b)\nplt.show()\n\nDataframes and tables\n\nimport pandas as pd\n\nd = {'col1': [1,2,3,4,5,6,7], 'col2': [1,2,3,4,5,6,7]}\ndf = pd.DataFrame(data=d)\ndf.head()\n\ndiv\nstyle scoped\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n/style\ntable border=\"1\" class=\"dataframe\"\n  thead\n    tr style=\"text-align: right;\"\n      th/th\n      thcol1/th\n      thcol2/th\n    /tr\n  /thead\n  tbody\n    tr\n      th0/th\n      td1/td\n      td1/td\n    /tr\n    tr\n      th1/th\n      td2/td\n      td2/td\n    /tr\n    tr\n      th2/th\n      td3/td\n      td3/td\n    /tr\n    tr\n      th3/th\n      td4/td\n      td4/td\n    /tr\n    tr\n      th4/th\n      td5/td\n      td5/td\n    /tr\n  /tbody\n/table\n/div\n\n Additional Language Kernels\n\nPython\n\nThe code above is written in python.  Now, lets try R statistical language.\n\n R language\n\n%load_ext rpy2.ipython\n\n{{ output }}\nThe rpy2.ipython extension is already loaded. To reload it, use:\n  %reload_ext rpy2.ipython\n{{ /output }}\n\n%R require(ggplot2)\n\n{{ output }}\narray([1], dtype=int32)\n{{ /output }}\n\nimport pandas as pd\ndf = pd.DataFrame({\n        'Letter': ['a', 'a', 'a', 'b', 'b', 'b', 'c', 'c', 'c'],\n        'X': [4, 3, 5, 2, 1, 7, 7, 5, 9],\n        'Y': [0, 4, 3, 6, 7, 10, 11, 9, 13],\n        'Z': [1, 2, 3, 1, 2, 3, 1, 2, 3]\n    })\n\n%%R -i df\nhead(df, 3)\n\n{{ output }}\n  Letter X Y Z\n0      a 4 0 1\n1      a 3 4 2\n2      a 5 3 3\n{{ /output }}\n\n%%R -i df -w 400 -h 300\noptions(repr.plot.width = 1, repr.plot.height = 0.75)\nthm <- theme(\n    #panel.background = element_rect(fill = \"transparent\"), # bg of the panel\n    plot.background = element_rect(fill = \"transparent\", color = NA), # bg of the plot\n    #panel.grid.major = element_blank(), # get rid of major grid\n    #panel.grid.minor = element_blank(), # get rid of minor grid\n    legend.background = element_rect(fill = \"transparent\"), # get rid of legend bg\n    legend.box.background = element_rect(fill = \"transparent\") # get rid of legend panel bg\n  )\np <- ggplot(data = df) + geom_point(aes(x = X, y= Y, color = Letter, size = Z))\np + thm\n\nGroovy\n\nNow, the kernel is changed to Groovy to introduce autotranslation.  Autotranslation is only available in beakerx with the Groovy kernel.\n\nbeakerx.foo = \"a groovy value\"\n\n{{ output }}\na groovy value\n{{ /output }}\n\n Javascript\n\nNow, we use javascript.\n\n%%javascript\nbeakerx.bar = [23, 48, 7, beakerx.foo];\nbeakerx.foo\n\nBack to python\n\n%%python\nfrom beakerx import beakerx\nbeakerx.bar\n\n{{ output }}\n[23, 48, 7, 'a groovy value']\n{{ /output }}\n\nHTML\n\nThe below is written in HTML and is used for rendering within the notebook.\n\n%%html\nstyle\n.node {\n    background-color: lightblue;\n}\n/style\ndiv class=\"node\" Hello World /div\n\nstyle\n.node {\n    background-color: lightblue;\n}\n/style\n\ndiv class=\"node\" Hello World /div\n\nUse the script tag to write safe, non-rendering HTML that still allows for correct syntax highlighting.\n\n%%html\nscript type=\"application/text\" \nstyle\n.node {\n    background-color: lightblue;\n}\n/style\ndiv class=\"node\" Hello World /div\n/script\n\nscript type=\"application/text\" \nstyle\n.node {\n    background-color: lightblue;\n}\n/style\ndiv class=\"node\" Hello World /div\n/script\n\nWhen you use nbconvert to change to markdown, you will receive the following error.  However, the output will be correct.\n\n%%output\nwriter.convert(notebook, site_dir, section)                                              \n/usr/local/lib/python3.7/site-packages/nbconvert-5.5.0-py3.7.egg/nbconvert/filters/datatypefilter.\npy:41: UserWarning: Your element with mimetype(s) dict_keys(['application/javascript']) is not able to be represented.\n  mimetypes=output.keys())\nCreated 'posts/blogtest-hugoblog.md'\n\n Back to python\n\nNow, manually change the kernel back to python.\n\nprint('back to python')\n\n{{ output }}\nback to python\n{{ /output }}\n\nFinal Section\n\nCupiditate voluptas sunt velit. Accusantium aliquid expedita excepturi quis laborum autem. Quas occaecati et atque est repellat dolores. Laudantium in molestiae consequatur voluptate ipsa. Nulla quia non qui sed. Voluptatem et enim nesciunt sunt pariatur. Libero eius excepturi voluptatibus reprehenderit. Facere enim neque dolorem sed ullam non. Dolor sit molestias repellendus. \n\n References\n\n: the reference goes here.\n",
        "tags": [
            "jupyter",
            "tag"
        ]
    },
    {
        "uri": "/posts/blog_test-my_first_post",
        "title": "Formatting a Markdown Post",
        "content": "\n\nCupiditate voluptas sunt velit. Accusantium aliquid expedita excepturi quis laborum autem. Quas occaecati et atque est repellat dolores. Laudantium in molestiae consequatur voluptate ipsa.\n\nNulla quia non qui sed. Voluptatem et enim nesciunt sunt pariatur. Libero eius excepturi voluptatibus reprehenderit. Facere enim neque dolorem sed ullam non. Dolor sit molestias repellendus.\n\nAwesome-1\n\nFacilis maiores doloribus similique sint quaerat reiciendis quia. Autem nemo voluptas rerum. Eos odio aut omnis. Adipisci voluptas nihil autem recusandae. \n\nThis is a footnote.\n\nIn addition, we have task lists: \n\n[ ] a task list item\n[ ] list syntax required\n[ ] incomplete\n[x] completed\n\nOne stormy night.\n\nRem aut rerum provident. Minima dolor tempore veniam veniam repellendus nihil.\n\nCat\n: Fluffy animal everyone likes\n\nInternet\n: Vector of transmission for pictures of cats\n\nAlias explicabo est et. Voluptas neque inventore beatae sequi dolor et autem non. Temporibus facilis molestiae sint excepturi a et quia. Assumenda libero qui et rerum quia nam aliquam dolores. Et eos placeat assumenda.\n\nEligendi sunt aut illum. Odio voluptate commodi non temporibus vel veniam. Voluptatem magnam eum eum.\n\n Awesome-2\n\nFacilis maiores doloribus similique sint quaerat reiciendis quia. Autem nemo voluptas rerum. Eos odio aut omnis. Adipisci voluptas nihil autem recusandae. Rem aut rerum provident. Minima dolor tempore veniam veniam repellendus nihil.\n\nAlias explicabo est et. Voluptas neque inventore beatae sequi dolor et autem non. Temporibus facilis molestiae sint excepturi a et quia. Assumenda libero qui et rerum quia nam aliquam dolores. Et eos placeat assumenda.\n\nEligendi sunt aut illum. Odio voluptate commodi non temporibus vel veniam. Voluptatem magnam eum eum.\n\nSub Awesome-1\n\nFacilis maiores doloribus similique sint quaerat reiciendis quia. Autem nemo voluptas rerum. Eos odio aut omnis. Adipisci voluptas nihil autem recusandae. Rem aut rerum provident. Minima dolor tempore veniam veniam repellendus nihil.\n\nAlias explicabo est et. Voluptas neque inventore beatae sequi dolor et autem non. Temporibus facilis molestiae sint excepturi a et quia. Assumenda libero qui et rerum quia nam aliquam dolores. Et eos placeat assumenda.\n\nEligendi sunt aut illum. Odio voluptate commodi non temporibus vel veniam. Voluptatem magnam eum eum.\n\n Sub Awesome-2\n\nFacilis maiores doloribus similique sint quaerat reiciendis quia. Autem nemo voluptas rerum. Eos odio aut omnis. Adipisci voluptas nihil autem recusandae. Rem aut rerum provident. Minima dolor tempore veniam veniam repellendus nihil.\n\nAlias explicabo est et. Voluptas neque inventore beatae sequi dolor et autem non. Temporibus facilis molestiae sint excepturi a et quia. Assumenda libero qui et rerum quia nam aliquam dolores. Et eos placeat assumenda.\n\nEligendi sunt aut illum. Odio voluptate commodi non temporibus vel veniam. Voluptatem magnam eum eum.\n\nSub Awesome-3\n\nFacilis maiores doloribus similique sint quaerat reiciendis quia. Autem nemo voluptas rerum. Eos odio aut omnis. Adipisci voluptas nihil autem recusandae. Rem aut rerum provident. Minima dolor tempore veniam veniam repellendus nihil.\n\nAlias explicabo est et. Voluptas neque inventore beatae sequi dolor et autem non. Temporibus facilis molestiae sint excepturi a et quia. Assumenda libero qui et rerum quia nam aliquam dolores. Et eos placeat assumenda.\n\nEligendi sunt aut illum. Odio voluptate commodi non temporibus vel veniam. Voluptatem magnam eum eum.\n\n Conclusion\n\nFacilis maiores doloribus similique sint quaerat reiciendis quia. Autem nemo voluptas rerum. Eos odio aut omnis. Adipisci voluptas nihil autem recusandae. Rem aut rerum provident. Minima dolor tempore veniam veniam repellendus nihil.\n\nAlias explicabo est et. Voluptas neque inventore beatae sequi dolor et autem non. Temporibus facilis molestiae sint excepturi a et quia. Assumenda libero qui et rerum quia nam aliquam dolores. Et eos placeat assumenda.\n\nEligendi sunt aut illum. Odio voluptate commodi non temporibus vel veniam. Voluptatem magnam eum eum.\n\n: the footnote text.\n",
        "tags": [
            "markdown",
            "tag"
        ]
    },
    {
        "uri": "/posts/blog-hugo_site_process",
        "title": "Communication Workflows with Hugo, Jupyter, and Friends",
        "content": "\n\nStatic Site Generators are quite popular replacements for traditional server-based methods of delivering HTML.  One of the most popular is Hugo because of its compilation speed.  Combining Hugo with Jupyter notebooks, and other tools, can provide for a speedy workflow for pushing your ideas to the web, books (online or pdf), and more.  This post will discuss why you may want to do this and provides tools for doing it.\n\nCreating and Sharing Ideas\n\nCreating and publishing content is an investment.  Even poorly-created content still takes time to put text to file and file to web.  I've seen many people get started with blogging only to quit after getting the site running.  They refine the site styling to a remarkable degree, then the posts end after two weeks.  \n\nWhich begs the question: why blog?  A way to to have an online presence or to build a brand?  Rubbish.  No one will go to your site because you're nobody.  And why should they - you don't care about them, either.  Funny enough, people go to Paul Graham's blog, and I don't think he spent 10 minutes on his CSS.\n\nAnother perspective is that you want to share ideas, with yourself, and, sometimes, others.  The content I create is a knowledge base.  I've learned a great deal of things.  I want to access, reference, and update those things as I refine skills and knowledge.  If someone asks me a question and I'm feeling selfish with my time, then I can point them to a post: it is researched, organized, and documented at times that I was interested in a topic.  I can't remember everything all of the time!\n\nPersonally, I'm easily distracted by new ideas.  Creating content adds a little more time to the current work I'm doing, but it helps drive new ideas toward longer-term interests and goals.  The ideas are incorporated into a previous world view that is then updated.  Strategically, I can look over this past work and use it in future projects.  This is not so much to make things easier, in the future, as it is to see how perspectives change with the addition of new information.\n\nBetter yet - prove to yourself that you understand some material.  You don't know something until you can teach to others, or teach it, simply... to a child... something like that.  This post is about creating this new habit, and sticking to it by not wasting your time with the boring stuff.\n\n An Effective Workflow\n\nProcess overview\n\nI've tried multiple workflows and the following is by far the fastest and most effective.  Two key components are Jupyter nobooks and Hugo Static Site Generator (SSG).  The key components are separating your content (Jupyter) from the delivery (Hugo), and ensuring you use simple scripts for the plumbing in your workflow.  \nDocker - Jupyter - Markdown - Hugo - SSG / Book (online) / Book (pdf) - github pages\n\nJupyter allows you to succinctly place all of your content, together, even if it doesn't concern programming.  That way you can easily move to some new method of dissemination if SSG doesn't serve your purpose.  If you make programming a topic in your content, you are really helping yourself.  The code and output are maintained, together, and can easily be update, in the future.\n\nUsing simple scripts (bash or python files) to automate your work ensures that plumbing can be created easily and quickly modified when you improve your process or make major changes to it.  This might seem like more overhead, and it is, in the short-term.  But, having the ability to direct your content to, and reuse it in, different sources, such as blog post, book, or a journal format, is incredibly powerful.\n\n Detailed process\n\nTo go into more detail, I start with a docker image with Jupyter installed.  The docker container shares volumes with the local space for saving .ipynb files.  These are maintained in a github repo, so all content is secure and easily reproducible.  The only concern is where to keep your accompanying data, which is mostly dependent on size.  An AWS S3 bucket is usually a safe bet.\n\nOnce the content is ready, it can be prepared for dissemination using a simple script.  Jupyter notebook files (.ipynb) are json.  These should be converted to markdown (.md) and placed, with dependencies (images, media, etc.), into the appropriate Hugo directory structure.  A final review can be performed by running Hugo locally.  Changes can be made to the markdown files, the Hugo public directory (converted HTML SSG files), is commited and pushed to github repo for publication on github pages.  All of this can be done in less than 30 seconds.\n\nThere are some similar, but less flexible, workflows.  If you are using RStudio and are only concerned with data science content using R or Python, then you can use blogdown.  This is a great workflow and really saves the user much time.  However, both RStudio and blogdown are opinionated and large.  If you want to change something, then you will either have to do it their way (if the option is present), or you will have to dig knee-deep into code (probably for several days) to modify things to how you want them.  This lack of control does not suite me.\n\nComplete process code\n\nFor docker images, I use one of the following:\n\nall spark notebook - all the data science goodies you expect\nbeakerx - strong multi-language and prototyping support, including JVM languages, python, and javascript\ncreate your notebook repo\n\\\\( git clone repo\n(~/.bash\\profile) export NOTEBOOK\\HOME=/Users/jason.beach/Desktop/Projects/IMTorgDemo-Notebooks \n\ncreate container and share volume\n\\\\) docker run -d -p 8887:8888 \\\n\t-v \\\\(NOTEBOOK\\HOME:/home/beakerx/PROJECTS\\PERSONAL \\\\\n\t-v \\\\)WORKHOME:/home/beakerx/PROJECTSWORK \\\n\t--name cntr_beakerx \\\n\tbeakerx/beakerx \n\nApply consistent formatting across notebooks.  Using a script to look for such formatting can be helpful.  The following are useful standards when running the nb2hugo script for converting a notebook to markdown.\n\nnotebook-namemustbe_lowercase.ipynb\nTitle As Above (.ipynb) or part of metadata (.md)\n## All Second Sections (to ensure proper smartToc)\n### All third sections\nuse opening paragraph beneath metadata\nensure either output, or markdown cell, between code cells\nreference other posts with absolute url: my post\nadd external references to documentation ref\nadd image references ``\n\nConvert the file to markdown and place files and dependencies into appropriate directory structure.\n\\\\( nb2hugo ./directory/to/file.ipynb   --site-dir ./Hugo\\_Site/ --section posts\n\nTake a quick look for final review.\n\\\\) hugo server -D\n\nThen commit and deploy to github pages.  Also, commit and push your notebook modifications to github repo.\n$ ./deploy.sh \"add new post\" \n\nThis is a simple process, once it is set-up.  The only difficulty is getting accustomed to the above formatting rules.\n\nJupyter for code and content\n\nJupyter notebooks can be real productivity enhancers because they bring code, output, and mathematical notation all under one JSON-based HTML renderer.  The notebook can be shared, as HTML, or converted to other formats.\n\nWhile docker is not necessary, running Jupyter from docker can make costly installation and configuration changes both automated and portable.  Two of the best images are:\n\nall-spark-notebook - all the data science goodies you expect\nbeakerx - strong multi-language and prototyping support, including JVM languages, python, and javascript\n\nThe kernels of these two images cover almost every language you might want to use; except NodeJs.  I've tried a few of different set-ups, but haven't found any that are consistently maintained.\n\nOnce you've completed some work in a notebook, you have a variety of different formats for which to convert it.  Converting it to markdown and diseminating files to Hugo is my chosen workflow, and the script nb2hugo performans quite well by making use of the Jupyter API.  I'm slowly improving it with post-processing.\n\n Hugo for static sites\n\nSSGs improved steadily over the last few years, and Hugo proclaims it is the fastest for compiling code.  The speed is quite impressive and allows users to see HTML updates while the underlying markdown is being modified, similar to how nodemon works, for Node developers.\n\nHugo is also relatively simple to learn and customize.  The basic tutorials are quite good.  Installing the system with code-block language coloring (pygments) is straightforward.\n\\\\( brew install hugo\n\\\\) pip3 install Pygments\n\\\\( pip3 install nb2hugo\n\nTypically, a new user will get started with a theme chosen from the Hugo Theme library.  The actual theme repo is cloned within the Hugo directory structure.\n\\\\) hugo new site quickstart\n\\\\( cd quickstart\n\\\\) git init\n\\\\( cd themes/\n\\\\) git clone --depth 1 https://github.com/carsonip/hugo-theme-minos\nhugo -t hugo-theme-minos\n\nThe final bit is to customize Hugo using the config.toml file.  This includes adding the url and other static site variables, the chosen theme and parameters associated with the theme, and static pages (like About or Tags).  Creating a new post from markdown, without Jupyter is simply: $ hugo new posts/my-first-post.md.\n\nHugo has some very powerful themes to choose from, including:\n\nacademic\ncoder portfolio\ntufte style\nbook style\n\nMathematical notation is supported through Katex.\n\nUseful Tools\n\nTo deploy Hugo, simply place the compiled public/ directory to a server.  You have many options; however, deploying your site simply by pushing commits to your code repo is one of the easiest - enter GithubPages.  The provided Hugo script is quite useful.  \n\nLater, you can create a custom domain name and point it at the account.github.io url, such as with Namecheap.\n\nLastly, you may want to consider distributing your content using other means, such as book pdf.  Pandoc appears to cover all needs for markdown transformations.  The writer, Thorsten Ball, appears to have good experience on this process, as well.\n\n Conclusion\n\nThere are many choices for distributing content to the web, but I find most are time-consuming in either overhead, process, or customization.  This is not the case with Jupyter and Hugo.  Overhead is only a few hours for set-up and getting accustomed to styling.  The process only takes a two commands and a localhost review.  Customization cannot be any easier because of the simplicity of the pipeline and scripts.  If fewer languages or less flexibility is acceptable, than RStudio and blogdown may be preferable, but this may be regretful, later.\n",
        "tags": [
            "knowledgebase",
            "markdown",
            "tag3"
        ]
    },
    {
        "uri": "/posts/blog-intro_latex",
        "title": "Introduction to LaTeX",
        "content": "\n\nLaTeX is the document preparation and typesetting system used for scientific publications.  LaTeX is based on the idea that 'it is better to leave document design to document designers', so the user can focus on the content. It requires a greater technical understanding than typical simple note-taking systems; however, because it is incredibly descriptive and produces aesthetically-appealing output, it is becoming more popular.  This post provides a reference to configuration and syntax.\n\nLaTeX Beginnings\n\nTex is the actual low-level language created by Donald Knuth in 1978.  Leslie Lamport created an alternative, high-level, macro file called lplain (l for Lamport), with a set of much-easier-to-use commands.  The latex script ran the macros, first, then compiled the Tex language and outputs to a PostScript file that another program converts to a document.  This evolved into the LaTeX program.   \n\nThe LaTeX site provides the open source software distribution that compiles your LaTeX markup.  Getting this set-up and using it can be quite involved and most workflows don't allow for such complexities.\n\nAlso, most users don't have to worry about becoming comfortable with the LaTeX markup.  There are many templates available, including:\nfree boilerplates\nfree templates\nsome commercial.  \n\nLarge journal publications provide their own templates for document preparation, such as IEEE.  However, some users may want to customize their own output.  An example document could include the following.\n\\begin{document}\n  \\begin{environment1}\n    \\begin{environment2}\n    \\end{environment2}\n  \\end{environment1}\n\\end{document}\n\nThere is an interesting post describing how to create a business card in LaTeX.  This is ridiculous!  For more graphic-intensive work there are much better options, such Photoshop or even PowerPoint.  For more information, look into latex tutorial.\n\n Typical Usage\n\nJupyter\n\nMore commonly, simple snippets or blocks of LaTeX are used within common markdown or HTML to display mathematical text or special symbols.  Pandoc can be used to convert simple markdown into other formats, including a PDF file with LaTeX.  \n\nJupyter notebook uses MathJax to render LaTeX inside html/markdown. Just put your LaTeX math inside \\\\(.\n\nThe inline notation \\\\)c = \\sqrt{a^2 + b^2}\\\\( becomes: \\\\)c = \\sqrt{a^2 + b^2}$\n\nThe display mode notation \\\\[c = \\\\sqrt{a^2 + b^2}\\\\] becomes:\n\n\\\\[c = \\\\sqrt{a^2 + b^2}\\\\]\n\nOr place it in an individual cell.\n\nfrom IPython.display import Math\nMath(r'F(k) = \\int_{-\\infty}^{\\infty} f(x) e^{2\\pi i k} dx')\n\n$\\displaystyle F(k) = \\int_{-\\infty}^{\\infty} f(x) e^{2\\pi i k} dx$\n\nYou can enter latex directly with the %%latex cell magic, within a Markdown cell:\n%%latex\n\\begin{aligned}\n\\nabla \\times \\vec{\\mathbf{B}} -\\, \\frac1c\\, \\frac{\\partial\\vec{\\mathbf{E}}}{\\partial t} & = \\frac{4\\pi}{c}\\vec{\\mathbf{j}} \\\\\n\\nabla \\cdot \\vec{\\mathbf{E}} & = 4 \\pi \\rho \\\\\n\\nabla \\times \\vec{\\mathbf{E}}\\, +\\, \\frac1c\\, \\frac{\\partial\\vec{\\mathbf{B}}}{\\partial t} & = \\vec{\\mathbf{0}} \\\\\n\\nabla \\cdot \\vec{\\mathbf{B}} & = 0\n\\end{aligned}\n\n%%latex\n\\begin{aligned}\n\\nabla \\times \\vec{\\mathbf{B}} -\\, \\frac1c\\, \\frac{\\partial\\vec{\\mathbf{E}}}{\\partial t} & = \\frac{4\\pi}{c}\\vec{\\mathbf{j}} \\\\\n\\nabla \\cdot \\vec{\\mathbf{E}} & = 4 \\pi \\rho \\\\\n\\nabla \\times \\vec{\\mathbf{E}}\\, +\\, \\frac1c\\, \\frac{\\partial\\vec{\\mathbf{B}}}{\\partial t} & = \\vec{\\mathbf{0}} \\\\\n\\nabla \\cdot \\vec{\\mathbf{B}} & = 0\n\\end{aligned}\n\n MathJax\n\nSuperscripts and Subscripts, use ^ and _. For example\n\nxi^2: \\\\(x\\i^2\\\\)\n\\log2 x: \\\\(\\\\log\\2 x\\\\)\n\nGroups, Superscripts, Subscripts, and other operations apply only to the next group. A group is either a single symbol, or any formula surrounded by curly braces {}. If you do 10^10, you will get a surprise: 1010\n\nBut 10^{10} gives what you probably wanted: \\\\(10^{10}\\\\). Use curly braces to delimit a formula to which a superscript or subscript applies: \nx^5^6 is an error\n{x^y}^z is \\\\({x^y}^z\\\\)\nx^{y^z} is \\\\(x^{y^z}\\\\) \n\nObserve the difference between xi^2 \\\\(x\\i^2\\\\) and x{i^2} \\\\(x\\{i^2}\\\\)\n\nParentheses and Ordinary symbols ()[] make parentheses and brackets \\\\((2+3)[4+4]\\\\) Use \\{ and \\} for curly braces \\\\(\\\\{\\\\}\\\\)\n\nThese do not scale with the formula in between, so if you write (\\frac{\\sqrt x}{y^3}) the parentheses will be too small: \\\\((\\\\frac{\\\\sqrt x}{y^3})\\\\)\n\nUsing \\left(\\right) will make the sizes adjust automatically to the formula they enclose: \\left(\\frac{\\sqrt x}{y^3}\\right) is \\\\(\\\\left(\\\\frac{\\\\sqrt x}{y^3}\\\\right)\\\\)\n\n\\left and \\right apply to all the following sorts of parentheses: \n( ) \\\\(()\\\\)\n[ ] \\\\([]\\\\)\n\\{  \\} \\\\(\\\\{\\\\}\\\\)\n| \\\\(||\\\\)\n\\vert \\\\(\\\\vert x\\\\vert\\\\)\n\\Vert \\\\(\\\\Vert x\\\\Vert\\\\)\n\\langle and \\rangle \\\\(\\\\langle x \\\\rangle\\\\)\n\\lceil and \\rceil \\\\(\\\\lceil x \\\\rceil\\\\)\n\\lfloor and \\rfloor \\\\(\\\\lfloor x \\\\rfloor\\\\)\n\\middle can be used to add additional dividers\n\nThere are also invisible parentheses, denoted by .: \\left.\\frac12\\right\\rbrace is \\\\(\\\\left.\\\\frac12\\\\right\\\\rbrace\\\\)\n\nIf manual size adjustments are required: \\Biggl(\\biggl(\\Bigl(\\bigl((x)\\bigr)\\Bigr)\\biggr)\\Biggr) gives \\\\(\\\\Biggl(\\\\biggl(\\\\Bigl(\\\\bigl((x)\\\\bigr)\\\\Bigr)\\\\biggr)\\\\Biggr)\\\\)\n\nSums and integrals \\sum and \\int; the subscript is the lower limit and the superscript is the upper limit, so for example \\sum1^n  \\\\(\\\\sum\\1^n\\\\). Don't forget {} if the limits are more than a single symbol. For example, \\sum{i=0}^\\infty i^2 is \\\\(\\\\sum\\{i=0}^\\\\infty i^2\\\\). Similarly, \\prod \\\\(\\\\prod\\\\), \\int \\\\(\\\\int\\\\), \\bigcup \\\\(\\\\bigcup\\\\), \\bigcap \\\\(\\\\bigcap\\\\), \\iint \\\\(\\\\iint\\\\), \\iiint \\\\(\\\\iiint\\\\), \\idotsint \\\\(\\\\idotsint\\\\)\n\nFractions There are three ways to make these. \\frac ab applies to the next two groups, and produces \\\\(\\\\frac ab\\\\); for more complicated numerators and denominators use {}: \\frac{a+1}{b+1} is \\\\(\\\\frac{a+1}{b+1}\\\\). If the numerator and denominator are complicated, you may prefer \\over, which splits up the group that it is in: {a+1\\over b+1} is \\\\({a+1\\\\over b+1}\\\\). Using \\cfrac{a}{b} command is useful for continued fractions \\\\(\\\\cfrac{a}{b}\\\\), more details for which are given in this sub-article.\n\nRadical signs use sqrt, which adjusts to the size of its argument: \\sqrt{x^3} \\\\(\\\\sqrt{x^3}\\\\); \\sqrt[3]{\\frac xy} \\\\(\\\\sqrt[3]{\\\\frac xy}\\\\). For complicated expressions, consider using {...}^{1/2} \\\\({...}^{1/2}\\\\) instead.\n\nSpecial functions, such as \"lim\", \"sin\", \"max\", \"ln\", and so on are normally set in roman font instead of italic font. Use \\lim \\\\(\\\\lim\\\\), \\sin \\\\(\\\\sin\\\\), etc. to make these: \\sin x \\\\(\\\\sin x\\\\), not sin x \\\\(sin x\\\\). Use subscripts to attach a notation to \\lim: \\lim{x\\to 0} \\\\(\\\\lim\\{x\\\\to 0}\\\\).\n\nThere are a very large number of special symbols and notations, too many to list here; see this shorter listing, or this exhaustive listing. Some of the most common include: \n\n\\lt \\gt \\le \\leq \\leqq \\leqslant \\\\(\\\\lt \\\\gt \\\\le \\\\leq \\\\leqq \\\\leqslant\\\\) \n\n\\ge \\geq \\geqq \\geqslant \\neq \\\\(\\\\ge \\\\geq \\\\geqq \\\\geqslant \\\\neq\\\\)\n    \nYou can use \\not to put a slash through almost anything: \\not\\lt \\\\(\\\\not\\\\lt\\\\), but it often looks bad.\n\n\\times \\div \\pm \\mp \\\\(\\\\times \\\\div \\\\pm \\\\mp\\\\)\n\n\\cup \\cap \\setminus \\subset \\subseteq \\subsetneq \\supset \\\\(\\\\cup \\\\cap \\\\setminus \\\\subset \\\\subseteq \\\\subsetneq \\\\supset\\\\) \n\n\\in \\notin \\emptyset \\varnothing \\\\(\\\\in \\\\notin \\\\emptyset \\\\varnothing\\\\)\n\n\\cdot is a centered dot: \\\\(x \\\\cdot y\\\\)\n\n{n+1 \\choose 2k} \\\\({n+1 \\\\choose 2k}\\\\) or \\binom{n+1}{2k} \\\\(\\\\binom{n+1}{2k}\\\\)\n\n\\to \\rightarrow \\leftarrow \\Rightarrow \\Leftarrow \\mapsto \\\\(\\\\to \\\\rightarrow \\\\leftarrow \\\\Rightarrow \\\\Leftarrow \\\\mapsto\\\\)\n\n\\land \\lor \\lnot \\forall \\exists \\top \\bot \\vdash \\vDash \\\\(\\\\land \\\\lor \\\\lnot \\\\forall \\\\exists \\\\top \\\\bot \\\\vdash \\\\vDash\\\\)\n\n\\star \\ast \\oplus \\circ \\bullet \\\\(\\\\star \\\\ast \\\\oplus \\\\circ \\\\bullet\\\\)\n\n\\approx \\sim \\simeq \\cong \\equiv \\prec \\lhd \\therefore \\\\(\\\\approx \\\\sim \\\\simeq \\\\cong \\\\equiv \\\\prec \\\\lhd \\\\therefore\\\\)\n\n\\infty \\aleph0 \\\\(\\\\infty \\\\aleph\\0\\\\)\n\n\\nabla \\partial \\\\(\\\\nabla \\\\partial\\\\) \\Im \\Re \\\\(\\\\Im \\\\Re\\\\)\n\nFor modular equivalence, use \\pmod like this: a\\equiv b\\pmod n \\\\(a\\\\equiv b\\\\pmod n\\\\)\n\n\\ldots is the dots in \\\\(a1,a2,\\\\ldots,an\\\\)\n\n\\cdots is the dots in \\\\(a1+a2+\\\\cdots+an\\\\)\n\nSome Greek letters have variant forms: \\epsilon \\varepsilon \\\\(\\\\epsilon\\\\) \\\\(\\\\varepsilon\\\\) and \\phi \\varphi \\\\(\\\\phi \\\\varphi\\\\) and others\n\nScript lowercase l is \\\\(\\\\ell\\\\)\n\nFormula to code can be done with Detexify which lets you draw a symbol on a web page and then lists the  symbols that seem to resemble it. These are not guaranteed to work in MathJax but are a good place to start. To check that a command is supported, note that MathJax.org maintains a list of currently supported  commands, and one can also check Dr. Carol JVF Burns's page of \n\nSpaces MathJax usually decides for itself how to space formulas, using a complex set of rules. Putting extra literal spaces into formulas will not change the amount of space MathJax puts in: a b and a    b are both ab\n\nTo add more space: use \\, for a thin space \\\\(a\\\\,b\\\\); and use\\; for a wider space \\\\(a\\\\;b\\\\). \\quad and \\qquad are large spaces: \\\\(a \\\\quad b\\\\) adn \\\\(a \\\\qquad b\\\\)\nTo set plain text, use \\text{}: \\\\(\\\\{x\\\\in s\\\\mid x\\\\text{ is extra large}\\\\}\\\\).  You can nest \\\\(\\\\) inside of \\text{}.\nAccents and diacritical marks use \\hat for a single symbol \\\\(\\\\hat{x}\\\\), \\widehat for a larger formula \\\\(\\\\hat{xy}\\\\).  If you make it too wide, it will look silly.  Similarly, there are \\bar \\\\(\\\\bar{x}\\\\) and \\overline \\\\(\\\\overline{xyz}\\\\), and \\vec \\\\(\\\\vec{x}\\\\)  and \\overrightarrow \\\\(\\\\overrightarrow{xy}\\\\) and \\overleftrightarrow \\\\(\\\\overleftrightarrow{xy}\\\\). For dots, as in \\\\(\\\\frac d{dx}x\\\\dot x =  \\\\dot x^2 +  x\\\\ddot x\\\\), use \\dot \\\\(\\\\dot\\\\) and \\ddot \\\\(\\\\ddot\\\\).\nSpecial characters used for MathJax interpreting can be escaped using the \\ character: \\$ \\\\(\n, \\\\{ {, \\\\ \\, etc. If you want \\\\ itself, you should use \\\\backslash \\\\)$, because \\\\ is for a new line. \n\nReferences\n\nTo see how any formula was written in any question or answer, including this one, right-click on the expression it and choose \"Show Math As  TeX Commands\".\n\nThis small mathjax post on stackexchange provided the best mathjax examples I've seen.  The docs are useful, but a bit wordy. \n\nThe wikipedia page provides some nice LaTeX references.\n\n Tables\n\nMathJax does not implement LaTeX tables.\n\n%%latex\n\\begin{array}{|c|c|}\n\\hline X & P(X = i) \\\\\\hline\n  1 & 1/6 \\\\\\hline\n  2 & 1/6 \\\\\\hline\n  3 & 1/6 \\\\\\hline\n  4 & 1/6 \\\\\\hline\n  5 & 1/6 \\\\\\hline\n  6 & 1/6 \\\\\\hline\n\\end{array}\n\nGreek letters\n\n%%latex\n\\begin{array}{|c|c|c|c|}\n\\hline\n\\alpha  &  \\theta  &  o  & \\tau          \\\\\\hline\n\\beta  &  \\vartheta &  \\pi  &  \\upsilon  \\\\\\hline\n\\gamma  &  \\gamma  &  \\varpi  & \\phi     \\\\\\hline\n\\delta  &  \\kappa  &  \\rho  &  \\varphi    \\\\\\hline\n\\epsilon  &  \\lambda  &   \\varrho  &   \\chi    \\\\\\hline\n\\varepsilon  &  \\mu  &  \\sigma   &   \\psi      \\\\\\hline\n\\zeta  &  \\nu  &  \\varsigma  &  \\omega      \\\\\\hline\n\\eta   &   \\xi  &  &   \\\\\\hline                                     \n\\end{array}                                                                  \n\n%%latex\n\\begin{array}{|c|c|c|c|}\n\\hline \n\\Gamma        &         \\Lambda       &        \\Sigma       &        \\Psi          \\\\\\hline\n \\Delta        &         \\Xi           &        \\Upsilon      &        \\Omega        \\\\\\hline\n \\Theta        &         \\Pi           &        \\Phi    & - \\\\\\hline\n\\end{array}\n\n Notation\n\n%%latex\n\\begin{array}{|c|c|c|c|c|}\n\\hline \n \\hat{a}    &        \\acute{a}     &     \\bar{a}     &       \\dot{a}     &       \\breve{a}    \\\\\\hline\n \\check{a}   &        \\grave{a}     &     \\vec{a}     &       \\ddot{a}    &       \\tilde{a}    \\\\\\hline\n\\end{array}\n\n%%latex\n\\begin{array}{|c|c|}\n\\hline\n\\widetilde{abc}    &                 \\widehat{abc}    \\\\\\hline\n \\overleftarrow{abc}   &              \\overrightarrow{abc}    \\\\\\hline\n \\overline{abc}    &                  \\underline{abc}    \\\\\\hline\n \\overbrace{abc}   &                  \\underbrace{abc}    \\\\\\hline\n \\sqrt{abc}      &                    \\sqrt[n]{abc}    \\\\\\hline\n f'      &                          \\frac{abc}{xyz}    \\\\\\hline\n \\end{array}\n\nBasic arrows and symbols \n\n%%latex\n\\begin{array}{|c|c|c|}\n\\hline\n \\leftarrow    &               \\longleftarrow       &        \\uparrow      \\\\\\hline\n \\Leftarrow    &                \\Longleftarrow      &         \\Uparrow      \\\\\\hline      \n \\rightarrow   &                \\longrightarrow     &         \\downarrow      \\\\\\hline    \n \\Rightarrow   &                \\Longrightarrow     &         \\Downarrow      \\\\\\hline    \n \\leftrightarrow  &             \\longleftrightarrow   &       \\updownarrow      \\\\\\hline  \n \\Leftrightarrow   &            \\Longleftrightarrow   &       \\Updownarrow      \\\\\\hline  \n \\mapsto         &              \\longmapsto         &         \\nearrow       \\\\\\hline     \n \\hookleftarrow   &             \\hookrightarrow      &        \\searrow       \\\\\\hline     \n \\leftharpoonup    &            \\rightharpoonup      &        \\swarrow       \\\\\\hline     \n \\leftharpoondown    &          \\rightharpoondown    &        \\nwarrow       \\\\\\hline     \n \\rightleftharpoons  &          \\leadsto    &                           \\\\\\hline\n\\end{array}\n\n Logic, set, and operator symbols\n\n%%latex\n\\begin{array}{|c|c|c|c|}\n\\hline\n\\forall  &  \\complement  &  \\therefore  &  \\emptyset    \\\\\\hline\n\\exists  &  \\subset  &  \\because  &  \\empty    \\\\\\hline\n\\exist  &  \\supset  &  \\mapsto  &  \\varnothing    \\\\\\hline\n\\nexists  &  \\mid  &  \\to  &  \\implies    \\\\\\hline\n\\in  &  \\land  &  \\gets  &  \\impliedby    \\\\\\hline\n\\isin  &  \\lor  &  \\leftrightarrow  &  \\iff    \\\\\\hline\n\\notin  &  \\ni  &  \\notni  &  \\neg or \\lnot    \\\\\\hline\n\\end{array}\n\n%%latex\n\\begin{array}{|c|c|c|c|}\n\\hline\n\\pm         &         \\cap       &         \\diamond           &         \\oplus    \\\\\\hline      \n\\mp         &        \\cup        &        \\bigtriangleup      &        \\ominus    \\\\\\hline     \n\\times      &         \\uplus     &         \\bigtriangledown   &         \\otimes    \\\\\\hline     \n\\div        &          \\sqcap    &          \\triangleleft     &          \\oslash    \\\\\\hline     \n\\ast        &         \\sqcup     &         \\triangleright     &         \\odot       \\\\\\hline       \n\\star       &         \\vee       &         \\lhd\\\\(^b\\\\)           &         \\bigcirc    \\\\\\hline    \n\\circ       &         \\wedge     &         \\rhd\\\\(^b\\\\)           &         \\dagger    \\\\\\hline     \n\\bullet     &         \\setminus  &         \\unlhd\\\\(^b\\\\)         &         \\ddagger    \\\\\\hline    \n\\cdot       &         \\wr        &         \\unrhd\\\\(^b\\\\)         &         \\amalg     \\\\\\hline      \n&         -          &                              &                \\\\\\hline\n\\end{array}\n\nRelation symbols\n\n%%latex\n\\begin{array}{|c|c|c|c|}\n\\hline\n \\leq         &        \\geq         &       \\equiv      &        \\models    \\\\\\hline       \n \\prec        &        \\succ        &       \\sim        &        \\perp    \\\\\\hline         \n \\preceq      &        \\succeq      &       \\simeq      &        \\mid    \\\\\\hline          \n \\ll          &        \\gg          &       \\asymp      &        \\parallel    \\\\\\hline     \n \\subset      &        \\supset      &       \\approx     &        \\bowtie    \\\\\\hline       \n \\subseteq    &        \\supseteq      &     \\cong       &        \\Join\\\\(^b\\\\)    \\\\\\hline     \n \\sqsubset\\\\(^b\\\\)    &    \\sqsupset\\\\(^b\\\\)  &     \\neq        &        \\smile    \\\\\\hline        \n \\sqsubseteq      &    \\sqsupseteq    &     \\doteq      &        \\frown    \\\\\\hline        \n \\in              &    \\ni           &      \\propto     &        =         \\\\\\hline        \n \\vdash           &    \\dashv        &                 &                 \\\\\\hline        \n :       &            &                &               \\\\\\hline \n\\end{array}\n\n Miscellaneous symbols\n\n%%latex\n\\begin{array}{|c|c|c|c|}\n\\hline\n\\ldots       &         \\cdots       &       \\vdots       &       \\ddots         \\\\\\hline        \n\\ldots       &         \\cdots       &       \\vdots       &       \\ddots         \\\\\\hline        \n \\aleph      &          \\prime      &        \\forall     &        \\infty         \\\\\\hline        \n \\hbar       &          \\emptyset   &        \\exists     &        \\Box\\\\(^b\\\\)         \\\\\\hline      \n \\imath      &          \\nabla      &        \\neg        &        \\Diamond\\\\(^b\\\\)         \\\\\\hline  \n \\jmath      &          \\surd       &        \\flat       &        \\triangle         \\\\\\hline     \n \\ell        &          \\top        &        \\natural    &        \\clubsuit         \\\\\\hline     \n \\wp         &         \\bot         &       \\sharp       &       \\diamondsuit         \\\\\\hline  \n \\Re         &         \\|           &       \\backslash   &       \\heartsuit          \\\\\\hline   \n \\Im         &         \\angle       &       \\partial     &       \\spadesuit         \\\\\\hline    \n \\mho\\\\(^b\\\\)    &         .            &       |      &                  \\\\\\hline\n \\end{array}\n\n%%latex\n\\begin{array}{|c|c|c|c|c|c|c|}\n\\hline\n\\arccos   &  \\cos    &   \\csc   &   \\exp   &   \\ker    &     \\limsup   &   \\min   &   \\sinh    \\\\\\hline  \n \\arcsin  &   \\cosh   &   \\deg  &    \\gcd  &    \\lg     &     \\ln\t   &   \\Pr    &   \\sup    \\\\\\hline   \n \\arctan  &   \\cot    &   \\det  &    \\hom  &    \\lim     &    \\log\t   &   \\sec   &   \\tan    \\\\\\hline   \n \\arg     &   \\coth   &   \\dim  &    \\inf  &    \\liminf  &    \\max\t   &   \\sin   &   \\tanh    \\\\\\hline\n  \\end{array}\n\nVariable-sized symbols\n\n%%latex\n\\begin{array}{|c|c|c|}\n\\hline\n\\sum         &        \\bigcap       &      \\bigodot    \\\\\\hline       \n \\prod       &         \\bigcup      &       \\bigotimes    \\\\\\hline     \n \\coprod     &         \\bigsqcup    &       \\bigoplus    \\\\\\hline      \n \\int        &         \\bigvee      &       \\biguplus    \\\\\\hline      \n \\oint       &         \\bigwedge &   \\\\\\hline\n \\end{array}\n\n Delimiters\n\n%%latex\n\\begin{array}{|c|c|c|c|}\n\\hline\n(         &           )         &          \\uparrow      &      \\Uparrow    \\\\\\hline       \n [        &            ]        &           \\downarrow    &      \\Downarrow    \\\\\\hline     \n \\{       &            \\}       &           \\updownarrow  &      \\Updownarrow     \\\\\\hline  \n \\lfloor    &          \\rfloor    &         \\lceil       &       \\rceil    \\\\\\hline         \n \\langle    &          \\rangle    &         /            &       \\backslash    \\\\\\hline     \n |          &          \\|    &           &    \\\\\\hline \n \\end{array}\n\n%%latex\n\\begin{array}{|c|c|c|c|}\n\\hline\n\\rmoustache    &    \\lmoustache     &    \\rgroup         &   \\lgroup     \\\\\\hline\n  \\arrowvert   &      \\Arrowvert     &     \\bracevert    &       \\\\\\hline\n\\end{array}\n\nMatrix symbols\n\n\\\\[\\\\begin{matrix} a & b \\\\\\\\ c & d \\\\end{matrix}\\\\]\n\n\\begin{pmatrix}\n   a & b \\\\\n   c & d\n\\end{pmatrix}\n\n\\\\[\\\\begin{bmatrix} 1 & 2 & -1 \\\\\\\\ 3 & 0 & 1 \\\\\\\\ 0 & 2 & 4 \\\\end{bmatrix}\\\\]\n\n\\\\[\\\\left( \\\\frac{p}{q} \\\\right)\\\\]\n\n Geometry symbols\n\n%%latex\n\\begin{array}{|c|c|}\n\\hline\n\\angle  & \\measuredangle        \\\\\\hline\n\\triangle & \\square         \\\\\\hline\n\\cong  &  \\ncong        \\\\\\hline\n\\sim   &   \\nsim        \\\\\\hline\n\\| & \\nparallel        \\\\\\hline\n\\perp  &  \\not \\perp       \\\\\\hline\n\\end{array}\n\nAlgebraic symbols\n\n\\\\[\\\\sum\\_{n=0}^{\\\\infty}\\\\]\n\n\\\\[\\\\prod\\_{n=0}^{\\\\infty}\\\\]\n\n Calculus symbols\n\n\\\\[\\\\int\\_a^b\\\\]\n\n\\\\[\\\\lim\\_{x \\\\to a}\\\\]\n\n\\\\[f'(a) = \\\\lim\\_{x \\\\to a} \\\\frac{f(x) - f(a)}{x - a}\\\\]\n\n\\\\[\\\\lim\\{x \\\\to a^-} f(x) = f(a) = \\\\lim\\{x \\\\to a^+} f(x)\\\\]\n\nConclusion\n\nRemembering these symbols' code may be difficult when only writing intermitently; however, this reference should provide any required information, quickly.\n\n References\n\nwikipedia page of latex references\nmathjax tutorial\ntex symbols\nlatex wiki symbols\nkatex page\nkatex supported\n",
        "tags": [
            "visualization",
            "tag2",
            "tag3"
        ]
    },
    {
        "uri": "/posts/blog-logic_for_math",
        "title": "Building Math from the Ground-Up",
        "content": "\n\nAfter completing basic high school mathematics, one might think that math stands on its own.  To understand and know that 1+1=2 is obvious.  But math can go much deeper.  In fact, we can build new concepts from math as well as build a math, itself.  This is important because it effects how we think about other subjects, and is especially useful in helping us think about language and abstract concepts, such as in programming.  This post will introduce a few of these concepts.  We will also make some references to how it is useful in natural language processing.\n\nLogical Beginnings\n\nThere are a few different types of logic.   These are presented, here, with increasing rigor:\n\ninformal logic - typically that of natural language\nformal logic - the study of inference, or steps in reasoning; in addition, it is possible to analyze the form of an argument\nsymbolic logic - abstractions for capturing features of inference\nmathematical logic - extension of symbolic to use in different theories, such as model, set, and proof theory\n\nMoving from informal to formal logic is a big jump.  Showing the 'logical form' of an argument is difficult in informal logic because 'indicative sentences of ordinary language show a considerable variety of form and complexity that makes their use in inference impractical.'  \n\nAristotle was the first to support the use of logical form by defining variables to represent valid inferences.  An example is 'all men are mortals' has the form 'all Ps are Qs'.  This advancement leads us to symbolic logic.\n\nThree formal systems of symbolic logic began with Greek philosophers and now provide the foundations we need to do mathematics.  These are: i) syllogism, ii) propositional (sentential), and iii) predicate (first-order) logics.  In order to discuss these we need to define a few terms.  These are formal definitions that are different from how we use every-day language, but they are not un-related.\n\n Important Definitions\n\nArguments and inference\n\nA premise is an assumption that something is true.  In logic, an argument requires a set of (at least) two declarative sentences known as the premises along with another declarative sentence known as the conclusion.  \n\nThe proof of a conclusion depends on both the truth of the premises and the validity of the argument.  An argument is valid if, and only if, it takes a form that makes it impossible for the premises to be true and the conclusion nevertheless to be false. \n\nThe word inference is used quite often in logic, math, and statistics.  It comes from the latin infero which means to 'carry forward', and is usually divided between deduction and induction.\n\nDeduction is the act of deriving (using formal proof) logical conclusions from premises using the 'laws of valid inference'.  So, there are a finite sequence of 'well-formed forumlas' each of which is an assumption (axiom), or conclusion (inferred from the others) used as an assumption, that create a theorem (proven statement).  There are a few popular rules for inference and they include such important ones as modus ponens, modus tollens, contrapositive, and reductio ad absurdum for propositional calculus.\n\nIn the example of modus ponens, the form is written:\nA - B\nA\n------\nB\nThere are additional rules for predicate calculus, as well as other logics, and many of the rules are displayed, here.\n\nA formal system is an organization of terms used for the analysis of deduction. It consists of an alphabet, a language over the alphabet to construct sentences, and a rule for deriving sentences. \n\nInduction involves inference from particular premises, each with some evidence of truth, to a universal conclusion.  While a deductive argument is certain, an inductive argument can only be probable.  It is the basis for the scientific method which is the foundation of all natural sciences (study of naturally occurring phenomena).  Inductive reasoning is inherently uncertain; therefore, it is important when used for making arguments with probability.  Bayes rule is an example of a rule for inference within probability-based inductive reasoning.  \n\nInstead of being valid or invalid, inductive arguments are either strong or weak, according to how probable it is that the conclusion is true.  An argument may be plausible, probable, reasonable, justified or strong, but never certain.\n\nConfusingly, inductive reasoning is different from mathematical induction, which is a form of deductive reasoning which is used for strict proofs of properties on recursively defined sets.\n\nReaching such a deep level of analysis and relating it to the real world can become quite philosophical.  An example is the Second Axiom of Probability which states that at least one of the elementary events in the entire sample space will occur is 1, which in epistemic uncertainty uses the closed-world assumption.  So, it can be difficult to know when one has gone 'too far down the rabbit hole', to use another philosophical reference.\n\nOftentimes, latin terms may be used to describe rules of inference, such as modus ponens, and these underly their Greek philosophical underpinnings.  As an aside, the greek language is not used because the vast majority of that culture's ideas are transferred only by the latin-bearing Roman scrolls.  Interestingly, there is not much latin texts (since the destruction of the Ptolemaic Library of Alexandria), also, but more is still being uncovered through the use of xray photography that displays text erased to provide for medieval christian writings.\n\nAt the same time, some philosophy of science must be understood.  For instance, the idea of hypothesis testing, and the use of the p-value, is fundamental to classical statistics and is almost universally used across all scientific disciplines.  Less conspicuous, but equally controversial, is the assumption of ceteris paribus, all things held constant, in economics research, which allowed statistical theory to be bridged from controlled experimental designs, to observational data.\n\n First-order logic\n\nSyntax is the collection of symbols (concepts) and rules used for creating well-formed expressions.  It is independent of symantics and interpretation.  In natural language, the rules are called grammar, and one such rule in english is that statement structure must be of the form Subject-Verb-Object.\n\nSymantics determine the meaning behind expressions.  It is concerned with words, phrases, signs and symbols.  Oftentimes, there may be a mapping from one set of symbols to another.  In effect, a translation between known and unknown symbols.  \n\nThese necessitate a definition for expression, which is a finite combination of symbols that are well-formed according to the syntax.  The term combination can be difficult because mathematical combinations which are selections made regardless of ordering.  Here, order is important to syntax.  In programming, expressions return a new value, as opposed to a statement which does not.\n\nExpressions are stated using terms, to represent objects, and formulas, which are predicates (relations) to true / false.  A predicate can visualized as the Unit Step (Heaviside) Function.  The domain of all terms and formulas (symbols) is the alphabet of that system.\n\nSyllogistic and Propositional Logic\n\nA syllogism is a kind of logical argument that applies deductive reasoning to arrive at a conclusion based on two or more propositions that are asserted or assumed to be true.  The modus ponens described above is an example.  Aristotle, of the Nyaya school, defined the three-part form where from a general statement (the major premise) and a specific statement (the minor premise), a conclusion is deduced.\nAll men are mortal.\nSocrates is a man.\nTherefore, Socrates is mortal. \n\nThe Stoics created propositional logic.  A proposition is any sentence that can be assigned a truth value, such as Helsinki is the capital of Finland.\n\nThe versatility (and restriction) of propositional logic lies in the fact that we can use it with any statement whatsoever, regardless of its inner structure or logical form.\nBut it is also very, very simple. Elementary propositions are denoted usually by letters, such as lower case p and q. These propositions are connected to each other and manipulated using simple logical connectives, such as:\n~ not\n& and\n| or\n= if, then\n= if and only if\nUsing these symbols, we can generate combinations of the elementary propositions to claim certain logical connections between them.\n\nWe then use so-called truth tables to evaluate the truth of this complex proposition. We can also determine whether it is a tautology (logical truth). In the truth-table method we go through all combinations of p and q as to their truth and falsity and see what the truth value of the whole proposition is. Like so:\n\nIf the last column has only T in it (sometimes +/- or 1/0 are used for truth and falsity), the proposition is a tautology; if it has only F in it, it is a contradiction.\n\n Predicate and Mathematical Logic\n\nWhile propositional logic treats whole propositions, predicate logic distinguishes between objects and their properties (called predicates).\n\nAn alphabet consists of logical and non-logical symbols.  Non-logical symbols include predicates (relations), functions, and constants.  The set of all of these are the signature.  The signature may be i) empty, ii) finite, iii) infinite, or iv) uncountable.  Logical symbols include i) quantifiers, ii) logical connectives, iii) and truth constants.\n\nPredicate logic is essentially a system where the elementary propositions of propositional logic can be further analysed using predicates/properties that are assigned to subjects. For example, above Helsinki is the capital of Finland can be further analysed by denoting Helsinki with the lower-case letter h and the predicate the capital of Finland with a upper-case letter, say C. We get: h is C.\n\nPredicate logic has standardly employed so-called quantifiers, which express the scope of the predicate over the subject-term. In the above case Helsinki is an individual object, so a quantifier makes little sense  so take the tapir example: now the subject-term is the general concept of tapir  denote it with T, and cuddly with C. Since the statement in effect claims that all tapirs are cuddly, we write: All T are C. This is the traditional Aristotelian way of expressing the matter. But the quantifier itself in modern predicate logic is expressed by one of the two symbols:\n\nUniversal quantifier , meaning all, every \nExistential quantifier , meaning some, there exists\n\nThus we see that unlike propositional logic, predicate logic is capable of dealing\nwith sets of entities  making it very useful e.g. in mathematics.\n\nUnfortunately, this property also makes it impossible to employ truth tables in predicate logic: one would have to iterate over a potential infinity of individuals. Instead, in determining the validity of inferences in predicate logic, simple logical rules are established and iterated. For example, we can apply the rule that negating the universal quantifier gives us the existential quantifier with the negation of the proposition:\n\nx(Px) x( Px)\n\nSince in addition we can also use all the logical rules established in propositional logic to the propositions themselves, we have a very powerful and versatile form of logic.\n\nUse in Natural Language Processing\n\nWhat does it take to move from a natural language to a logical form?\n\nFirst, ignoring those grammatical features irrelevant to logic (such as gender and declension, if the argument is in Latin), replacing conjunctions irrelevant to logic (such as \"but\") with logical conjunctions like \"and\" and replacing ambiguous, or alternative logical expressions (\"any\", \"every\", etc.) with expressions of a standard type (such as \"all\", or the universal quantifier ).\n\nSecond, certain parts of the sentence must be replaced with schematic letters. Thus, for example, the expression \"all Ps are Qs\" shows the logical form common to the sentences \"all men are mortals\", \"all cats are carnivores\", \"all Greeks are philosophers\", and so on. The schema can further be condensed into the formula A(P,Q), where the letter A indicates the judgement 'all  are '. \n\nThe english language uses the Subject-Verb-Object statement structure.  From this, a Noun Phrase is created from the subject and object, while the verb and object define the predicate.  The subject and predict, together, create a clause.  The clause may be independent, or dependent.  The entire SVO statement in a meaningful context is a sentence.\n\nMaking use of all of these rules and building models around form structure can be highly supportive for both understanding natural language and creating it.\n\n Conclusion\n\nLogic is one of the worlds oldest subjects of study and it is initmately related with mathematics, especially at the level of analysis.  While this may seem impractical for practicioners, learning and applying it provides a mucher richer understanding of why and how some things are done in math.  It also provides a strong precendence in studying math related disciplines, such as Natural Language Processing.\n",
        "tags": [
            "nlp",
            "tag2",
            "tag3"
        ]
    }
]