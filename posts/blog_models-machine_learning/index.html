<!DOCTYPE html>
<html>
<head>
    <title>Generalizing the Machine Learning Process // IMTorg</title>

        <meta charset="utf-8">
    <meta http-equiv="content-type" content="text/html; charset=utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1">
    <meta name="description" content="">
    <meta name="keywords" content="">
    <meta name="author" content="">
        <meta property="og:title" content="Generalizing the Machine Learning Process" />
    <meta property="og:description" content="" />
    <meta property="og:type" content="website" />
    <meta property="og:locale" content="en_US" />
    <meta property="og:url" content="https://imtorgdemo.github.io/posts/blog_models-machine_learning/" />
    

    <link href="" rel="alternate" type="application/rss+xml" title="IMTorg" />
    <link rel="shortcut icon" href="/favicon.ico">

    <link href="https://imtorgdemo.github.io/webfonts/ptserif/main.css" rel='stylesheet' type='text/css'>
    <link href="https://imtorgdemo.github.io/webfonts/source-code-pro/main.css" rel="stylesheet" type="text/css">

    <link rel="stylesheet" href="https://imtorgdemo.github.io/css/style.css">

    <meta name="generator" content="Hugo 0.55.5" />
</head>


<body>
<div id="container">
    <header id="header">
    <div id="header-outer" class="outer">
        <div id="header-inner" class="inner">
            <a id="main-nav-toggle" class="nav-icon" href="javascript:;"></a>
            <a id="logo" class="logo-text" href="https://imtorgdemo.github.io/">IMTorg</a>
            <nav id="main-nav">
                
                <a class="main-nav-link" href="/about/">About</a>
                
                <a class="main-nav-link" href="/categories/">Categories</a>
                
                <a class="main-nav-link" href="/tags/">Tags</a>
                
            </nav>
            <nav id="sub-nav">
                <div id="search-form-wrap">
                </div>
            </nav>
        </div>
    </div>
</header>

    <section id="main" class="outer">
        <article class="article article-type-post" itemscope itemprop="blogPost">
    <div class="article-inner">
        
        <header class="article-header">
            <h1 class="article-title" itemprop="name">Generalizing the Machine Learning Process</h1>
        </header>
        
        <div class="article-meta">
            <a href="/posts/blog_models-machine_learning/" class="article-date">
                <time datetime='2019-05-09T00:00:00.000&#43;00:00' itemprop="datePublished">2019-05-09</time>
            </a>
            
            
            <div class="post-categories">
                <div class="article-category">
                    
                    
                    <a class="article-category-link" href="https://imtorgdemo.github.io//categories/process">Process</a>
                    
                    
                    <span>&gt;</span>
                    
                    <a class="article-category-link" href="https://imtorgdemo.github.io//categories/datascience">DataScience</a>
                    
                </div>
            </div>
            
            
        </div>
        <div class="article-entry" itemprop="articleBody">
            

<p>This work describes a general approach to follow when performing machine learning (ML) manually, and when automating in a deployment setting.  Unlike a classical statistical analysis, standard machine learning projects typically follow a general and repeatable process.  While the practictioner should be aware of details for each of the steps and the reasons for choosing them, there is much less design-thinking and checking of assumptions that are necessary components of more mathematical modeling fields.  This makes the machine learning process amenable to deployment as a service because automating the re-training and prediction of a model with consistent data is straight-forward programming.</p>

<h2 id="model-theory">Model Theory</h2>

<p>Most of the design-thinking in the ML process is in choosing a variety of models for comparing performance against.  The following three characteristics succinctly describe a ML model.  See <a href="https://imtorgdemo.github.io/posts/blog_page-todo/">here</a> for more explanation.</p>

<ol>
<li>Representation: structural model characteristics

<ul>
<li>name</li>
<li>family</li>
<li>interpretability</li>
<li>type

<ul>
<li>generative / discriminative</li>
<li>bias / var</li>
<li>fixed- / variable- learner</li>
</ul></li>
</ul></li>
<li>Evaluation: functions applied to the structure

<ul>
<li>objective</li>
<li>cost</li>
<li>loss</li>
</ul></li>
<li>Optimization: algorithms necessary to solve for parameters</li>
</ol>

<p>It is also important to understand how the chosen model effects the modeling process</p>

<ul>
<li>assumptions inherent in representation</li>
<li>alignment of loss function with project goals</li>
<li>sources of bias / variance</li>
<li>determination of resource constraints</li>
<li>enumeration of how over-tuning can occur (regularization)</li>
<li>understanding when manual methods are ineffective &lsquo;fiddling&rsquo; of model implementation parameters</li>
<li>statement of strong false assumptions can be better than weak true ones, because they need more data</li>
</ul>

<p><em>Note:</em> This should be considered carefully with feature engineering and feature selection to ensure the input transformations align with the model.</p>

<h2 id="the-machine-learning-process">The Machine Learning Process</h2>

<p>The following are the general steps taken in the ML Process.  They are similar to many other problem-solving processes, but tailored to ML specifics.  There are a few steps where care should be taken to ensure the process is reasonable.  These are more design-oriented and some research may be necessary depending on the scenario.</p>

<p>The practicioner must ensure he is maintaining honesty with the investigation.  One important check is laying-out proper evaluation methods, before implementing them.  This is similar to classical statistics in choosing an accepatable p-value before running the model.  They include selecting evaluation scores and how they should be evaluated.  Another check is on model resource and time requirements.  More sophisticated models need more memory to implement and take a longer time to run.  These are highly dependent on the environment they are deployed to.  These should be determined with the customer, at the beginning.  To learn more read, <a href="https://imtorgdemo.github.io/posts/blog_page-todo/">here</a> for more.</p>

<p>The categories to be predicted on, and the percent of records used for each in training, is a very important subject.  If your target data is of a much lower percentage amount than the rest (needle-in-haystack / imbalanced data problem), then it should be addressed before separating training and testing data.  The most orthodox and direct way to deal with this problem is to simply resample from the target records, with replacement, for enough times to reach 50% of your data.  However, this is an important area of research and some time should be taken before moving forward in the process.  For more information on imbalanced data, check <a href="https://imtorgdemo.github.io/posts/blog_page-todo/">here</a>.</p>

<p>While classical statistics places a strong emphasis on model exploration and ensuring assumptions are met, this is less important in ML.  Instead, much more time should be focused on the features used in the model.  This is mainly in the form of Feature Engineering, which can include several different methodologies, such as Feature Extraction, Feature Selection / Dimensionality Reduction, and Feature Engineering.  Read more about this, <a href="https://imtorgdemo.github.io/posts/blog_page-todo/">here</a>.</p>

<p><em>Discover</em></p>

<ul>
<li>determine problem and constraints</li>
<li>determine characteristics the problem / scenario dictates on the solution

<ul>
<li>model family</li>
<li>acceptable methods of dimensionality reduction and regularization</li>
<li>deployment environment</li>
</ul></li>
<li>decide evaluation

<ul>
<li>primary / secondary evaluation score (ie. accuracy)</li>
<li>methods of evaluation (ie. confusion matrix, roc)</li>
</ul></li>
</ul>

<p><em>Collect and Transform</em></p>

<ul>
<li>obtain raw data

<ul>
<li>internal data warehouses</li>
<li>external APIs and services</li>
</ul></li>
<li>integration and cleaning<br /></li>
<li>filter, aggregate, and query</li>
</ul>

<p><em>Summary and Process</em></p>

<ul>
<li>exploration</li>
<li>preparation

<ul>
<li>address balance (classification, anova, etc.)</li>
<li>create Train, Validate, Test with split (above)</li>
</ul></li>
<li>configure Feature Extraction with feature_union</li>
<li>configure Preprocess and choose model-families with pipeline</li>
</ul>

<p><em>Build</em></p>

<ul>
<li>train the models

<ul>
<li>apply k-folds CV and grid search with Training set</li>
<li>perform on multiple model-families and hyper-parameters</li>
</ul></li>
<li>evaluate models

<ul>
<li>review afore-mentioned confusion matrix, scoring, classifier-threshold, and tests</li>
<li>select the best model-family / hyper-parameters</li>
<li>apply to Validation set or all of Training set to model-family to parameterize it and set as the final model</li>
</ul></li>
<li>refine performance

<ul>
<li>debug performance with learning curve, lift chart</li>
<li>use Testing set to evaluate final model characteristics</li>
<li>export to binary file</li>
</ul></li>
</ul>

<p><em>Deliver</em></p>

<ul>
<li>select solution

<ul>
<li>design interface most appropriate for using the model</li>
<li>automate data integration and pipelines</li>
<li>implement model in deployable environment</li>
</ul></li>
<li>deploy solution within system environments</li>
</ul>

<p><em>Note:</em> Train, Validate, and Test should be from different (independent) data sets, if possible.</p>

<h2 id="stakeholder-interaction-and-timeline">Stakeholder Interaction and Timeline</h2>

<p>It is useful to display these in relation to interactions that must take place with stakeholders.  These may be business users who need a problem solved, or technology departments that will have to support applications that implement the solution.  The y-axis show stage proximity to these stakeholders.</p>

<p>While every project is different, most stages use a similar proportion of time.  The horizontal axis lays-out the timeline.</p>

<p><img src="ml_process.png" alt="machine learning process" /></p>

<h2 id="demonstation">Demonstation</h2>

<p>The following code demonstrates the programming portions of these stages and steps using a toy example on a simulated diverse dataset of both numeric and categorical data.  It separates the columns and uses transform pipelines to perform different dimensionality reduction techniques.<sup class="footnote-ref" id="fnref:1"><a href="#fn:1">1</a></sup> This does display the important steps that must be taken with stakeholders.</p>

<h3 id="configuration">Configuration</h3>

<p>Notebook configurations for the kernel and display output.</p>

<pre><code class="language-python">import warnings
warnings.filterwarnings('ignore')

pd.set_option('display.max_rows', 10)

%matplotlib inline
</code></pre>

<p>Provide for utility functions.</p>

<pre><code class="language-python">import random
import string

def randomString(stringLength=10):
    &quot;&quot;&quot;Generate a random string of fixed length &quot;&quot;&quot;
    letters = string.ascii_lowercase
    return ''.join(random.choice(letters) for i in range(stringLength))
</code></pre>

<p>While importing modules, try to organize them in the order they are used, and by their parent library.</p>

<pre><code class="language-python">#modules
import pandas as pd
import numpy as np

from sklearn.preprocessing import LabelEncoder
from sklearn.preprocessing import OneHotEncoder

from sklearn.impute import SimpleImputer
from sklearn.preprocessing import StandardScaler

from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.pipeline import FeatureUnion

from sklearn.feature_selection import SelectKBest
from sklearn.decomposition import PCA

from sklearn.linear_model import LogisticRegression

from sklearn.model_selection import train_test_split
from sklearn.model_selection import KFold
from sklearn.model_selection import cross_val_score
from sklearn.model_selection import GridSearchCV
from sklearn.model_selection import learning_curve
</code></pre>

<h3 id="collect-and-transform">Collect and transform</h3>

<p>Bring internal and external data, together, for a combined and succinct dataset.  Here, we are simulating both categorical and numeric data for the same dataset.</p>

<pre><code class="language-python">#make data (both numeric and categorical)
iCOLUMNS = 50
iROWS = 1000
#generate classification dataset
from sklearn.datasets.samples_generator import make_blobs
X_cat, Y_cat = make_blobs(n_samples=iROWS, centers=2, n_features=iCOLUMNS, random_state=1)
categories = [randomString(5) for x in range(5)]
cols = [random.choices(categories, k=iCOLUMNS) for _ in range(iROWS)]
X_cat = np.array(cols)


#generate regression dataset
from sklearn.datasets.samples_generator import make_regression
X_num, not_used = make_regression(n_samples=iROWS, n_features=iCOLUMNS, noise=0.1, random_state=1)
</code></pre>

<p>Your processing is simplified when most of your work is within a dataframe.</p>

<pre><code class="language-python">#set in dataframe
dfX_cat = pd.DataFrame(X_cat, columns=['IndepCat-'+str(x) for x in range(iCOLUMNS)] )
dfX_num = pd.DataFrame(X_num, columns=['IndepNum-'+str(x) for x in range(iCOLUMNS)])
dfY_cat = pd.DataFrame(Y_cat, columns=[&quot;Dep&quot;])
dfData = pd.concat([dfY_cat, dfX_cat, dfX_num], axis=1)
</code></pre>

<h3 id="summary-and-process">Summary and process</h3>

<p>Encode your data with transformations in an appropriate order.  Remember that some transformations, such as scaling, should be performed after separation of testing and training datasets because you will be dividing all records by the maximum value, within the dataset.  In model implementation, you would not see the maximum value of your original testing dataset; rather, you would use the current dataset.</p>

<pre><code class="language-python">#separate
X = dfData.drop('Dep', axis=1)
y = dfData['Dep']

#encode y and create datasets
enc = LabelEncoder()
y_set = enc.fit_transform(y)
X_train, X_test, y_train, y_test = train_test_split(X, y_set, test_size=0.2)

print( &quot;Training records: %s&quot;%(X_train.shape[0]) )
print( &quot;Testing records: %s&quot;%(X_test.shape[0]) )
</code></pre>

<pre><code>Training records: 800
Testing records: 200
</code></pre>

<p>Here, you perform scaling, imputation, Principal Component Analysis (PCA), and other transformations whose arguments are dependent upon the same dataset.</p>

<p>Also, the transformation pipelines should be divided into numeric and categoric because some transformations, such as PCA, are inappropriate for categoric data.  Instead use methods, such as <em>Select K Best</em>, for dimensionality reduction.</p>

<p>Working with pipelines can be unwieldly at some times.  For a reference of pipelines, see <a href="https://scikit-learn.org/stable/modules/compose.html#pipelines-and-composite-estimators">sklearn docs</a>.</p>

<pre><code class="language-python">#create feature union of numeric data
features = []
features.append(('pca', PCA()))                    #&lt;&lt;&lt;GRID
features.append(('select_best', SelectKBest()))    #&lt;&lt;&lt;GRID
num_feature_eng = FeatureUnion(features)

#create the preprocessing pipelines for both numeric and categorical data
numeric_features = [x for x in X_train.columns if x.split('-')[0]=='IndepNum' ]
numeric_transformer = Pipeline(steps=[
    ('imputer', SimpleImputer(strategy='median')),
    ('scaler', StandardScaler()),
    ('num_feature_eng', num_feature_eng)
])

categorical_features =  [x for x in X_train.columns if x.split('-')[0]=='IndepCat' ]
categorical_transformer = Pipeline(steps=[
    ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),
    ('onehot', OneHotEncoder(handle_unknown='ignore')),
    ('select_best', SelectKBest(k=6))
])

preprocessor = ColumnTransformer(
    transformers=[
        ('num', numeric_transformer, numeric_features),
        ('cat', categorical_transformer, categorical_features)])

#append classifier to preprocessing pipeline
#full prediction pipeline
clf = Pipeline(steps=[('preprocessor', preprocessor),
                      ('classifier', LogisticRegression(solver='lbfgs'))])
</code></pre>

<p>Optimize your hyper-parameters in a grid search.  You may have to get output for all the pipeline keys to find their names because the notation can become quite lenthy based on the amount of nesting, such as this pipeline displays.</p>

<pre><code class="language-python">param_grid = {
    'preprocessor__num__imputer__strategy': ['mean', 'median'],
    'classifier__C': [0.1, 1.0, 10, 100],
    'preprocessor__num__num_feature_eng__pca__n_components': [.75, .80, .85, .90, .95],
    'preprocessor__num__num_feature_eng__select_best__k': [5, 7, 9, 11]
}
gridClf = GridSearchCV(clf, param_grid, cv=5)
</code></pre>

<h3 id="build">Build</h3>

<p>Build your model through optimizing values over the grid.  This is usually based on stochastic gradient descent, or some other iterative routine.  Convergence may be time-consuming depending on the model you&rsquo;ve chosen and the number of parameters and hyper-parameters that must be selected.  NaiveBayes methods can be some of the most costly.  Run more balanced models, first, to get an idea of the parameter space, before trying more costly approaches.</p>

<pre><code class="language-python">gridClf.fit(X_train, y_train)
</code></pre>

<pre><code>GridSearchCV(cv=5, error_score='raise-deprecating',
       estimator=Pipeline(memory=None,
     steps=[('preprocessor', ColumnTransformer(n_jobs=None, remainder='drop', sparse_threshold=0.3,
         transformer_weights=None,
         transformers=[('num', Pipeline(memory=None,
     steps=[('imputer', SimpleImputer(copy=True, fill_value=None, missing_values=nan,
       strategy='median', verbo...enalty='l2', random_state=None, solver='lbfgs',
          tol=0.0001, verbose=0, warm_start=False))]),
       fit_params=None, iid='warn', n_jobs=None,
       param_grid={'preprocessor__num__imputer__strategy': ['mean', 'median'], 'classifier__C': [0.1, 1.0, 10, 100], 'preprocessor__num__num_feature_eng__pca__n_components': [0.75, 0.8, 0.85, 0.9, 0.95], 'preprocessor__num__num_feature_eng__select_best__k': [5, 7, 9, 11]},
       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',
       scoring=None, verbose=0)
</code></pre>

<p>Take the <em>best</em> model with parameters / hyper-parameters from highest grid-search, cross-validation, and apply it to the test data.  This data is simulated and you should be able to perform better than a coin-flip (50%).</p>

<pre><code class="language-python">print((&quot;best logistic regression from grid search: %.3f&quot;
       % gridClf.score(X_test, y_test)))
</code></pre>

<pre><code>best logistic regression from grid search: 0.515
</code></pre>

<p>Get an idea of the results and parameter space.  Extreme values may indicate over-fitting or some other anomaly is occuring.</p>

<pre><code class="language-python"># Cross Validation
#GridSearchCV: Mean cross-validated score of the best_estimator
#SGDClassifier: Returns the mean accuracy on the given test data and labels
print(&quot;Best Score: (CV score=%0.3f)&quot; % gridClf.best_score_)
print(&quot;\n&quot;)
print(&quot;Best Parameters\n %s&quot; % gridClf.best_params_ )
print(&quot;\n&quot;)
print(&quot;Best Estimator\n %s&quot; %  gridClf.best_estimator_ )
</code></pre>

<pre><code>Best Score: (CV score=0.484)


Best Parameters
 {'classifier__C': 10, 'preprocessor__num__imputer__strategy': 'mean', 'preprocessor__num__num_feature_eng__pca__n_components': 0.9, 'preprocessor__num__num_feature_eng__select_best__k': 5}


Best Estimator
 Pipeline(memory=None,
     steps=[('preprocessor', ColumnTransformer(n_jobs=None, remainder='drop', sparse_threshold=0.3,
         transformer_weights=None,
         transformers=[('num', Pipeline(memory=None,
     steps=[('imputer', SimpleImputer(copy=True, fill_value=None, missing_values=nan, strategy='mean',
       verbose...enalty='l2', random_state=None, solver='lbfgs',
          tol=0.0001, verbose=0, warm_start=False))])
</code></pre>

<p>A confusion matrix is your basic display of results.  This is for your training data.</p>

<pre><code class="language-python"># Confusion Matrix
from sklearn.metrics import confusion_matrix
y_train_pred = gridClf.predict(X_train)
print( &quot;Confusion matrix: Training&quot;)
confusion_matrix(y_train, y_train_pred)
</code></pre>

<pre><code>Confusion matrix: Training





array([[255, 149],
       [146, 250]])
</code></pre>

<p>This confusion matrix is for your test data.</p>

<pre><code class="language-python">y_pred = gridClf.predict(X_test)
print( &quot;Confusion matrix: Testing&quot;)
confusion_matrix(y_test, y_pred)
</code></pre>

<pre><code>Confusion matrix: Testing





array([[51, 45],
       [52, 52]])
</code></pre>

<p>After getting a general feel for the situation, look at the specific performance metrics you set, at the beginning of your problem statement.  Ensure you hold yourself to this standard and do not change the solutions&rsquo; needs based on current results.  For a complete listing of performance metrics, view the <a href="https://scikit-learn.org/stable/modules/model_evaluation.html#model-evaluation-quantifying-the-quality-of-predictions">sklearn docs</a>.</p>

<pre><code class="language-python"># Testing

#predictions for outcome labels
#Predict class probabilities for X.  The predicted class probabilities of an input sample are computed as the mean predicted
#class probabilities of the trees in the forest. The class probability of a single tree is the fraction of samples of the same
#class in a leaf.
y_class_prob = gridClf.predict_proba(X_test)                # called   predict_proba(), for some classifiers
y_prob = np.asarray( [x[1] for x in y_class_prob], dtype=np.float32)
threshold = 0                                               # set threshold
y_some_digit_pred = (y_prob &gt; threshold)
print( &quot;Average training probability: %0.3f&quot; % np.mean(y_prob) )

#roc auc
from sklearn.metrics import roc_auc_score
print( &quot;Area Under ROC Curve: %0.3f&quot; % roc_auc_score(y_test, y_prob) )
</code></pre>

<pre><code>Average training probability: 0.484
Area Under ROC Curve: 0.492
</code></pre>

<p>A variety of different plots can be used to explore model and result performance.  The ROC Curve is one of the most fundamental, but several others are of importance.  Performance graphs are explained in the <a href="https://scikit-learn.org/stable/modules/learning_curve.html#validation-curves-plotting-scores-to-evaluate-models">sklearn docs</a>.</p>

<pre><code class="language-python">log_y_prob = gridClf.decision_function(X_test) 

from sklearn import metrics
import numpy as np
import matplotlib.pyplot as plt

#plt.figure(0).clf()

#LogisticRegression  
y_prob = log_y_prob
fpr, tpr, thresh = metrics.roc_curve(y_test, y_prob)
auc = metrics.roc_auc_score(y_test, y_prob)
plt.plot(fpr,tpr,label=&quot;logistic reg, auc=&quot;+str(auc))


plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Receiver operating characteristic')
plt.legend(loc=0)
plt.show()
</code></pre>

<p><img src="output_40_0.png" alt="png" /></p>

<h3 id="deliver">Deliver</h3>

<p>Save the model for future use, especially if you just spent a large amount of time getting the algorithm to converge.</p>

<pre><code class="language-python">from sklearn.externals import joblib
import os

cwd = os.getcwd()
file_path = cwd+'/Data/project/Models/'

#save the model to disk
filename = file_path+'finalized_model.sav'
joblib.dump(gridClf, filename)
</code></pre>

<p>Implement the model within the necessary solution system.</p>

<pre><code class="language-python">#in deployment application...
#load the model from disk
loaded_model = joblib.load(filename)
result = loaded_model.score(X_test, Y_test)
print(result)
</code></pre>

<h2 id="conclusion">Conclusion</h2>

<p>In this work, we provide an orthodox approach to the ML Process.  We list the stages involved and the steps for each, and align these with more traditional modeling and analysis processes.  Demo code runs through the basic ideas.  This code can be modified in order to automate processing in a separate environment, such as a deployed service.  The complete process can be generalized to many situations.</p>
<div class="footnotes">

<hr />

<ol>
<li id="fn:1"><a href="https://scikit-learn.org/stable/auto_examples/compose/plot_column_transformer_mixed_types.html#sphx-glr-auto-examples-compose-plot-column-transformer-mixed-types-py">Column Transformer with Mixed Types</a>
 <a class="footnote-return" href="#fnref:1"><sup>[return]</sup></a></li>
</ol>
</div>

        </div>

        
        
        <div class="article-toc" style="display:none;">
            <h3>Contents</h3>
            <nav id="TableOfContents">
<ul>
<li>
<ul>
<li><a href="#model-theory">Model Theory</a></li>
<li><a href="#the-machine-learning-process">The Machine Learning Process</a></li>
<li><a href="#stakeholder-interaction-and-timeline">Stakeholder Interaction and Timeline</a></li>
<li><a href="#demonstation">Demonstation</a>
<ul>
<li><a href="#configuration">Configuration</a></li>
<li><a href="#collect-and-transform">Collect and transform</a></li>
<li><a href="#summary-and-process">Summary and process</a></li>
<li><a href="#build">Build</a></li>
<li><a href="#deliver">Deliver</a></li>
</ul></li>
<li><a href="#conclusion">Conclusion</a></li>
</ul></li>
</ul>
</nav>
        </div>
        
        

        
        <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.1.1/jquery.slim.min.js" integrity="sha256-/SIrNqv8h6QGKDuNoLGA4iret+kyesCkHGzVUUV0shc=" crossorigin="anonymous"></script>
        <script>
            (function() {
                var $toc = $('#TableOfContents');
                if ($toc.length > 0) {
                    var $window = $(window);

                    function onScroll(){
                        var currentScroll = $window.scrollTop();
                        var h = $('.article-entry h1, .article-entry h2, .article-entry h3, .article-entry h4, .article-entry h5, .article-entry h6');
                        var id = "";
                        h.each(function (i, e) {
                            e = $(e);
                            if (e.offset().top - 10 <= currentScroll) {
                                id = e.attr('id');
                            }
                        });
                        var active = $toc.find('a.active');
                        if (active.length == 1 && active.eq(0).attr('href') == '#' + id) return true;

                        active.each(function (i, e) {
                            $(e).removeClass('active').siblings('ul').hide();
                        });
                        $toc.find('a[href="#' + id + '"]').parentsUntil('#TableOfContents').each(function (i, e) {
                            $(e).children('a').addClass('active').siblings('ul').show();
                        });
                    }

                    $window.on('scroll', onScroll);
                    $(document).ready(function() {
                        $toc.find('a').parent('li').find('ul').hide();
                        onScroll();
                        document.getElementsByClassName('article-toc')[0].style.display = '';
                    });
                }
            })();
        </script>
        


        
        <footer class="article-footer">
            <ul class="article-tag-list">
                
                <li class="article-tag-list-item">
                    <a class="article-tag-list-link" href="https://imtorgdemo.github.io//tags/machine-learning">machine-learning
                    </a>
                </li>
                
                <li class="article-tag-list-item">
                    <a class="article-tag-list-link" href="https://imtorgdemo.github.io//tags/best-practice">best-practice
                    </a>
                </li>
                
            </ul>
        </footer>
        
    </div>
    <nav id="article-nav">
    
    <a href="/posts/blog_nlp-regular_expressions_workflow/" id="article-nav-newer" class="article-nav-link-wrap">
        <div class="article-nav-title"><span>&lt;</span>&nbsp;
            Solving Textual Problems with Regular Expressions
        </div>
    </a>
    
    
    <a href="/posts/blog_test-hugo_blog/" id="article-nav-older" class="article-nav-link-wrap">
        <div class="article-nav-title">Formatting for Jupyter (.ipynb) Notebooks&nbsp;<span>&gt;</span></div>
    </a>
    
</nav>

</article>

        
    </section>
    <footer id="footer">
    <div class="outer">
        <div id="footer-info" class="inner">
            &copy; 2019 IMTorg
            <br />
            <b> Want to discuss software?</b><br>Send me a message <a href="mailto:information@mgmt-tech.org?Subject=Open%20Software" target="_top"></a> information@mgmt-tech.org
        </div>
    </div>
    

    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.9.0/styles/tomorrow-night.min.css" integrity="sha256-2wL88NKUqvJi/ExflDzkzUumjUM73mcK2gBvBBeLvTk=" crossorigin="anonymous" />
    <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.9.0/highlight.min.js" integrity="sha256-KbfTjB0WZ8vvXngdpJGY3Yp3xKk+tttbqClO11anCIU=" crossorigin="anonymous"></script>
    <script>hljs.initHighlightingOnLoad();</script>

    
        <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.7.1/katex.min.css" integrity="sha384-wITovz90syo1dJWVh32uuETPVEtGigN07tkttEqPv+uR2SE/mbQcG7ATL28aI9H0" crossorigin="anonymous">
        <script src="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.7.1/katex.min.js" integrity="sha384-/y1Nn9+QQAipbNQWU65krzJralCnuOasHncUFXGkdwntGeSvQicrYkiUBwsgUqc1" crossorigin="anonymous"></script>
        <script src="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.7.1/contrib/auto-render.min.js" integrity="sha256-ExtbCSBuYA7kq1Pz362ibde9nnsHYPt6JxuxYeZbU+c=" crossorigin="anonymous"></script>
        <script>renderMathInElement(document.body);</script>
    
    <script>
        document.getElementById('main-nav-toggle').addEventListener('click', function () {
            var header = document.getElementById('header');
            if (header.classList.contains('mobile-on')) {
                header.classList.remove('mobile-on');
            } else {
                header.classList.add('mobile-on');
            }
        });
    </script>
</footer>

</div>
</body>
</html>
