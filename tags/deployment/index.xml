<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>deployment on IMTorg Kbase</title>
    <link>https://imtorgdemo.github.io/tags/deployment/</link>
    <description>Recent content in deployment on IMTorg Kbase</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Tue, 03 Mar 2020 00:00:00 +0000</lastBuildDate>
    
	<atom:link href="https://imtorgdemo.github.io/tags/deployment/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Spark Deployments</title>
      <link>https://imtorgdemo.github.io/posts/blog_ds_spark_deployment/</link>
      <pubDate>Tue, 03 Mar 2020 00:00:00 +0000</pubDate>
      
      <guid>https://imtorgdemo.github.io/posts/blog_ds_spark_deployment/</guid>
      <description>Hadoop is seen as the staple of clusters and distributed management. Spark is ubiquitous data science tool. What if you combine Hadoop with Spark? We will explore that question and compare different deployment architectures in this post.
Introduction As Storage you use HDFS. Analytics is done with Apache Spark and YARN is taking care of the resource management. Why does that work so well together?
From a platform architecture perspective, Hadoop and Spark are usually managed on the same cluster.</description>
    </item>
    
    <item>
      <title>Working through a Progressive Python Application</title>
      <link>https://imtorgdemo.github.io/posts/blog_programming_python-develop_and_deploy/</link>
      <pubDate>Sun, 01 Mar 2020 00:00:00 +0000</pubDate>
      
      <guid>https://imtorgdemo.github.io/posts/blog_programming_python-develop_and_deploy/</guid>
      <description>This post walks the developer through a python application as it progresses in development. It uses linux, docker, vscode, pyenv, pipenv and other tools for developing, building, and deploying an application.
Environment Two tools can help you setup your local development environment: pyenv and pipenv. Pyenv is good for getting the correct python version. Pipenv is quite good at setting your virtual environment so that your versions of python and dependencies are separate from your actual machine.</description>
    </item>
    
    <item>
      <title>Distributing Code in Python</title>
      <link>https://imtorgdemo.github.io/posts/blog_programming_py-distributing_code/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://imtorgdemo.github.io/posts/blog_programming_py-distributing_code/</guid>
      <description>Distributing and deploying products is a necessary step in the solution development process, and an imperative in business. Each solution must be thoughtfully analyzed for strengths and weaknesses, especially from the perspective of security. The decisons you make are largely based on the language employed to create the solution. This post will describe steps taken in distributing a Python solution.
Introduction to Bytecode Simple python scripts are a terrific approach to getting work done, quickly.</description>
    </item>
    
  </channel>
</rss>