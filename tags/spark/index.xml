<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>spark on IMTorg Kbase</title>
    <link>https://imtorgdemo.github.io/tags/spark/</link>
    <description>Recent content in spark on IMTorg Kbase</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Tue, 03 Mar 2020 00:00:00 +0000</lastBuildDate>
    
	<atom:link href="https://imtorgdemo.github.io/tags/spark/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Spark Deployments</title>
      <link>https://imtorgdemo.github.io/posts/blog_ds_spark_deployment/</link>
      <pubDate>Tue, 03 Mar 2020 00:00:00 +0000</pubDate>
      
      <guid>https://imtorgdemo.github.io/posts/blog_ds_spark_deployment/</guid>
      <description>Hadoop is seen as the staple of clusters and distributed management. Spark is ubiquitous data science tool. What if you combine Hadoop with Spark? We will explore that question and compare different deployment architectures in this post.
Introduction As Storage you use HDFS. Analytics is done with Apache Spark and YARN is taking care of the resource management. Why does that work so well together?
From a platform architecture perspective, Hadoop and Spark are usually managed on the same cluster.</description>
    </item>
    
  </channel>
</rss>