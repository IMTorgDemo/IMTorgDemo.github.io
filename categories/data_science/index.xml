<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Data_Science on IMTorg Kbase</title>
    <link>https://imtorgdemo.github.io/categories/data_science/</link>
    <description>Recent content in Data_Science on IMTorg Kbase</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Fri, 13 Jan 2023 00:00:00 +0000</lastBuildDate><atom:link href="https://imtorgdemo.github.io/categories/data_science/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Determine a Reasonable Sample Size for Training a Text Classifier</title>
      <link>https://imtorgdemo.github.io/posts/blog_nlp-sample_size_pred_intvl/</link>
      <pubDate>Fri, 13 Jan 2023 00:00:00 +0000</pubDate>
      
      <guid>https://imtorgdemo.github.io/posts/blog_nlp-sample_size_pred_intvl/</guid>
      <description>Consider that we are creating a text classification model that will discover a few target needles in a massive haystack of records. Maybe we are looking for messages of Death among emergency services messages - 20 for every 50,000 messages. Labeling this large dataset and finding the Death messages is costly, so we don&amp;rsquo;t want to label more than is necessary. If we already have enough to estimate the target proportion, let us determine whether the sample size used for training the classification model is large enough.</description>
    </item>
    
    <item>
      <title>Terminology Useful for NLP</title>
      <link>https://imtorgdemo.github.io/posts/blog_nlp-intro_terminology/</link>
      <pubDate>Sat, 11 Dec 2021 00:00:00 +0000</pubDate>
      
      <guid>https://imtorgdemo.github.io/posts/blog_nlp-intro_terminology/</guid>
      <description>NLP allows for both theoretical and practical study of language. Below are a few of aspects of study, as well as terminology, that is frequently used within the field. Because of the interdisciplinary nature of computational linguistics, the terms come from linguistics, computer science, and mathematics.
Semiotics - a philosophical theory covering the relationship between signs and the things they reference.
Phonetic and Phonological Knowledge - Phonetics is the study of language at the level of sounds while phonology is the study of the combination of sounds into organized units of speech.</description>
    </item>
    
    <item>
      <title>Three Levels of Customer Explanations for Data Science</title>
      <link>https://imtorgdemo.github.io/posts/blog_biz-customer_explanation/</link>
      <pubDate>Fri, 10 Dec 2021 00:00:00 +0000</pubDate>
      
      <guid>https://imtorgdemo.github.io/posts/blog_biz-customer_explanation/</guid>
      <description>Every customer is different. That seems obvious until they begin to ask you specific questions about your work - or they don&amp;rsquo;t ask anything at all. It is good to have a framework for providing information: starting general and moving to more specific. Note that at no time are you at the math or calculation level. I&amp;rsquo;ve never seen that go well.
Solution level: What you&amp;rsquo;re doing Nothing special here, just input and output.</description>
    </item>
    
    <item>
      <title>Determining Sample Size for AI Models</title>
      <link>https://imtorgdemo.github.io/posts/blog_nlp-sample_size_calc/</link>
      <pubDate>Thu, 09 Dec 2021 00:00:00 +0000</pubDate>
      
      <guid>https://imtorgdemo.github.io/posts/blog_nlp-sample_size_calc/</guid>
      <description>We are going to dive into the deep disturbing world of sample size in AI. This work is RARELY done as part of AI solutions. There are comparatively few research papers on this topic, and the approaches they offer tend to be specific to the underlying problem addressed in the paper. However, the simple fact that it is poorly understood gives great understanding to the world of AI, which is why I describe it as &amp;lsquo;disturbing&amp;rsquo;.</description>
    </item>
    
    <item>
      <title>Design Thinking and Employee Maturity</title>
      <link>https://imtorgdemo.github.io/posts/blog_pm-mentorship/</link>
      <pubDate>Wed, 08 Dec 2021 00:00:00 +0000</pubDate>
      
      <guid>https://imtorgdemo.github.io/posts/blog_pm-mentorship/</guid>
      <description>I thought about why I felt like some data scientists are more Junior- to Mid- level data scientists; rather than Mid- to Senior- level. The reason I think this is because I often ask them to propose some type of design for a solution to multiple requirements / problems. The response is almost always &amp;lsquo;how do I do this?&amp;rsquo; - bad answer. This is very different from high-performing teams I&amp;rsquo;ve been on where it is more common to have multiple people arguing over multiple solution designs.</description>
    </item>
    
    <item>
      <title>SpaCy Internals</title>
      <link>https://imtorgdemo.github.io/posts/blog_nlp-spacy_internals/</link>
      <pubDate>Tue, 07 Dec 2021 00:00:00 +0000</pubDate>
      
      <guid>https://imtorgdemo.github.io/posts/blog_nlp-spacy_internals/</guid>
      <description>I think there is some confusion about the different components - I&amp;rsquo;ll try to clarify:
The tokenizer does not produce vectors. It&amp;rsquo;s just a component that segments texts into tokens. In spaCy, it&amp;rsquo;s rule-based and not trainable, and doesn&amp;rsquo;t have anything to do with vectors. It looks at whitespace and punctuation to determine which are the unique tokens in a sentence.
An nlp model in spaCy can have predefined (static) word vectors that are accessible on the Token level.</description>
    </item>
    
    <item>
      <title>User Stories vs Data Stories</title>
      <link>https://imtorgdemo.github.io/posts/blog_pm-user_stories/</link>
      <pubDate>Sun, 05 Dec 2021 00:00:00 +0000</pubDate>
      
      <guid>https://imtorgdemo.github.io/posts/blog_pm-user_stories/</guid>
      <description>Agile is used to remove uncertainty from projects, so that the features for development are fairly clear, at least for the current iteration. However, producing an analytics application creates many more tasks because it is focused on data. To remove uncertainty from these data tasks, and the overall project, we keep it separate from development. This ensures that we: i) understand the data, ii) have a clear methodology for addressing problems using the data.</description>
    </item>
    
    <item>
      <title>Why Data Scientists Need Some Fundamental Front End Skills</title>
      <link>https://imtorgdemo.github.io/posts/blog_ds-web_skills/</link>
      <pubDate>Thu, 02 Dec 2021 00:00:00 +0000</pubDate>
      
      <guid>https://imtorgdemo.github.io/posts/blog_ds-web_skills/</guid>
      <description>Most data scientists are lucky to have a basic understanding of HTML, or web applications, in general. However, this dearth of knowledge can be quite limiting as their career grows. They will not be able to grow their skills more broadly to areas such as data visualization or web scraping. They will also have difficulty leading mixed teams delivering complete solutions. They can be easily relegated to creating models of simple reports.</description>
    </item>
    
    <item>
      <title>Computer Vision Using PyTorch</title>
      <link>https://imtorgdemo.github.io/posts/blog_models-pytorch_computervision/</link>
      <pubDate>Thu, 02 Jul 2020 00:00:00 +0000</pubDate>
      
      <guid>https://imtorgdemo.github.io/posts/blog_models-pytorch_computervision/</guid>
      <description>The deep learning movement began by applying neural networks to image classification. PyTorch became a leading framework for work in this field. This post provides a cheatsheet to some of the basic methods used for computer vision, using PyTorch.
Configuration This is a typical environment setup. Seed the Random Number Generator for all devices (both CPU and CUDA) using manual_seed() so that work can be reproduced. Computations are deterministic only on your specific problem, platform, and PyTorch release.</description>
    </item>
    
    <item>
      <title>Neural Network Basics: Linear Regression with PyTorch</title>
      <link>https://imtorgdemo.github.io/posts/blog_models-neuralnet_pytorch_intro/</link>
      <pubDate>Wed, 01 Jul 2020 00:00:00 +0000</pubDate>
      
      <guid>https://imtorgdemo.github.io/posts/blog_models-neuralnet_pytorch_intro/</guid>
      <description>In just a few short years, PyTorch took the crown for most popular deep learning framework. Its concise and straightforward API allows for custom changes to popular networks and layers. While some of the descriptions may some foreign to mathematicians, the concepts are familiar to anyone with a little experience in machine learning. This post will walk the user from a simple linear regression to an (overkill) neural network model, with thousands of parameters, which provides a good base for future learning.</description>
    </item>
    
    <item>
      <title>PySpark Refresher Tutorial</title>
      <link>https://imtorgdemo.github.io/posts/blog_bigdata_pyspark-refresher/</link>
      <pubDate>Mon, 15 Jun 2020 00:00:00 +0000</pubDate>
      
      <guid>https://imtorgdemo.github.io/posts/blog_bigdata_pyspark-refresher/</guid>
      <description>Spark is the primier BigData tool for data science, and PySpark supports a natural move from the local machine to cluster computing. In fact, you can use PySpark on your local machine in standalone mode just as you would on a cluster. In this post, we provide a refresher for those working on legacy or other systems, and want to quickly transition back to Spark.
Environment When using the pyspark-shell, the spark.</description>
    </item>
    
    <item>
      <title>An Introduction to Numpy and Pandas</title>
      <link>https://imtorgdemo.github.io/posts/blog_ds-intro_numpy_pandas/</link>
      <pubDate>Sun, 22 Mar 2020 00:00:00 +0000</pubDate>
      
      <guid>https://imtorgdemo.github.io/posts/blog_ds-intro_numpy_pandas/</guid>
      <description>Numpy and Pandas are the basic data science tools in the Python environment. Having a good understanding of their capabilities and how they process data is imperative to writing optimal code. This post provides an introductory overview and a refresher for those who might come back to the libraries after taking a break. The end of the post explains external interfaces for increasing code execution and performing more sophisticated matrix operations.</description>
    </item>
    
    <item>
      <title>The R and Pandas Dataframe</title>
      <link>https://imtorgdemo.github.io/posts/blog_ds-dataframe_r_and_pandas/</link>
      <pubDate>Mon, 02 Mar 2020 00:00:00 +0000</pubDate>
      
      <guid>https://imtorgdemo.github.io/posts/blog_ds-dataframe_r_and_pandas/</guid>
      <description>Although Pandas uses the Dataframe as its primary data structure, just as R does, the Pandas syntax and underlying fundamentals can be disorienting for R users. This post will describe some basic comparisons and inconsistencies between the two languages. It will also provide some examples of very non-intuitive solutions to common problems.
Introduction In the Datascience R versus Pandas debate, it is really an apples and oranges comparison. R is a domain specific language in the field of statistics, analytics, and data visualization.</description>
    </item>
    
    <item>
      <title>Incorporating an Initial Training Sample into a Project</title>
      <link>https://imtorgdemo.github.io/posts/blog_math-reuse_tng_sample/</link>
      <pubDate>Thu, 09 Jan 2020 00:00:00 +0000</pubDate>
      
      <guid>https://imtorgdemo.github.io/posts/blog_math-reuse_tng_sample/</guid>
      <description>During a data science project, data is often provided in an incremental manner. Some customer files are easier to obtain than others, such as when lengthy unarchiving processes are warranted. To ensure no time is wasted, available data can be put to use with initial analyses and model training as a Training Sample. The same data is incorporated with Training data when it is formally split into Training and Holdout sets.</description>
    </item>
    
    <item>
      <title>Working with Matrices and Tensors in PyTorch</title>
      <link>https://imtorgdemo.github.io/posts/blog_models-matrix_tensor_operations/</link>
      <pubDate>Mon, 26 Aug 2019 00:00:00 +0000</pubDate>
      
      <guid>https://imtorgdemo.github.io/posts/blog_models-matrix_tensor_operations/</guid>
      <description>The Artificial Intelligence field is moving from single-function libraries to frameworks for building different network models. TensorFlow was one of the first, and has strong production capabilities, such as process optimizations. However, its syntax is unintuitive, and the library has a reputation for being difficult for testing new models. This led to many organizations adopting PyTorch, with underlying Numpy, for designing network models. This post describes the basic data structures for working with Matrices and Tensors in PyTorch.</description>
    </item>
    
  </channel>
</rss>
